import os
os.environ['GRPC_VERBOSITY'] = 'ERROR'
os.environ['GLOG_minloglevel'] = '2'

#!/usr/bin/env python3
"""
AgenticX GraphRAG æ¼”ç¤ºç³»ç»Ÿä¸»ç¨‹åº

åŸºäº AgenticX æ ¸å¿ƒæ¨¡å—çš„å®Œæ•´ GraphRAG å®ç°ï¼ŒåŒ…æ‹¬ï¼š
- æ–‡æ¡£è§£æå’Œæ™ºèƒ½åˆ†å—
- å±‚çº§åŒ–çŸ¥è¯†å›¾è°±æ„å»º
- å¤šæ¨¡æ€å­˜å‚¨å’Œç´¢å¼•
- æ™ºèƒ½æ··åˆæ£€ç´¢
- äº¤äº’å¼é—®ç­”ç³»ç»Ÿ
"""
import absl.logging
absl.logging.set_verbosity('info')

import sys
import yaml
import asyncio
import warnings
import time
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime, timezone
from loguru import logger

# å¯¼å…¥ Rich ç¾åŒ–åº“
try:
    from rich.console import Console
    from rich.panel import Panel
    from rich.text import Text
    from rich.table import Table
    from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn
    from rich.layout import Layout
    from rich.align import Align
    from rich.rule import Rule
    from rich import box
    from rich.prompt import Prompt, Confirm
    try:
        from pyboxen import boxen
    except ImportError:
        boxen = None
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€ç‰ˆæœ¬
    Console = None
    Panel = None
    Table = None
    Text = None
    Progress = None
    SpinnerColumn = None
    TextColumn = None
    BarColumn = None
    TimeElapsedColumn = None
    Layout = None
    Align = None
    Rule = None
    box = None
    Prompt = None
    Confirm = None
    boxen = None

# è¿‡æ»¤è­¦å‘Šä¿¡æ¯
warnings.filterwarnings("ignore", category=DeprecationWarning, module="importlib._bootstrap")
warnings.filterwarnings("ignore", message=".*datetime.datetime.utcnow.*")
warnings.filterwarnings("ignore", message=".*SwigPy.*")
warnings.filterwarnings("ignore", message=".*builtin type.*has no __module__ attribute.*")
warnings.filterwarnings("ignore", category=DeprecationWarning, module="neo4j")
warnings.filterwarnings("ignore", message=".*session.*")
warnings.filterwarnings("ignore", message=".*connection.*")

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
# ç¡®ä¿ä»è„šæœ¬æ‰€åœ¨ç›®å½•åŠ è½½ .env æ–‡ä»¶
script_dir = Path(__file__).parent
env_path = script_dir / ".env"
load_dotenv(env_path)

# å¯¼å…¥ os æ¨¡å—ç”¨äºç¯å¢ƒå˜é‡
import os

# AgenticX æ ¸å¿ƒæ¨¡å—å¯¼å…¥
from agenticx.knowledge import (
    Knowledge,
    Document,
    DocumentProcessor,
    KnowledgeGraphBuilder,   SemanticChunker,
    AgenticChunker,
    get_chunker
)
from agenticx.knowledge.readers import (
    PDFReader,
    TextReader,
    JSONReader,
    CSVReader,
    WordReader,
    PowerPointReader
)
from agenticx.embeddings import (
    EmbeddingRouter,
    OpenAIEmbeddingProvider,
    SiliconFlowEmbeddingProvider,
    BailianEmbeddingProvider
)
from agenticx.storage import (
    StorageManager,
    StorageConfig,
    StorageType,
    Neo4jStorage,
    ChromaStorage,
    RedisStorage
)
from agenticx.storage.vectordb_storages.base import VectorRecord
from agenticx.retrieval import (
    HybridRetriever,
    GraphRetriever,
    GraphVectorConfig,
    VectorRetriever,
    BM25Retriever,
    AutoRetriever,
    Reranker,
    QueryAnalysisAgent,
    RetrievalAgent
)
from agenticx.llms import LlmFactory

# å¯¼å…¥æœ¬åœ°æ¨¡å—
from prompt_manager import PromptManager

# åˆ›å»º Rich Console å®ä¾‹
console = Console() if Console else None

# ANSI é¢œè‰²ä»£ç ï¼ˆä¿ç•™ä½œä¸ºåå¤‡ï¼‰
class Colors:
    RESET = '\033[0m'
    BOLD = '\033[1m'
    DIM = '\033[2m'
    
    # åŸºç¡€é¢œè‰²
    BLACK = '\033[30m'
    RED = '\033[31m'
    GREEN = '\033[32m'
    YELLOW = '\033[33m'
    BLUE = '\033[34m'
    MAGENTA = '\033[35m'
    CYAN = '\033[36m'
    WHITE = '\033[37m'
    
    # äº®è‰²
    BRIGHT_BLACK = '\033[90m'
    BRIGHT_RED = '\033[91m'
    BRIGHT_GREEN = '\033[92m'
    BRIGHT_YELLOW = '\033[93m'
    BRIGHT_BLUE = '\033[94m'
    BRIGHT_MAGENTA = '\033[95m'
    BRIGHT_CYAN = '\033[96m'
    BRIGHT_WHITE = '\033[97m'

def print_thinking(message: str):
    """æ˜¾ç¤ºAIæ€è€ƒè¿‡ç¨‹ï¼ˆç™½è‰²ç‚¹ï¼‰"""
    if console:
        console.print(f"â— {message}", style="white dim")
    else:
        print(f"{Colors.WHITE}â— {Colors.DIM}{message}{Colors.RESET}")

def print_action(message: str):
    """æ˜¾ç¤ºå·¥å…·è°ƒç”¨ï¼ˆç»¿è‰²ç‚¹ï¼‰"""
    if console:
        console.print(f"â— {message}", style="green")
    else:
        print(f"{Colors.BRIGHT_GREEN}â— {message}{Colors.RESET}")

def print_error(message: str):
    """æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯ï¼ˆçº¢è‰²ï¼‰"""
    if console:
        console.print(f"â— {message}", style="bright_red bold")
    else:
        print(f"{Colors.BRIGHT_RED}â— {message}{Colors.RESET}")

def print_success(message: str):
    """æ˜¾ç¤ºæˆåŠŸä¿¡æ¯ï¼ˆç»¿è‰²ç‚¹ï¼‰"""
    if console:
        console.print(f"â— {message}", style="bright_green bold")
    else:
        print(f"{Colors.BRIGHT_GREEN}â— {message}{Colors.RESET}")

def print_info(message: str):
    """æ˜¾ç¤ºä¿¡æ¯ï¼ˆç™½è‰²ç‚¹ï¼‰"""
    if console:
        console.print(f"â— {message}", style="white")
    else:
        print(f"{Colors.WHITE}â— {message}{Colors.RESET}")

def print_mode_selection(message: str):
    """æ˜¾ç¤ºæ¨¡å¼é€‰æ‹©ï¼ˆæ©™è‰²ç‚¹ï¼‰"""
    if console:
        console.print(f"â— {message}", style="bright_yellow bold")
    else:
        print(f"{Colors.BRIGHT_YELLOW}â— {message}{Colors.RESET}")

def print_welcome():
    """æ˜¾ç¤ºæ¬¢è¿ç•Œé¢"""
    # AgenticX-GraphRAG ASCII Logo
    graphrag_logo = """

 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—
â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â• â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘      â•šâ–ˆâ–ˆâ–ˆâ•”â• 
â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘      â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— 
â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•—
â•šâ•â•  â•šâ•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•â•   â•šâ•â•   â•šâ•â• â•šâ•â•â•â•â•â•â•šâ•â•  â•šâ•â•

   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— 
  â–ˆâ–ˆâ•”â•â•â•â•â• â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â• 
  â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•—
  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â• â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘
  â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
   â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•     â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â• â•šâ•â•â•â•â•â• 
                                                                      
    """
    
    if console and Panel:
        # ä½¿ç”¨ Rich æ˜¾ç¤ºæ´»åŠ›æ©™è‰²ä¸»é¢˜çš„ logo å’Œä¿¡æ¯
        console.print(graphrag_logo, style="bold orange1")
        
        # ç¯å¢ƒé…ç½®ä¿¡æ¯
        api_key = os.getenv('BAILIAN_API_KEY', 'sk-***')
        api_key_display = f"{api_key[:8]}..." if len(api_key) > 8 else api_key
        
        console.print("â— æ™ºèƒ½çŸ¥è¯†å›¾è°±é—®ç­”ç³»ç»Ÿ:", style="bold orange1")
        console.print("  â¿  æ–‡æ¡£è§£æ + çŸ¥è¯†å›¾è°±æ„å»º + æ··åˆæ£€ç´¢ + æ™ºèƒ½é—®ç­”", style="dim")
        console.print("  â¿  æ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼ï¼šPDFã€Wordã€PPTã€TXT", style="dim")
        console.print("  â¿  å¤šè·³æ¨ç†ã€å®ä½“å…³ç³»æŸ¥è¯¢ã€ç¤¾åŒºå‘ç°\n", style="dim")
        
        console.print("â— ç¯å¢ƒé…ç½®:", style="bold orange1")
        console.print(f"  â¿  API Key: {api_key_display}", style="dim")
        console.print(f"  â¿  å·¥ä½œç›®å½•: {os.getcwd()}", style="dim")
        console.print(f"  â¿  é…ç½®æ–‡ä»¶: configs.yml\n", style="dim")

    elif boxen:
        # ä½¿ç”¨ pyboxen åˆ›å»ºæ¡†æ¡†
        print(graphrag_logo)
        content = (
            "ğŸš€ AgenticX GraphRAG æ™ºèƒ½çŸ¥è¯†å›¾è°±é—®ç­”ç³»ç»Ÿ\n\n"
            "åŠŸèƒ½ç‰¹æ€§:\n"
            "â— æ–‡æ¡£è§£æ + çŸ¥è¯†å›¾è°±æ„å»º + æ··åˆæ£€ç´¢ + æ™ºèƒ½é—®ç­”\n"
            "â— æ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼ï¼šPDFã€Wordã€PPTã€TXT\n"
            "â— å¤šè·³æ¨ç†ã€å®ä½“å…³ç³»æŸ¥è¯¢ã€ç¤¾åŒºå‘ç°\n\n"
            "ç¯å¢ƒé…ç½®:\n"
            f"â— API Key: {os.getenv('BAILIAN_API_KEY', 'sk-***')[:8]}...\n"
            f"â— å·¥ä½œç›®å½•: {os.getcwd()}\n"
            f"â— é…ç½®æ–‡ä»¶: configs.yml"
        )
        print(boxen(
            content,
            title="AgenticX-GraphRAG",
            title_alignment="center",
            style="rounded",
            color="orange",
            padding=1
        ))
    else:
        # åå¤‡æ–¹æ¡ˆï¼šä½¿ç”¨åŸå§‹çš„ ASCII è‰ºæœ¯
        print(graphrag_logo)
        print(f"""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸš€ AgenticX GraphRAG æ™ºèƒ½çŸ¥è¯†å›¾è°±é—®ç­”ç³»ç»Ÿ                    â”‚
â”‚                                                             â”‚
â”‚ åŠŸèƒ½ç‰¹æ€§:                                                   â”‚
â”‚ â— æ–‡æ¡£è§£æ + çŸ¥è¯†å›¾è°±æ„å»º + æ··åˆæ£€ç´¢ + æ™ºèƒ½é—®ç­”              â”‚
â”‚ â— æ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼ï¼šPDFã€Wordã€PPTã€TXT                     â”‚
â”‚ â— å¤šè·³æ¨ç†ã€å®ä½“å…³ç³»æŸ¥è¯¢ã€ç¤¾åŒºå‘ç°                          â”‚
â”‚                                                             â”‚
â”‚ ç¯å¢ƒé…ç½®:                                                   â”‚
â”‚ â— API Key: {os.getenv('BAILIAN_API_KEY', 'sk-***')[:8]}...{' ' * (43 - len(os.getenv('BAILIAN_API_KEY', 'sk-***')[:8]))} â”‚
â”‚ â— å·¥ä½œç›®å½•: {os.getcwd():<51} â”‚
â”‚ â— é…ç½®æ–‡ä»¶: configs.yml{' ' * 42} â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")

def print_help():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
    if console and Table and box:
        # ä½¿ç”¨ Rich åˆ›å»ºç¾è§‚çš„å¸®åŠ©è¡¨æ ¼
        table = Table(title="[bold orange1]å¯ç”¨å‘½ä»¤[/bold orange1]", box=box.ROUNDED)
        table.add_column("å‘½ä»¤", style="bold bright_yellow", width=12)
        table.add_column("æè¿°", style="white")
        
        table.add_row("/help", "æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯")
        table.add_row("/clear", "æ¸…å±")
        table.add_row("/mode", "é€‰æ‹©è¿è¡Œæ¨¡å¼")
        table.add_row("/data", "é€‰æ‹©æ–‡æ¡£è·¯å¾„")
        table.add_row("/rebuild", "é‡æ–°æ„å»ºçŸ¥è¯†åº“")
        table.add_row("/exit", "é€€å‡ºç¨‹åº")
        table.add_row("", "")
        table.add_row("[dim]ç›´æ¥è¾“å…¥[/dim]", "[dim]è¾“å…¥é—®é¢˜å¼€å§‹æ™ºèƒ½é—®ç­”[/dim]")
        
        console.print(table)
    elif boxen:
        # ä½¿ç”¨ pyboxen åˆ›å»ºå¸®åŠ©æ¡†
        content = (
            "å¯ç”¨å‘½ä»¤:\n\n"
            "/help     æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯\n"
            "/clear    æ¸…å±\n"
            "/mode     é€‰æ‹©è¿è¡Œæ¨¡å¼\n"
            "/data     é€‰æ‹©æ–‡æ¡£è·¯å¾„\n"
            "/rebuild  é‡æ–°æ„å»ºçŸ¥è¯†åº“\n"
            "/exit     é€€å‡ºç¨‹åº\n\n"
            "ç›´æ¥è¾“å…¥é—®é¢˜å¼€å§‹æ™ºèƒ½é—®ç­”"
        )
        print(boxen(
            content,
            title="å¸®åŠ©",
            style="rounded",
            color="orange",
            padding=1
        ))
    else:
        # åå¤‡æ–¹æ¡ˆ
        print(f"""
{Colors.BOLD}å¯ç”¨å‘½ä»¤:{Colors.RESET}

/help     æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
/clear    æ¸…å±
/mode     é€‰æ‹©è¿è¡Œæ¨¡å¼
/data     é€‰æ‹©æ–‡æ¡£è·¯å¾„
/rebuild  é‡æ–°æ„å»ºçŸ¥è¯†åº“
/exit     é€€å‡ºç¨‹åº

ç›´æ¥è¾“å…¥é—®é¢˜å¼€å§‹æ™ºèƒ½é—®ç­”
""")

def scan_data_directories() -> Dict[str, List[Dict[str, Any]]]:
    """æ‰«ææ•°æ®ç›®å½•ï¼Œè¿”å›æ–‡ä»¶ä¿¡æ¯"""
    data_dirs = ["data", "data2"]
    file_info = {}
    
    for data_dir in data_dirs:
        dir_path = Path(data_dir)
        if dir_path.exists():
            files = []
            for file_path in dir_path.iterdir():
                if file_path.is_file():
                    stat = file_path.stat()
                    files.append({
                        "name": file_path.name,
                        "path": str(file_path),
                        "size": stat.st_size,
                        "size_mb": round(stat.st_size / (1024 * 1024), 2),
                        "type": file_path.suffix.lower(),
                        "modified": datetime.fromtimestamp(stat.st_mtime).strftime("%Y-%m-%d %H:%M")
                    })
            file_info[data_dir] = files
    
    return file_info

def display_data_selection() -> str:
    """æ˜¾ç¤ºæ•°æ®ç›®å½•é€‰æ‹©ç•Œé¢"""
    file_info = scan_data_directories()
    
    if console and Table and box:
        # ä½¿ç”¨ Rich æ˜¾ç¤ºæ–‡ä»¶é€‰æ‹©è¡¨æ ¼
        table = Table(title="[bold orange1]ğŸ“ å¯ç”¨æ–‡æ¡£ç›®å½•[/bold orange1]", box=box.ROUNDED)
        table.add_column("ç›®å½•", style="bold orange1", width=10)
        table.add_column("æ–‡ä»¶æ•°", style="bright_yellow", width=8)
        table.add_column("æ–‡ä»¶åˆ—è¡¨", style="white")
        
        for dir_name, files in file_info.items():
            file_list = []
            for file in files:
                file_list.append(f"{file['name']} ({file['size_mb']}MB)")
            
            table.add_row(
                dir_name,
                str(len(files)),
                "\n".join(file_list) if file_list else "æ— æ–‡ä»¶"
            )
        
        console.print(table)
        
        # æ˜¾ç¤ºè¯¦ç»†æ–‡ä»¶ä¿¡æ¯
        for dir_name, files in file_info.items():
            if files:
                detail_table = Table(title=f"[bold orange1]{dir_name}/ ç›®å½•è¯¦æƒ…[/bold orange1]", box=box.SIMPLE)
                detail_table.add_column("æ–‡ä»¶å", style="cyan")
                detail_table.add_column("å¤§å°", style="bright_yellow")
                detail_table.add_column("ç±»å‹", style="magenta")
                detail_table.add_column("ä¿®æ”¹æ—¶é—´", style="dim")
                
                for file in files:
                    detail_table.add_row(
                        file['name'],
                        f"{file['size_mb']} MB",
                        file['type'].upper(),
                        file['modified']
                    )
                
                console.print(detail_table)
                console.print()
    
    # é€‰æ‹©ç›®å½•
    available_dirs = [dir_name for dir_name, files in file_info.items() if files]
    
    if not available_dirs:
        print_error("æœªæ‰¾åˆ°å¯ç”¨çš„æ–‡æ¡£ç›®å½•")
        return "data"  # é»˜è®¤è¿”å› data ç›®å½•
    
    if len(available_dirs) == 1:
        print_info(f"è‡ªåŠ¨é€‰æ‹©å”¯ä¸€å¯ç”¨ç›®å½•: {available_dirs[0]}")
        return available_dirs[0]
    
    # å¤šä¸ªç›®å½•æ—¶è®©ç”¨æˆ·é€‰æ‹©
    if console and Prompt:
        choices = "/".join(available_dirs)
        selected = Prompt.ask(
            f"è¯·é€‰æ‹©æ–‡æ¡£ç›®å½• ({choices})",
            choices=available_dirs,
            default=available_dirs[0]
        )
        return selected
    else:
        print(f"å¯ç”¨ç›®å½•: {', '.join(available_dirs)}")
        while True:
            choice = input(f"è¯·é€‰æ‹©ç›®å½• ({'/'.join(available_dirs)}): ").strip()
            if choice in available_dirs:
                return choice
            elif not choice and available_dirs:
                return available_dirs[0]
            print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

def select_run_mode() -> str:
    """é€‰æ‹©è¿è¡Œæ¨¡å¼"""
    if console and Panel and Text and box:
        mode_text = Text()
        mode_text.append("1. Full Mode", style="bold green")
        mode_text.append(" - å®Œæ•´æµç¨‹ï¼ˆæ–‡æ¡£è§£æ + çŸ¥è¯†åº“æ„å»º + é—®ç­”ï¼‰\n", style="white")
        mode_text.append("   é€‚ç”¨: é¦–æ¬¡è¿è¡Œæˆ–éœ€è¦é‡æ–°å¤„ç†æ–‡æ¡£\n", style="dim")
        
        mode_text.append("2. Build Mode", style="bold orange1")
        mode_text.append(" - ä»…æ„å»ºæ¨¡å¼ï¼ˆæ–‡æ¡£è§£æ + çŸ¥è¯†åº“æ„å»ºï¼‰\n", style="white")
        mode_text.append("   é€‚ç”¨: åªéœ€è¦æ„å»ºçŸ¥è¯†åº“ï¼Œä¸å¯åŠ¨é—®ç­”\n", style="dim")
        
        mode_text.append("3. QA Mode", style="bold magenta")
        mode_text.append(" - ä»…é—®ç­”æ¨¡å¼ï¼ˆä½¿ç”¨å·²æœ‰çŸ¥è¯†åº“ï¼‰\n", style="white")
        mode_text.append("   é€‚ç”¨: çŸ¥è¯†åº“å·²å­˜åœ¨ï¼Œç›´æ¥å¼€å§‹é—®ç­”\n", style="dim")
        
        panel = Panel(
            mode_text,
            title="é€‰æ‹©è¿è¡Œæ¨¡å¼",
            border_style="orange1",
            box=box.ROUNDED,
            padding=(1, 2)
        )
        console.print(panel)
    elif boxen:
        content = (
            "é€‰æ‹©è¿è¡Œæ¨¡å¼:\n\n"
            "1. Full Mode - å®Œæ•´æµç¨‹ï¼ˆæ–‡æ¡£è§£æ + çŸ¥è¯†åº“æ„å»º + é—®ç­”ï¼‰\n"
            "   é€‚ç”¨: é¦–æ¬¡è¿è¡Œæˆ–éœ€è¦é‡æ–°å¤„ç†æ–‡æ¡£\n\n"
            "2. Build Mode - ä»…æ„å»ºæ¨¡å¼ï¼ˆæ–‡æ¡£è§£æ + çŸ¥è¯†åº“æ„å»ºï¼‰\n"
            "   é€‚ç”¨: åªéœ€è¦æ„å»ºçŸ¥è¯†åº“ï¼Œä¸å¯åŠ¨é—®ç­”\n\n"
            "3. QA Mode - ä»…é—®ç­”æ¨¡å¼ï¼ˆä½¿ç”¨å·²æœ‰çŸ¥è¯†åº“ï¼‰\n"
            "   é€‚ç”¨: çŸ¥è¯†åº“å·²å­˜åœ¨ï¼Œç›´æ¥å¼€å§‹é—®ç­”"
        )
        print(boxen(
            content,
            title="è¿è¡Œæ¨¡å¼é€‰æ‹©",
            style="rounded",
            color="orange",
            padding=1
        ))
    else:
        print("""
é€‰æ‹©è¿è¡Œæ¨¡å¼:

1. Full Mode - å®Œæ•´æµç¨‹ï¼ˆæ–‡æ¡£è§£æ + çŸ¥è¯†åº“æ„å»º + é—®ç­”ï¼‰
   é€‚ç”¨: é¦–æ¬¡è¿è¡Œæˆ–éœ€è¦é‡æ–°å¤„ç†æ–‡æ¡£

2. Build Mode - ä»…æ„å»ºæ¨¡å¼ï¼ˆæ–‡æ¡£è§£æ + çŸ¥è¯†åº“æ„å»ºï¼‰
   é€‚ç”¨: åªéœ€è¦æ„å»ºçŸ¥è¯†åº“ï¼Œä¸å¯åŠ¨é—®ç­”

3. QA Mode - ä»…é—®ç­”æ¨¡å¼ï¼ˆä½¿ç”¨å·²æœ‰çŸ¥è¯†åº“ï¼‰
   é€‚ç”¨: çŸ¥è¯†åº“å·²å­˜åœ¨ï¼Œç›´æ¥å¼€å§‹é—®ç­”
""")
    
    mode_map = {"1": "full", "2": "build", "3": "qa"}
    
    if console and Prompt:
        choice = Prompt.ask(
            "è¯·é€‰æ‹©æ¨¡å¼",
            choices=["1", "2", "3"],
            default="1"
        )
        return mode_map[choice]
    else:
        while True:
            try:
                choice = input("\nè¯·é€‰æ‹©æ¨¡å¼ (1-3): ").strip()
                if choice == '' or choice == '1':
                    return 'full'
                elif choice == '2':
                    return 'build'
                elif choice == '3':
                    return 'qa'
                else:
                    print("è¯·è¾“å…¥ 1ã€2 æˆ– 3")
            except (EOFError, KeyboardInterrupt):
                return 'full'


class AgenticXGraphRAGDemo:
    """AgenticX GraphRAG æ¼”ç¤ºç³»ç»Ÿä¸»ç±»"""
    
    def __init__(self, config_path: str = "configs.yml", mode: str = "full"):
        """åˆå§‹åŒ–æ¼”ç¤ºç³»ç»Ÿ"""
        self.config_path = config_path
        self.mode = mode  # è¿è¡Œæ¨¡å¼ï¼šfull æˆ– qa
        self.config = self._load_config()
        self.logger = self._setup_logging()
        
        # æ ¸å¿ƒç»„ä»¶
        self.llm_client = None
        self.embedding_router = None
        self.storage_manager = None
        self.knowledge_graph = None
        self.retriever = None
        
        # æç¤ºè¯ç®¡ç†å™¨
        self.prompt_manager = PromptManager("prompts")
        
        # æ•°æ®è·¯å¾„
        self.data_dir = Path("./data")
        self.workspace_dir = Path(self.config['system']['workspace']['base_dir'])
        
        self.logger.info(f"AgenticX GraphRAG æ¼”ç¤ºç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ (æ¨¡å¼: {self.mode})")
    
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        config_file = Path(self.config_path)
        if not config_file.exists():
            # å¦‚æœå½“å‰ç›®å½•æ²¡æœ‰é…ç½®æ–‡ä»¶ï¼Œå°è¯•ä»æ–‡æ¡£ç›®å½•åŠ è½½
            config_file = Path(".trae/documents/configs.yml")
            
        if not config_file.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {self.config_path}")
            
        with open(config_file, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
            
        # ç¯å¢ƒå˜é‡æ›¿æ¢
        self._replace_env_vars(config)
        
        return config
    
    def _replace_env_vars(self, obj: Any) -> None:
        """é€’å½’æ›¿æ¢é…ç½®ä¸­çš„ç¯å¢ƒå˜é‡"""
        if isinstance(obj, dict):
            for key, value in obj.items():
                if isinstance(value, str) and value.startswith('${') and value.endswith('}'):
                    env_var = value[2:-1]
                    obj[key] = os.getenv(env_var, value)
                else:
                    self._replace_env_vars(value)
        elif isinstance(obj, list):
            for item in obj:
                self._replace_env_vars(item)
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        # è¿‡æ»¤æ‰ç‰¹å®šçš„è­¦å‘Š
        warnings.filterwarnings("ignore", category=DeprecationWarning, module="importlib._bootstrap")
        warnings.filterwarnings("ignore", message=".*datetime.datetime.utcnow.*")
        warnings.filterwarnings("ignore", message=".*SwigPy.*")
        
        log_config = self.config.get('monitoring', {}).get('logging', {})
        
        # åˆ›å»ºæ—¥å¿—ç›®å½•
        log_dir = Path(self.config['system']['workspace']['logs_dir'])
        log_dir.mkdir(parents=True, exist_ok=True)
        
        # ç§»é™¤é»˜è®¤çš„loguruå¤„ç†å™¨
        logger.remove()
        
        # é…ç½®æ§åˆ¶å°è¾“å‡º
        logger.add(
            sys.stdout,
            level=log_config.get('level', 'DEBUG'),  # ä¸´æ—¶å¯ç”¨DEBUGçº§åˆ«
            format="<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
            colorize=True
        )
        
        # é…ç½®æ–‡ä»¶è¾“å‡º
        logger.add(
            log_dir / "agenticx_graphrag.log",
            level=log_config.get('level', 'INFO'),
            format="{time:YYYY-MM-DD HH:mm:ss.SSS} | {level: <8} | {name}:{function}:{line} - {message}",
            rotation="10 MB",
            retention="7 days",
            compression="zip"
        )
        
        return logger
    
    async def initialize_components(self) -> None:
        """åˆå§‹åŒ–æ‰€æœ‰æ ¸å¿ƒç»„ä»¶"""
        self.logger.info("å¼€å§‹åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶...")
        
        # 1. åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
        await self._initialize_llm()
        
        # 2. åˆå§‹åŒ–åµŒå…¥æœåŠ¡
        await self._initialize_embeddings()
        
        # 3. åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨
        await self._initialize_storage()
        
        # 4. åˆå§‹åŒ–æ£€ç´¢å™¨
        await self._initialize_retriever()
        
        self.logger.info("ç³»ç»Ÿç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
    
    async def _initialize_llm(self) -> None:
        """åˆå§‹åŒ– LLM å®¢æˆ·ç«¯"""
        from agenticx.knowledge.graphers.config import LLMConfig
        
        llm_config_dict = self.config['llm']
        provider = llm_config_dict.get('provider', 'litellm')
        
        # æä¾›å•†ç±»å‹æ˜ å°„
        provider_type_mapping = {
            'openai': 'litellm',
            'anthropic': 'litellm', 
            'litellm': 'litellm',
            'bailian': 'bailian',
            'kimi': 'kimi'
        }
        
        llm_type = provider_type_mapping.get(provider, 'litellm')
        
        # å°†å­—å…¸é…ç½®è½¬æ¢ä¸º LLMConfig å¯¹è±¡
        llm_config = LLMConfig(
            type=llm_type,
            model=llm_config_dict.get('model'),
            api_key=llm_config_dict.get('api_key'),
            base_url=llm_config_dict.get('base_url'),
            provider=provider,
            timeout=llm_config_dict.get('timeout'),
            max_retries=llm_config_dict.get('retry_attempts'),  # é…ç½®æ–‡ä»¶ä¸­æ˜¯retry_attempts
            temperature=llm_config_dict.get('temperature'),
            max_tokens=llm_config_dict.get('max_tokens')
        )
        
        self.llm_client = LlmFactory.create_llm(llm_config)
        self.logger.info(f"LLMåˆå§‹åŒ–å®Œæˆ: {llm_config.provider}/{llm_config.model}")
    
    async def _initialize_embeddings(self) -> None:
        """åˆå§‹åŒ–åµŒå…¥æœåŠ¡è·¯ç”±å™¨"""
        embed_config = self.config['embeddings']
        
        # åˆ›å»ºåµŒå…¥æä¾›å•†åˆ—è¡¨
        providers = []
        provider_names = []
        
        # æ ¹æ®é…ç½®çš„ä¼˜å…ˆçº§é¡ºåºæ·»åŠ æä¾›å•†
        router_config = embed_config.get('router', {})
        primary_provider = router_config.get('primary_provider', 'bailian')
        fallback_providers = router_config.get('fallback_providers', [])
        
        # æŒ‰ä¼˜å…ˆçº§é¡ºåºæ·»åŠ æä¾›å•†
        provider_order = [primary_provider] + fallback_providers
        
        for provider_name in provider_order:
            if provider_name == 'bailian' and 'bailian' in embed_config:
                config = embed_config['bailian']
                provider = BailianEmbeddingProvider(
                    api_key=config['api_key'],
                    model=config.get('model', 'text-embedding-v4'),
                    api_url=config.get('base_url'),
                    dimensions=config.get('dimensions', 1536),
                    batch_size=config.get('batch_size', 10)  # ä¿®å¤ï¼šæ·»åŠ batch_sizeå‚æ•°
                )
                providers.append(provider)
                provider_names.append('bailian')
                
            elif provider_name == 'openai' and 'openai' in embed_config:
                config = embed_config['openai']
                provider = OpenAIEmbeddingProvider(
                    api_key=config['api_key'],
                    model=config.get('model', 'text-embedding-3-small'),
                    base_url=config.get('base_url'),
                    dimensions=config.get('dimensions', 1536)
                )
                providers.append(provider)
                provider_names.append('openai')
                
            elif provider_name == 'siliconflow' and 'siliconflow' in embed_config:
                config = embed_config['siliconflow']
                provider = SiliconFlowEmbeddingProvider(
                    api_key=config['api_key'],
                    model=config.get('model', 'BAAI/bge-large-zh-v1.5'),
                    dimensions=config.get('dimensions', 1024)
                )
                providers.append(provider)
                provider_names.append('siliconflow')
        
        # åˆ›å»ºè·¯ç”±å™¨ï¼ˆåªä¼ å…¥providersåˆ—è¡¨ï¼‰
        self.embedding_router = EmbeddingRouter(providers=providers)
        
        self.logger.info(f"åµŒå…¥æœåŠ¡åˆå§‹åŒ–å®Œæˆ: {len(provider_names)}ä¸ªæä¾›å•†")

    async def _initialize_storage(self) -> None:
        """åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨"""
        from agenticx.storage import StorageConfig, StorageType
        
        storage_config = self.config['storage']
        configs = []
        
        # åŠ¨æ€è·å–åµŒå…¥ç»´åº¦
        embedding_dim = self.embedding_router.get_embedding_dim()
        self.logger.info(f"åŠ¨æ€è·å–çš„åµŒå…¥ç»´åº¦: {embedding_dim}")

        # é…ç½®å‘é‡å­˜å‚¨
        vector_config = storage_config['vector']
        if vector_config['provider'] == 'milvus':
            try:
                milvus_config = vector_config.get('milvus', {})
                # æ„å»ºextra_paramsï¼Œè¿‡æ»¤æ‰Noneå€¼
                # æ ¹æ®è¿è¡Œæ¨¡å¼å†³å®šæ˜¯å¦æ¸…ç†æ•°æ®
                recreate_if_exists = self.mode in ["full", "build"]  # fullå’Œbuildæ¨¡å¼é‡æ–°åˆ›å»ºï¼Œqaæ¨¡å¼ä¿ç•™
                
                extra_params = {
                    'dimension': embedding_dim,
                    'collection_name': milvus_config.get('collection_name', 'agenticx_graphrag'),
                    'database': milvus_config.get('database', 'default'),
                    'recreate_if_exists': recreate_if_exists  # æ ¹æ®æ¨¡å¼å†³å®šæ˜¯å¦é‡æ–°åˆ›å»º
                }
                
                # åªåœ¨usernameå’Œpasswordä¸ä¸ºNoneæ—¶æ‰æ·»åŠ 
                username = milvus_config.get('username')
                password = milvus_config.get('password')
                if username is not None:
                    extra_params['username'] = username
                if password is not None:
                    extra_params['password'] = password
                
                # ç®€åŒ–æ—¥å¿—ï¼šåªè®°å½•å…³é”®ä¿¡æ¯
                self.logger.debug(f"Milvusé…ç½®: {milvus_config.get('host', 'localhost')}:{milvus_config.get('port', 19530)}")
                
                configs.append(StorageConfig(
                    storage_type=StorageType.MILVUS,
                    host=milvus_config.get('host', 'localhost'),
                    port=milvus_config.get('port', 19530),
                    extra_params=extra_params
                ))
            except Exception as e:
                self.logger.error(f"âŒ é…ç½®Milvuså­˜å‚¨å¤±è´¥: {e}")
                self.logger.warning(f"âš ï¸ Milvusé…ç½®å¤±è´¥: {e}ï¼Œå›é€€åˆ°Chroma")
                # å›é€€åˆ°Chroma
                chroma_config = vector_config.get('chroma', {})
                configs.append(StorageConfig(
                    storage_type=StorageType.CHROMA,
                    extra_params={
                        'dimension': embedding_dim,
                        'persist_directory': chroma_config.get('persist_directory', './storage/chroma'),
                        'collection_name': chroma_config.get('collection_name', 'agenticx_graphrag')
                    }
                ))
                self.logger.info("âœ… é…ç½®Chromaå‘é‡å­˜å‚¨ï¼ˆå›é€€ï¼‰")
        elif vector_config['provider'] == 'chroma':
            chroma_config = vector_config['chroma'].copy()
            configs.append(StorageConfig(
                storage_type=StorageType.CHROMA,
                extra_params={
                    'dimension': embedding_dim,
                    'persist_directory': chroma_config.get('persist_directory', './storage/chroma'),
                    'collection_name': chroma_config.get('collection_name', 'agenticx_graphrag')
                }
            ))
            self.logger.info("âœ… é…ç½®Chromaå‘é‡å­˜å‚¨")
        elif vector_config['provider'] == 'faiss':
            configs.append(StorageConfig(
                storage_type=StorageType.FAISS,
                extra_params={
                    'dimension': embedding_dim,  # ä½¿ç”¨åŠ¨æ€è·å–çš„ç»´åº¦
                    'index_path': './storage/faiss_index'
                }
            ))
            self.logger.info("âœ… é…ç½®FAISSå‘é‡å­˜å‚¨")
        
        # é…ç½®å›¾å­˜å‚¨
        graph_config = storage_config['graph']
        if graph_config['provider'] == 'neo4j':
            neo4j_config = graph_config['neo4j'].copy()
            
            # å¤„ç†URIæ ¼å¼çš„é…ç½®
            uri = neo4j_config.get('uri', 'bolt://localhost:7687')
            # å°†å®¹å™¨åneo4jæ›¿æ¢ä¸ºlocalhostï¼ˆç”¨äºå¤–éƒ¨è®¿é—®ï¼‰
            if 'neo4j:' in uri:
                uri = uri.replace('neo4j:', 'localhost:')
            
            configs.append(StorageConfig(
                storage_type=StorageType.NEO4J,
                connection_string=uri,
                username=neo4j_config.get('username', 'neo4j'),
                password=neo4j_config.get('password', None),
                database=neo4j_config.get('database', 'neo4j'),
                extra_params={
                    'max_connection_lifetime': neo4j_config.get('max_connection_lifetime', 3600),
                    'max_connection_pool_size': neo4j_config.get('max_connection_pool_size', 50),
                    'connection_acquisition_timeout': neo4j_config.get('connection_acquisition_timeout', 60)
                }
            ))
        
        # é…ç½®é”®å€¼å­˜å‚¨
        kv_config = storage_config['key_value']
        if kv_config['provider'] == 'redis':
            redis_config = kv_config['redis'].copy()
            configs.append(StorageConfig(
                storage_type=StorageType.REDIS,
                host=redis_config.pop('host', 'localhost'),
                port=redis_config.pop('port', 6379),
                password=redis_config.pop('password', None),
                database=redis_config.pop('database', 0),
                **redis_config
            ))
        elif kv_config['provider'] == 'sqlite':
            sqlite_config = kv_config.get('sqlite', {})
            configs.append(StorageConfig(
                storage_type=StorageType.SQLITE,
                connection_string=sqlite_config.get('database_path', './storage/cache.db')
            ))
            self.logger.info("âœ… é…ç½®SQLiteé”®å€¼å­˜å‚¨")
        
        # åˆ›å»ºå­˜å‚¨ç®¡ç†å™¨
        self.storage_manager = StorageManager(configs=configs)
        await self.storage_manager.initialize()
        
        # è°ƒè¯•ï¼šæ£€æŸ¥é”®å€¼å­˜å‚¨æ˜¯å¦å¯ç”¨
        kv_storage = await self.storage_manager.get_key_value_storage('default')
        if kv_storage:
            self.logger.debug(f"é”®å€¼å­˜å‚¨: {type(kv_storage).__name__}")
        else:
            self.logger.warning("âš ï¸ é”®å€¼å­˜å‚¨ä¸å¯ç”¨")
    
    async def _initialize_retriever(self) -> None:
        """åˆå§‹åŒ–æ£€ç´¢å™¨"""
        from agenticx.storage import StorageType
        
        retrieval_config = self.config['retrieval']
        
        # ğŸ”§ ç¡®ä¿æ–‡æ¡£å‘é‡å­˜å‚¨å®ä¾‹å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
        if not hasattr(self, '_document_vector_storage') or not self._document_vector_storage:
            from agenticx.storage.vectordb_storages.milvus import MilvusStorage
            storage_config = self.config['storage']['vector']['milvus']
            self._document_vector_storage = MilvusStorage(
                dimension=1024,  # ä½¿ç”¨åµŒå…¥ç»´åº¦
                host=storage_config['host'],
                port=storage_config['port'],
                collection_name=storage_config['collection_name'],  # ä½¿ç”¨æ–‡æ¡£ä¸“ç”¨é›†åˆå
                database=storage_config.get('database', 'default'),
                username=storage_config.get('username'),
                password=storage_config.get('password'),
                recreate_if_exists=False  # æ£€ç´¢å™¨åˆå§‹åŒ–æ—¶ä¸é‡æ–°åˆ›å»º
            )
        
        # åˆ›å»ºå‘é‡æ£€ç´¢å™¨
        vector_retriever = VectorRetriever(
            tenant_id="default",
            vector_storage=self._document_vector_storage,  # ä½¿ç”¨ç»Ÿä¸€çš„æ–‡æ¡£å‘é‡å­˜å‚¨å®ä¾‹
            embedding_provider=self.embedding_router,
            **retrieval_config.get('vector', {})
        )
        
        self.logger.info(f"ğŸ“„ æ–‡æ¡£æ£€ç´¢å­˜å‚¨é›†åˆ: {storage_config['collection_name']}")
        
        # åˆ›å»ºBM25æ£€ç´¢å™¨
        bm25_retriever = BM25Retriever(
            tenant_id="default",
            **retrieval_config.get('bm25', {})
        )
        
        # åˆ›å»ºå¢å¼ºçš„å›¾æ£€ç´¢å™¨ï¼ˆæ”¯æŒå‘é‡ç´¢å¼•ï¼‰
        graph_storage = self.storage_manager.get_storage(StorageType.NEO4J)
        vector_storage = self.storage_manager.get_storage(StorageType.MILVUS)
        
        # ğŸ”§ ç¡®ä¿å›¾å‘é‡å­˜å‚¨å®ä¾‹å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
        if not hasattr(self, '_graph_vector_storage') or not self._graph_vector_storage:
            from agenticx.storage.vectordb_storages.milvus import MilvusStorage
            storage_config = self.config['storage']['vector']['milvus']
            # æ ¹æ®è¿è¡Œæ¨¡å¼å†³å®šæ˜¯å¦é‡æ–°åˆ›å»ºå›¾å‘é‡é›†åˆ
            recreate_graph_collection = self.mode in ["full", "build"]
            self._graph_vector_storage = MilvusStorage(
                dimension=1024,  # ä½¿ç”¨åµŒå…¥ç»´åº¦
                host=storage_config['host'],
                port=storage_config['port'],
                collection_name=storage_config['graph_collection_name'],  # ä½¿ç”¨å›¾ä¸“ç”¨é›†åˆå
                database=storage_config.get('database', 'default'),
                username=storage_config.get('username'),
                password=storage_config.get('password'),
                recreate_if_exists=recreate_graph_collection  # ğŸ”§ ä¿®å¤ï¼šæ ¹æ®æ¨¡å¼å†³å®šæ˜¯å¦é‡æ–°åˆ›å»º
            )
        
        # é…ç½®å›¾å‘é‡ç´¢å¼•
        graph_vector_config = GraphVectorConfig(
            enable_vector_indexing=True,
            **retrieval_config.get('graph', {}).get('vector_config', {})
        )
        
        graph_retriever = GraphRetriever(
            tenant_id="default",
            graph_storage=graph_storage,
            vector_storage=self._graph_vector_storage,  # ä½¿ç”¨ç»Ÿä¸€çš„å›¾å‘é‡å­˜å‚¨å®ä¾‹
            embedding_provider=self.embedding_router,
            vector_config=graph_vector_config,
            **retrieval_config.get('graph', {})
        )
        
        self.logger.info(f"ğŸ”— å›¾å‘é‡å­˜å‚¨é›†åˆ: {storage_config['graph_collection_name']}")
        
        # åˆ›å»ºä¸‰è·¯æ··åˆæ£€ç´¢å™¨
        from agenticx.retrieval.hybrid_retriever import HybridConfig
        hybrid_config = HybridConfig(**retrieval_config.get('hybrid', {}))
        self.retriever = HybridRetriever(
            vector_retriever=vector_retriever,
            bm25_retriever=bm25_retriever,
            graph_retriever=graph_retriever,  # é›†æˆå›¾æ£€ç´¢å™¨
            config=hybrid_config
        )
        
        # å­˜å‚¨å›¾æ£€ç´¢å™¨ä»¥å¤‡åç”¨
        self.graph_retriever = graph_retriever
        
        # å¦‚æœé…ç½®äº†é‡æ’åºå™¨ï¼Œæ·»åŠ é‡æ’åºå™¨
        if 'reranker' in retrieval_config:
            reranker = Reranker(retrieval_config['reranker'])
            # æ³¨æ„ï¼šHybridRetriever å¯èƒ½æ²¡æœ‰ set_reranker æ–¹æ³•ï¼Œè¿™é‡Œå…ˆæ³¨é‡Šæ‰
            # self.retriever.set_reranker(reranker)
        
        self.logger.debug("æ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def validate_data_path(self) -> List[Path]:
        """éªŒè¯æ•°æ®è·¯å¾„å¹¶è¿”å›æ–‡ä»¶åˆ—è¡¨"""
        self.logger.info(f"éªŒè¯æ•°æ®è·¯å¾„: {self.data_dir}")
        
        if not self.data_dir.exists():
            raise FileNotFoundError(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.data_dir}")
        
        # æ”¯æŒçš„æ–‡ä»¶ç±»å‹
        supported_extensions = {'.pdf', '.txt', '.json', '.csv', '.md', '.doc', '.docx', '.ppt', '.pptx'}
        
        # æ‰«ææ–‡ä»¶
        files = []
        for file_path in self.data_dir.rglob('*'):
            if file_path.is_file() and file_path.suffix.lower() in supported_extensions:
                files.append(file_path)
        
        if not files:
            raise ValueError(f"æ•°æ®ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {supported_extensions}")
        
        self.logger.info(f"æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶: {[f.name for f in files]}")
        return files
    
    async def load_documents(self, file_paths: List[Path]) -> List[Document]:
        """åŠ è½½æ–‡æ¡£"""
        self.logger.info(f"å¼€å§‹åŠ è½½ {len(file_paths)} ä¸ªæ–‡æ¡£...")
        
        documents = []
        reader_config = self.config['knowledge']['readers']
        
        for file_path in file_paths:
            try:
                # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©è¯»å–å™¨
                if file_path.suffix.lower() == '.pdf' and reader_config['pdf']['enabled']:
                    pdf_config = reader_config['pdf'].copy()
                    pdf_config.pop('enabled', None)  # ç§»é™¤enabledå­—æ®µ
                    reader = PDFReader(**pdf_config)
                elif file_path.suffix.lower() in ['.txt', '.md'] and reader_config['text']['enabled']:
                    text_config = reader_config['text'].copy()
                    text_config.pop('enabled', None)  # ç§»é™¤enabledå­—æ®µ
                    self.logger.debug(f"TextReaderé…ç½®: {text_config}")
                    reader = TextReader(**text_config)
                elif file_path.suffix.lower() == '.json' and reader_config['json']['enabled']:
                    json_config = reader_config['json'].copy()
                    json_config.pop('enabled', None)  # ç§»é™¤enabledå­—æ®µ
                    reader = JSONReader(**json_config)
                elif file_path.suffix.lower() == '.csv' and reader_config['csv']['enabled']:
                    csv_config = reader_config['csv'].copy()
                    csv_config.pop('enabled', None)  # ç§»é™¤enabledå­—æ®µ
                    reader = CSVReader(**csv_config)
                elif file_path.suffix.lower() in ['.doc', '.docx'] and reader_config.get('word', {}).get('enabled', True):
                    word_config = reader_config.get('word', {}).copy()
                    word_config.pop('enabled', None)  # ç§»é™¤enabledå­—æ®µ
                    reader = WordReader(**word_config)
                elif file_path.suffix.lower() in ['.ppt', '.pptx'] and reader_config.get('powerpoint', {}).get('enabled', True):
                    ppt_config = reader_config.get('powerpoint', {}).copy()
                    ppt_config.pop('enabled', None)  # ç§»é™¤enabledå­—æ®µ
                    reader = PowerPointReader(**ppt_config)
                else:
                    self.logger.warning(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹æˆ–å·²ç¦ç”¨: {file_path}")
                    continue
                
                # è¯»å–æ–‡æ¡£
                self.logger.debug(f"å¼€å§‹è¯»å–æ–‡æ¡£: {file_path}")
                result = await reader.read(str(file_path))
                self.logger.debug(f"è¯»å–ç»“æœç±»å‹: {type(result)}, å†…å®¹: {result if not isinstance(result, list) else f'åˆ—è¡¨é•¿åº¦: {len(result)}'}")
                
                # å¤„ç†è¿”å›ç»“æœï¼ˆå¯èƒ½æ˜¯å•ä¸ªæ–‡æ¡£æˆ–æ–‡æ¡£åˆ—è¡¨ï¼‰
                if isinstance(result, list):
                    # å¦‚æœè¿”å›çš„æ˜¯åˆ—è¡¨ï¼Œéå†æ¯ä¸ªæ–‡æ¡£
                    for doc in result:
                        documents.append(doc)
                        self.logger.info(f"æˆåŠŸåŠ è½½æ–‡æ¡£: {file_path.name} ({len(doc.content)} å­—ç¬¦)")
                else:
                    # å¦‚æœè¿”å›çš„æ˜¯å•ä¸ªæ–‡æ¡£
                    documents.append(result)
                    self.logger.info(f"æˆåŠŸåŠ è½½æ–‡æ¡£: {file_path.name} ({len(result.content)} å­—ç¬¦)")
                
            except Exception as e:
                self.logger.error(f"åŠ è½½æ–‡æ¡£å¤±è´¥ {file_path}: {e}")
                continue
        
        self.logger.info(f"æ–‡æ¡£åŠ è½½å®Œæˆ: {len(documents)}ä¸ªæ–‡æ¡£")
        return documents
    
    async def build_knowledge_graph(self, documents: List[Document]) -> None:
        """æ„å»ºçŸ¥è¯†å›¾è°±"""
        self.logger.info("å¼€å§‹æ„å»ºçŸ¥è¯†å›¾è°±")
        
        # æ‰“å°å…¥å‚ä¿¡æ¯
        doc_info = [f"{getattr(doc.metadata, 'title', None) or getattr(doc.metadata, 'name', 'Unknown')}({len(doc.content)}å­—ç¬¦)" for doc in documents]
        self.logger.info(f"è¾“å…¥æ–‡æ¡£: {len(documents)}ä¸ª - {', '.join(doc_info[:3])}{'...' if len(documents) > 3 else ''}")
        
        # ä¿å­˜documentsä»¥ä¾›å‘é‡ç´¢å¼•ä½¿ç”¨
        self.documents = documents
        
        # é…ç½® GraphRAG æ„é€ å™¨
        from agenticx.knowledge.graphers.config import LLMConfig, GraphRagConfig
        from agenticx.knowledge.base import ChunkingConfig
        
        graph_knowledge_config_dict = self.config['knowledge']['graph_knowledge']
        
        # æ‰“å°å…³é”®é…ç½®
        self.logger.info(f"é…ç½®å‚æ•°: extraction_method={graph_knowledge_config_dict.get('extraction_method', 'æœªè®¾ç½®')}, "
                        f"spo_batch_size={graph_knowledge_config_dict.get('spo_batch_size', 'æœªè®¾ç½®')}")
        
        # å°†å­—å…¸è½¬æ¢ä¸º GraphRagConfig å¯¹è±¡
        graph_knowledge_config = GraphRagConfig.from_dict(graph_knowledge_config_dict)
        llm_config_dict = self.config['llm']
        
        # è½¬æ¢ä¸º LLMConfig å¯¹è±¡
        provider = llm_config_dict.get('provider', 'litellm')
        
        # æä¾›å•†ç±»å‹æ˜ å°„
        provider_type_mapping = {
            'openai': 'litellm',
            'anthropic': 'litellm', 
            'litellm': 'litellm',
            'bailian': 'bailian',
            'kimi': 'kimi'
        }
        
        llm_type = provider_type_mapping.get(provider, 'litellm')
        
        # æ‰‹åŠ¨åˆ›å»º LLMConfigï¼Œç¡®ä¿ type å­—æ®µæ­£ç¡®
        llm_config = LLMConfig(
            type=llm_type,
            model=llm_config_dict.get('model'),
            api_key=llm_config_dict.get('api_key'),
            base_url=llm_config_dict.get('base_url'),
            provider=provider,
            timeout=llm_config_dict.get('timeout'),
            max_retries=llm_config_dict.get('retry_attempts'),  # é…ç½®æ–‡ä»¶ä¸­æ˜¯retry_attempts
            temperature=llm_config_dict.get('temperature'),
            max_tokens=llm_config_dict.get('max_tokens')
        )
        
        # åˆ›å»ºå¼ºæ¨¡å‹é…ç½®ï¼ˆç”¨äºæ–‡æ¡£åˆ†æå’ŒSchemaç”Ÿæˆï¼‰
        strong_model_dict = llm_config_dict.get('strong_model', llm_config_dict)
        strong_provider = strong_model_dict.get('provider', provider)
        strong_llm_type = provider_type_mapping.get(strong_provider, 'litellm')
        
        strong_llm_config = LLMConfig(
            type=strong_llm_type,
            model=strong_model_dict.get('model'),
            api_key=strong_model_dict.get('api_key'),
            base_url=strong_model_dict.get('base_url'),
            provider=strong_provider,
            timeout=strong_model_dict.get('timeout'),
            max_retries=strong_model_dict.get('retry_attempts', 3),
            temperature=strong_model_dict.get('temperature'),
            max_tokens=strong_model_dict.get('max_tokens')
        )
        
        # å°†å¼ºæ¨¡å‹é…ç½®æ·»åŠ åˆ°graph_knowledge_configä¸­
        graph_knowledge_config.strong_model_config = strong_llm_config
        
        self.logger.info(f"LLMé…ç½®: é»˜è®¤æ¨¡å‹={llm_config.model}, å¼ºæ¨¡å‹={strong_llm_config.model}")
        
        # ä½¿ç”¨çŸ¥è¯†å›¾è°±ä¸“ç”¨åˆ†å—é…ç½®
        graph_chunking_config = self.config['knowledge']['chunking']['graph_knowledge']
        strategy = graph_chunking_config.get('strategy', 'fixed_size')
        chunk_size = graph_chunking_config.get('chunk_size', 3000)
        chunk_overlap = graph_chunking_config.get('chunk_overlap', 300)
        
        chunking_config = ChunkingConfig(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap
        )
        
        self.logger.info(f"åˆ†å—é…ç½®: strategy={strategy}, chunk_size={chunk_size}, overlap={chunk_overlap}")
        
        # å¯¹æ‰€æœ‰æ–‡æ¡£è¿›è¡Œåˆ†å—
        all_chunks = []
        for i, document in enumerate(documents):
            doc_name = document.metadata.name
            doc_length = len(document.content)
            
            # æ£€æŸ¥æ–‡æ¡£æ˜¯å¦éœ€è¦åˆ†å—
            if doc_length > chunk_size:
                self.logger.info(f"åˆ†å—æ–‡æ¡£ {i+1}/{len(documents)}: {doc_name} ({doc_length}å­—ç¬¦)")
                
                # ä½¿ç”¨åˆ†å—å™¨
                chunker_kwargs = {}
                if strategy == "semantic":
                    chunker_kwargs['embedding_model'] = self.embedding_router
                    chunker_kwargs['similarity_threshold'] = graph_chunking_config.get('semantic', {}).get('similarity_threshold', 0.7)
                    chunker_kwargs['min_chunk_size'] = graph_chunking_config.get('min_chunk_size', 1500)
                    chunker_kwargs['max_chunk_size'] = graph_chunking_config.get('max_chunk_size', 5000)
                elif strategy == "agentic":
                    chunker_kwargs['llm_client'] = self.llm_client
                    agentic_config = graph_chunking_config.get('agentic', {})
                    chunker_kwargs.update(agentic_config)
                
                chunker = get_chunker(strategy, chunking_config, **chunker_kwargs)
                chunks = await chunker.chunk_document_async(document)
                
                if hasattr(chunks, 'chunks'):
                    chunk_docs = chunks.chunks
                else:
                    chunk_docs = chunks
                
                all_chunks.extend(chunk_docs)
                self.logger.info(f"åˆ†å—ç»“æœ: {len(chunk_docs)}ä¸ªå—")
            else:
                # æ–‡æ¡£è¶³å¤Ÿå°ï¼Œä¸éœ€è¦åˆ†å—
                all_chunks.append(document)
                self.logger.info(f"æ–‡æ¡£ {i+1}/{len(documents)}: {doc_name} æ— éœ€åˆ†å—")
        
        self.logger.info(f"åˆ†å—å®Œæˆ: æ€»è®¡{len(all_chunks)}ä¸ªæ–‡æœ¬å—")
        
        # ä½¿ç”¨æ–°çš„KnowledgeGraphBuilderè¿›è¡Œä¸¤é˜¶æ®µSPOæŠ½å–
        builder = KnowledgeGraphBuilder(
            config=graph_knowledge_config,
            llm_config=llm_config
        )
        
        # æå–åˆ†å—åçš„æ–‡æ¡£æ–‡æœ¬
        texts = [chunk.content for chunk in all_chunks]
        metadata = [chunk.metadata.__dict__ for chunk in all_chunks]
        
        # æ„å»ºå›¾è°±ï¼ˆä½¿ç”¨æ‰¹å¤„ç†SPOæŠ½å–ï¼‰
        self.logger.info(f"å¼€å§‹SPOæŠ½å–: {len(texts)}ä¸ªæ–‡æœ¬å—")
        self.knowledge_graph = await builder.build_from_texts(
            texts=texts,
            metadata=metadata
        )
        
        # æ‰“å°æ„å»ºç»“æœ
        entity_count = len(self.knowledge_graph.entities)
        relation_count = len(self.knowledge_graph.relationships)
        self.logger.info(f"âœ… çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆ: {entity_count}ä¸ªå®ä½“, {relation_count}ä¸ªå…³ç³»")
    
    async def store_and_index(self) -> None:
        """å­˜å‚¨å’Œç´¢å¼•çŸ¥è¯†å›¾è°±"""
        self.logger.info("å¼€å§‹å­˜å‚¨å’Œç´¢å¼•")
        
        # æ‰“å°è¾“å…¥æ•°æ®ç»Ÿè®¡
        entity_count = len(self.knowledge_graph.entities)
        relation_count = len(self.knowledge_graph.relationships)
        self.logger.info(f"è¾“å…¥æ•°æ®: {entity_count}ä¸ªå®ä½“, {relation_count}ä¸ªå…³ç³»")
        
        # 1. å­˜å‚¨åˆ°å›¾æ•°æ®åº“
        try:
            graph_storage = await self.storage_manager.get_graph_storage('default')
            
            if graph_storage:
                clear_existing = self.mode in ["full", "build"]
                self.logger.info(f"å›¾æ•°æ®åº“å­˜å‚¨: æ¸…ç†æ¨¡å¼={clear_existing}")
                graph_storage.store_graph(self.knowledge_graph, clear_existing=clear_existing)
                self.logger.info("âœ… å›¾æ•°æ®åº“å­˜å‚¨å®Œæˆ")
            else:
                self.logger.warning("âŒ æœªæ‰¾åˆ°å›¾æ•°æ®åº“å­˜å‚¨ï¼Œè·³è¿‡")
        except Exception as e:
            self.logger.error(f"âŒ å›¾æ•°æ®åº“å­˜å‚¨å¤±è´¥: {e}")
            self.logger.warning("ç»§ç»­æ‰§è¡Œå…¶ä»–ç´¢å¼•æ­¥éª¤")
        
        # 2. æ„å»ºå‘é‡ç´¢å¼•
        try:
            await self._build_vector_index()
        except Exception as e:
            self.logger.error(f"âŒ å‘é‡ç´¢å¼•æ„å»ºå¤±è´¥: {e}")
        
        # 3. æ„å»ºBM25ç´¢å¼•
        try:
            await self._build_bm25_index()
        except Exception as e:
            self.logger.error(f"âŒ BM25ç´¢å¼•æ„å»ºå¤±è´¥: {e}")
        
        # 4. æ„å»º SPO ç´¢å¼•
        try:
            await self._build_spo_index()
        except Exception as e:
            self.logger.error(f"âŒ SPOç´¢å¼•æ„å»ºå¤±è´¥: {e}")
        
        # 5. ç¼“å­˜å…³é”®æ•°æ®
        try:
            await self._cache_key_data()
        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®ç¼“å­˜å¤±è´¥: {e}")
        
        # ç»Ÿè®¡å‘é‡ç´¢å¼•æ€»æ•° - ç»Ÿè®¡æ‰€æœ‰ç‹¬ç«‹å‘é‡å­˜å‚¨å®ä¾‹
        total_vectors = 0
        
        # ç»Ÿè®¡æ–‡æ¡£å‘é‡å­˜å‚¨
        if hasattr(self, '_document_vector_storage') and self._document_vector_storage:
            try:
                doc_status = self._document_vector_storage.status()
                doc_vectors = doc_status.vector_count
                total_vectors += doc_vectors
                self.logger.debug(f"æ–‡æ¡£å‘é‡å­˜å‚¨: {doc_vectors}æ¡è®°å½•")
            except Exception as e:
                self.logger.debug(f"è·å–æ–‡æ¡£å‘é‡å­˜å‚¨çŠ¶æ€å¤±è´¥: {e}")
        
        # ç»Ÿè®¡å›¾å‘é‡å­˜å‚¨
        if hasattr(self, '_graph_vector_storage') and self._graph_vector_storage:
            try:
                graph_status = self._graph_vector_storage.status()
                graph_vectors = graph_status.vector_count
                total_vectors += graph_vectors
                self.logger.debug(f"å›¾å‘é‡å­˜å‚¨: {graph_vectors}æ¡è®°å½•")
            except Exception as e:
                self.logger.debug(f"è·å–å›¾å‘é‡å­˜å‚¨çŠ¶æ€å¤±è´¥: {e}")
        
        self.logger.info(f"å­˜å‚¨å’Œç´¢å¼•å®Œæˆ: å›¾æ•°æ®åº“{len(self.knowledge_graph.entities)}ä¸ªå®ä½“/{len(self.knowledge_graph.relationships)}ä¸ªå…³ç³», å‘é‡æ•°æ®åº“{total_vectors}æ¡è®°å½•")
    
    async def _build_vector_index(self) -> None:
        """æ„å»ºå‘é‡ç´¢å¼• - ç°åœ¨åˆ†ç¦»ä¸ºæ–‡æ¡£å‘é‡å’Œå›¾å‘é‡"""
        self.logger.info("å¼€å§‹æ„å»ºå‘é‡ç´¢å¼•")
        
        # æ„å»ºæ–‡æ¡£å‘é‡ç´¢å¼•ï¼ˆç”¨äºå‘é‡æ£€ç´¢ï¼‰
        await self._build_document_vector_index()
        
        # æ„å»ºå›¾å‘é‡ç´¢å¼•ï¼ˆç”¨äºå›¾æ£€ç´¢å¢å¼ºï¼‰
        await self._build_graph_vector_indices()
        
        self.logger.info("âœ… å‘é‡ç´¢å¼•æ„å»ºå®Œæˆ")
    
    async def _build_document_vector_index(self) -> None:
        """æ„å»ºæ–‡æ¡£åˆ†å—å‘é‡ç´¢å¼• - ä¸“ç”¨äºå‘é‡æ£€ç´¢è·¯å¾„"""
        from agenticx.storage import StorageType
        from agenticx.storage.vectordb_storages.milvus import MilvusStorage
        
        self.logger.info("æ„å»ºæ–‡æ¡£å‘é‡ç´¢å¼•")
        
        # ğŸ”§ ä¸ºæ–‡æ¡£å‘é‡åˆ›å»ºç‹¬ç«‹çš„Milvuså­˜å‚¨å®ä¾‹
        storage_config = self.config['storage']['vector']['milvus']
        self._document_vector_storage = MilvusStorage(
            dimension=1024,  # ä½¿ç”¨åµŒå…¥ç»´åº¦
            host=storage_config['host'],
            port=storage_config['port'],
            collection_name=storage_config['collection_name'],  # ä½¿ç”¨æ–‡æ¡£ä¸“ç”¨é›†åˆå
            database=storage_config.get('database', 'default'),
            username=storage_config.get('username'),
            password=storage_config.get('password'),
            recreate_if_exists=True  # é‡æ–°åˆ›å»ºé›†åˆï¼Œç¡®ä¿å¹²å‡€çš„å¼€å§‹
        )
        
        self.logger.info(f"ğŸ“„ æ–‡æ¡£å‘é‡å­˜å‚¨é›†åˆ: {storage_config['collection_name']}")
        
        if not hasattr(self, 'documents') or not self.documents:
            self.logger.warning("âŒ æ²¡æœ‰æ–‡æ¡£å¯ä»¥ç´¢å¼•")
            return
        
        # ä½¿ç”¨å‘é‡æ£€ç´¢ä¸“ç”¨åˆ†å—é…ç½®
        vector_chunking_config = self.config['knowledge']['chunking'].get('vector', {
            'strategy': 'fixed_size',
            'chunk_size': 1500,
            'chunk_overlap': 150,
            'min_chunk_size': 500,
            'max_chunk_size': 2000
        })
        
        strategy = vector_chunking_config['strategy']
        chunk_size = vector_chunking_config['chunk_size']
        chunk_overlap = vector_chunking_config['chunk_overlap']
        self.logger.info(f"å‘é‡åˆ†å—é…ç½®: strategy={strategy}, chunk_size={chunk_size}, overlap={chunk_overlap}")
        
        # è·å–å‘é‡æ£€ç´¢ä¸“ç”¨åˆ†å—å™¨
        from agenticx.knowledge.base import ChunkingConfig
        vector_config = ChunkingConfig(
            chunk_size=vector_chunking_config['chunk_size'],
            chunk_overlap=vector_chunking_config['chunk_overlap']
        )
        vector_chunker = get_chunker(vector_chunking_config['strategy'], vector_config)
        
        document_records = []
        for doc_idx, document in enumerate(self.documents):
            # ä½¿ç”¨å‘é‡æ£€ç´¢ä¸“ç”¨åˆ†å—
            try:
                chunks_result = await vector_chunker.chunk_document_async(document)
                chunks = chunks_result.chunks if hasattr(chunks_result, 'chunks') else chunks_result
            except Exception as e:
                self.logger.warning(f"åˆ†å—å¤±è´¥ï¼Œä½¿ç”¨ç®€å•åˆ†å—: {e}")
                # ç®€å•åˆ†å—ä½œä¸ºå¤‡ç”¨
                chunk_size = vector_chunking_config['chunk_size']
                content = document.content
                chunks = []
                for i in range(0, len(content), chunk_size):
                    chunk_content = content[i:i + chunk_size]
                    chunk_metadata = type(document.metadata)(
                        name=f"{document.metadata.name}_chunk_{i//chunk_size}",
                        source=document.metadata.source,
                        source_type=document.metadata.source_type,
                        content_type=document.metadata.content_type,
                        parent_id=document.id,
                        chunk_index=i//chunk_size,
                        chunker_name="SimpleChunker"
                    )
                    chunk = type(document)(content=chunk_content, metadata=chunk_metadata)
                    chunks.append(chunk)
            
            for chunk_idx, chunk in enumerate(chunks):
                # ç”ŸæˆåµŒå…¥
                embedding = await self.embedding_router.aembed_text(chunk.content)
                
                # åˆ›å»ºå‘é‡è®°å½•
                record = VectorRecord(
                    id=f"doc_{doc_idx}_chunk_{chunk_idx}",
                    vector=embedding,
                    payload={
                        'content': chunk.content,  # ğŸ”§ ä¿®å¤ï¼šå°†contentæ”¾åˆ°payloadä¸­
                        'metadata': {
                            'type': 'document_chunk',
                            'document_id': document.id,
                            'document_title': getattr(document.metadata, 'title', None) or getattr(document.metadata, 'name', ''),
                            'chunk_index': chunk_idx,
                            'chunk_size': len(chunk.content),
                            'chunking_strategy': vector_chunking_config['strategy']
                        }
                    }
                )
                document_records.append(record)
        
        # æ‰¹é‡å­˜å‚¨æ–‡æ¡£åˆ†å—å‘é‡
        if document_records:
            await self._document_vector_storage.add(document_records)
            self.logger.info(f"âœ… æ–‡æ¡£å‘é‡ç´¢å¼•å®Œæˆ: {len(document_records)}æ¡è®°å½•")
            self.logger.info(f"ğŸ“„ å­˜å‚¨åˆ°é›†åˆ: {storage_config['collection_name']}")
        else:
            self.logger.warning("âŒ æ²¡æœ‰æ–‡æ¡£åˆ†å—å¯ä»¥ç´¢å¼•")
    
    async def _build_graph_vector_indices(self) -> None:
        """æ„å»ºå›¾å‘é‡ç´¢å¼• - ä¸“ç”¨äºå›¾æ£€ç´¢å¢å¼º"""
        self.logger.info("æ„å»ºå›¾å‘é‡ç´¢å¼•")
        
        # æ£€æŸ¥å›¾æ£€ç´¢å™¨æ˜¯å¦æ”¯æŒå‘é‡ç´¢å¼•
        if not hasattr(self, 'graph_retriever') or not self.graph_retriever:
            self.logger.warning("âŒ å›¾æ£€ç´¢å™¨æœªåˆå§‹åŒ–ï¼Œè·³è¿‡")
            return
        
        if not self.graph_retriever.enable_vector_search:
            self.logger.info("å›¾å‘é‡ç´¢å¼•å·²ç¦ç”¨ï¼Œè·³è¿‡æ„å»º")
            return
        
        try:
            # ä½¿ç”¨GraphRetrieverçš„å‘é‡ç´¢å¼•æ„å»ºåŠŸèƒ½
            results = await self.graph_retriever.build_vector_indices()
            
            # å¤„ç†ä¸åŒç±»å‹çš„ç»“æœçŠ¶æ€
            success_count = 0
            skipped_count = 0
            failed_count = 0
            
            for k, v in results.items():
                if k == 'error':
                    continue
                if v is True or v == "success":
                    success_count += 1
                elif v == "skipped":
                    skipped_count += 1
                else:
                    failed_count += 1
            
            total_count = len([k for k in results.keys() if k != 'error'])
            
            if 'error' in results:
                self.logger.error(f"âŒ å›¾å‘é‡ç´¢å¼•æ„å»ºå¤±è´¥: {results['error']}")
            else:
                self.logger.info(f"âœ… å›¾å‘é‡ç´¢å¼•æ„å»ºå®Œæˆ: {success_count}/{total_count}ä¸ªæˆåŠŸ")
                for index_type, result in results.items():
                    if index_type == 'error':
                        continue
                    if result is True or result == "success":
                        status = "âœ…"
                    elif result == "skipped":
                        status = "â­ï¸"  # è·³è¿‡ç¬¦å·
                    else:
                        status = "âŒ"
                    self.logger.info(f"  {status} {index_type}ç´¢å¼•")
                
        except Exception as e:
            self.logger.error(f"âŒ å›¾å‘é‡ç´¢å¼•æ„å»ºå¼‚å¸¸: {e}")
    
    async def _build_bm25_index(self) -> None:
        """æ„å»ºBM25å€’æ’ç´¢å¼• - åŸºäºä¸“ç”¨åˆ†å—é…ç½®"""
        self.logger.info("æ„å»ºBM25å€’æ’ç´¢å¼•")
        
        if not hasattr(self, 'documents') or not self.documents:
            self.logger.warning("âŒ æ²¡æœ‰æ–‡æ¡£å¯ä»¥æ„å»ºBM25ç´¢å¼•")
            return
        
        # æ£€æŸ¥BM25æ£€ç´¢å™¨æ˜¯å¦å·²åˆå§‹åŒ–
        if not hasattr(self, 'retriever') or not self.retriever:
            self.logger.warning("âŒ æ£€ç´¢å™¨æœªåˆå§‹åŒ–ï¼Œè·³è¿‡")
            return
        
        # è·å–BM25æ£€ç´¢å™¨
        bm25_retriever = None
        if hasattr(self.retriever, 'bm25_retriever'):
            bm25_retriever = self.retriever.bm25_retriever
        else:
            self.logger.warning("âŒ æœªæ‰¾åˆ°BM25æ£€ç´¢å™¨ï¼Œè·³è¿‡")
            return
        
        # ä½¿ç”¨BM25ä¸“ç”¨åˆ†å—é…ç½®
        bm25_chunking_config = self.config['knowledge']['chunking'].get('bm25', {
            'strategy': 'fixed_size',
            'chunk_size': 600,
            'chunk_overlap': 100,
            'min_chunk_size': 400,
            'max_chunk_size': 1000
        })
        
        strategy = bm25_chunking_config['strategy']
        chunk_size = bm25_chunking_config['chunk_size']
        chunk_overlap = bm25_chunking_config['chunk_overlap']
        self.logger.info(f"BM25åˆ†å—é…ç½®: strategy={strategy}, chunk_size={chunk_size}, overlap={chunk_overlap}")
        
        # è·å–BM25ä¸“ç”¨åˆ†å—å™¨
        from agenticx.knowledge.base import ChunkingConfig
        bm25_config = ChunkingConfig(
            chunk_size=bm25_chunking_config['chunk_size'],
            chunk_overlap=bm25_chunking_config['chunk_overlap']
        )
        bm25_chunker = get_chunker(bm25_chunking_config['strategy'], bm25_config)
        
        # å‡†å¤‡BM25æ–‡æ¡£
        bm25_documents = []
        for doc_idx, document in enumerate(self.documents):
            # ä½¿ç”¨BM25ä¸“ç”¨åˆ†å—
            try:
                chunks_result = await bm25_chunker.chunk_document_async(document)
                chunks = chunks_result.chunks if hasattr(chunks_result, 'chunks') else chunks_result
            except Exception as e:
                self.logger.warning(f"BM25åˆ†å—å¤±è´¥ï¼Œä½¿ç”¨ç®€å•åˆ†å—: {e}")
                # ç®€å•åˆ†å—ä½œä¸ºå¤‡ç”¨
                chunk_size = bm25_chunking_config['chunk_size']
                content = document.content
                chunks = []
                for i in range(0, len(content), chunk_size):
                    chunk_content = content[i:i + chunk_size]
                    chunk_metadata = type(document.metadata)(
                        name=f"{document.metadata.name}_bm25_chunk_{i//chunk_size}",
                        source=document.metadata.source,
                        source_type=document.metadata.source_type,
                        content_type=document.metadata.content_type,
                        parent_id=document.id,
                        chunk_index=i//chunk_size,
                        chunker_name="SimpleChunker"
                    )
                    chunk = type(document)(content=chunk_content, metadata=chunk_metadata)
                    chunks.append(chunk)
            
            for chunk_idx, chunk in enumerate(chunks):
                # åˆ›å»ºBM25æ–‡æ¡£è®°å½•
                bm25_doc = {
                    'id': f"bm25_doc_{doc_idx}_chunk_{chunk_idx}",
                    'content': chunk.content,
                    'metadata': {
                        'type': 'bm25_chunk',
                        'document_id': document.id,
                        'document_title': getattr(document.metadata, 'title', None) or getattr(document.metadata, 'name', ''),
                        'chunk_index': chunk_idx,
                        'chunk_size': len(chunk.content),
                        'chunking_strategy': bm25_chunking_config['strategy']
                    }
                }
                bm25_documents.append(bm25_doc)
        
        # æ‰¹é‡æ·»åŠ åˆ°BM25æ£€ç´¢å™¨
        if bm25_documents:
            try:
                document_ids = await bm25_retriever.add_documents(bm25_documents)
                self.logger.info(f"âœ… BM25ç´¢å¼•æ„å»ºå®Œæˆ: {len(bm25_documents)}æ¡è®°å½•")
                self.logger.debug(f"BM25æ–‡æ¡£ID: {document_ids[:5]}..." if len(document_ids) > 5 else f"BM25æ–‡æ¡£ID: {document_ids}")
            except Exception as e:
                self.logger.error(f"âŒ BM25ç´¢å¼•æ·»åŠ å¤±è´¥: {e}")
        else:
            self.logger.warning("âš ï¸ æ²¡æœ‰BM25æ–‡æ¡£å¯ä»¥ç´¢å¼•")
    
    async def _build_legacy_entity_relation_vectors(self) -> None:
        """æ„å»ºä¼ ç»Ÿçš„å®ä½“å’Œå…³ç³»å‘é‡ï¼ˆä¿ç•™ç”¨äºå…¼å®¹æ€§ï¼‰"""
        from agenticx.storage import StorageType
        
        self.logger.debug("æ„å»ºä¼ ç»Ÿå®ä½“å…³ç³»å‘é‡...")
        
        vector_storage = await self.storage_manager.get_vector_storage('default')
        if not vector_storage:
            vector_storage = self.storage_manager.get_storage(StorageType.CHROMA)
            if not vector_storage:
                return
        
        # ä¸ºå®ä½“æ„å»ºå‘é‡ç´¢å¼•
        entity_records = []
        for entity in self.knowledge_graph.entities.values():
            entity_text = f"{entity.name}: {entity.description or ''}"
            embedding = await self.embedding_router.aembed_text(entity_text)
            
            record = VectorRecord(
                id=f"legacy_entity_{entity.id}",
                vector=embedding,
                metadata={
                    'type': 'legacy_entity',
                    'entity_type': entity.entity_type.value,
                    'name': entity.name,
                    'confidence': entity.confidence
                },
                content=entity_text
            )
            entity_records.append(record)
        
        # ä¸ºå…³ç³»æ„å»ºå‘é‡ç´¢å¼•
        relationship_records = []
        for relationship in self.knowledge_graph.relationships.values():
            source_entity = self.knowledge_graph.get_entity(relationship.source_entity_id)
            target_entity = self.knowledge_graph.get_entity(relationship.target_entity_id)
            
            if source_entity and target_entity:
                rel_text = f"{source_entity.name} {relationship.relation_type.value} {target_entity.name}"
                embedding = await self.embedding_router.aembed_text(rel_text)
                
                record = VectorRecord(
                    id=f"legacy_relation_{relationship.id}",
                    vector=embedding,
                    metadata={
                        'type': 'legacy_relationship',
                        'relation_type': relationship.relation_type.value,
                        'source_entity': source_entity.name,
                        'target_entity': target_entity.name,
                        'confidence': relationship.confidence
                    },
                    content=rel_text
                )
                relationship_records.append(record)
        
        # æ‰¹é‡å­˜å‚¨
        all_records = entity_records + relationship_records
        if all_records:
            vector_storage.add(all_records)
            self.logger.debug(f"ä¼ ç»Ÿå‘é‡ç´¢å¼•: {len(entity_records)}ä¸ªå®ä½“ + {len(relationship_records)}ä¸ªå…³ç³»")
    
    async def _build_spo_index(self) -> None:
        """æ„å»º SPO ä¸‰å…ƒç»„ç´¢å¼•"""
        import json
        self.logger.info("æ„å»º SPO ä¸‰å…ƒç»„ç´¢å¼•...")
        
        # è°ƒè¯•ï¼šæ£€æŸ¥å­˜å‚¨ç®¡ç†å™¨çŠ¶æ€
        self.logger.info(f"å­˜å‚¨ç®¡ç†å™¨åˆå§‹åŒ–çŠ¶æ€: {self.storage_manager.initialized}")
        self.logger.info(f"å­˜å‚¨å®ä¾‹æ•°é‡: {len(self.storage_manager.storages)}")
        
        kv_storage = await self.storage_manager.get_key_value_storage('default')
        self.logger.info(f"è·å–åˆ°çš„é”®å€¼å­˜å‚¨: {type(kv_storage) if kv_storage else 'None'}")
        
        if not kv_storage:
            self.logger.warning("âš ï¸ æœªæ‰¾åˆ°é”®å€¼å­˜å‚¨ï¼Œè·³è¿‡SPOç´¢å¼•æ„å»º")
            return
        
        # æ„å»º SPO ç´¢å¼•
        spo_index = {
            'subject_index': {},  # ä¸»è¯­ç´¢å¼•
            'predicate_index': {},  # è°“è¯­ç´¢å¼•
            'object_index': {}  # å®¾è¯­ç´¢å¼•
        }
        
        for relationship in self.knowledge_graph.relationships.values():
            source_entity = self.knowledge_graph.get_entity(relationship.source_entity_id)
            target_entity = self.knowledge_graph.get_entity(relationship.target_entity_id)
            
            if source_entity and target_entity:
                subject = source_entity.name
                predicate = relationship.relation_type.value
                object_name = target_entity.name
                
                # ä¸»è¯­ç´¢å¼•
                if subject not in spo_index['subject_index']:
                    spo_index['subject_index'][subject] = []
                spo_index['subject_index'][subject].append({
                    'predicate': predicate,
                    'object': object_name,
                    'relationship_id': relationship.id
                })
                
                # è°“è¯­ç´¢å¼•
                if predicate not in spo_index['predicate_index']:
                    spo_index['predicate_index'][predicate] = []
                spo_index['predicate_index'][predicate].append({
                    'subject': subject,
                    'object': object_name,
                    'relationship_id': relationship.id
                })
                
                # å®¾è¯­ç´¢å¼•
                if object_name not in spo_index['object_index']:
                    spo_index['object_index'][object_name] = []
                spo_index['object_index'][object_name].append({
                    'subject': subject,
                    'predicate': predicate,
                    'relationship_id': relationship.id
                })
        
        # å­˜å‚¨ç´¢å¼•ï¼ˆåºåˆ—åŒ–ä¸ºJSONï¼‰
        kv_storage.set('spo_index', json.dumps(spo_index, ensure_ascii=False))
        
        self.logger.info(
            f"SPO ç´¢å¼•æ„å»ºå®Œæˆ: "
            f"{len(spo_index['subject_index'])} ä¸ªä¸»è¯­, "
            f"{len(spo_index['predicate_index'])} ä¸ªè°“è¯­, "
            f"{len(spo_index['object_index'])} ä¸ªå®¾è¯­"
        )
    
    async def _cache_key_data(self) -> None:
        """ç¼“å­˜å…³é”®æ•°æ®"""
        import json
        from datetime import datetime, timezone
        self.logger.info("ç¼“å­˜å…³é”®æ•°æ®...")
        
        kv_storage = await self.storage_manager.get_key_value_storage('default')
        if not kv_storage:
            self.logger.warning("âš ï¸ æœªæ‰¾åˆ°é”®å€¼å­˜å‚¨ï¼Œè·³è¿‡æ•°æ®ç¼“å­˜")
            return
        
        # ç¼“å­˜å›¾è°±ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'entity_count': len(self.knowledge_graph.entities),
            'relationship_count': len(self.knowledge_graph.relationships),
            'entity_types': {},
            'relationship_types': {},
            'build_time': datetime.now(timezone.utc).isoformat()
        }
        
        # ç»Ÿè®¡å®ä½“ç±»å‹
        for entity in self.knowledge_graph.entities.values():
            entity_type = entity.entity_type.value
            stats['entity_types'][entity_type] = stats['entity_types'].get(entity_type, 0) + 1
        
        # ç»Ÿè®¡å…³ç³»ç±»å‹
        for relationship in self.knowledge_graph.relationships.values():
            rel_type = relationship.relation_type.value
            stats['relationship_types'][rel_type] = stats['relationship_types'].get(rel_type, 0) + 1
        
        kv_storage.set('graph_stats', json.dumps(stats, ensure_ascii=False))
        self.logger.info("å…³é”®æ•°æ®ç¼“å­˜å®Œæˆ")
    
    async def interactive_qa(self) -> None:
        """äº¤äº’å¼é—®ç­”ç³»ç»Ÿ"""
        self.logger.info("å¯åŠ¨äº¤äº’å¼é—®ç­”ç³»ç»Ÿ...")
        
        if console and Panel and box:
            # ä½¿ç”¨ Rich æ˜¾ç¤ºé—®ç­”ç•Œé¢
            qa_text = Text()
            qa_text.append("ğŸ¤– AgenticX GraphRAG é—®ç­”ç³»ç»Ÿ\n\n", style="bold cyan")
            qa_text.append("æ”¯æŒçš„æŸ¥è¯¢ç±»å‹:\n", style="bold white")
            qa_text.append("â— å®ä½“æŸ¥è¯¢: æŸ¥æ‰¾ç‰¹å®šå®ä½“çš„ä¿¡æ¯\n", style="white")
            qa_text.append("â— å…³ç³»æŸ¥è¯¢: æŸ¥æ‰¾å®ä½“é—´çš„å…³ç³»\n", style="white")
            qa_text.append("â— è·¯å¾„æŸ¥è¯¢: æŸ¥æ‰¾å®ä½“é—´çš„è¿æ¥è·¯å¾„\n", style="white")
            qa_text.append("â— ç¤¾åŒºæŸ¥è¯¢: æŸ¥æ‰¾ç›¸å…³å®ä½“ç¾¤ç»„\n", style="white")
            qa_text.append("â— è‡ªç”±é—®ç­”: åŸºäºçŸ¥è¯†å›¾è°±çš„å¼€æ”¾å¼é—®ç­”\n\n", style="white")
            qa_text.append("è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºç³»ç»Ÿ", style="dim")
            
            panel = Panel(
                qa_text,
                title="æ™ºèƒ½é—®ç­”",
                border_style="orange1",
                box=box.ROUNDED,
                padding=(1, 2)
            )
            console.print(panel)
        else:
            print("\n" + "="*60)
            print("ğŸ¤– AgenticX GraphRAG é—®ç­”ç³»ç»Ÿ")
            print("="*60)
            print("æ”¯æŒçš„æŸ¥è¯¢ç±»å‹:")
            print("  1. å®ä½“æŸ¥è¯¢: æŸ¥æ‰¾ç‰¹å®šå®ä½“çš„ä¿¡æ¯")
            print("  2. å…³ç³»æŸ¥è¯¢: æŸ¥æ‰¾å®ä½“é—´çš„å…³ç³»")
            print("  3. è·¯å¾„æŸ¥è¯¢: æŸ¥æ‰¾å®ä½“é—´çš„è¿æ¥è·¯å¾„")
            print("  4. ç¤¾åŒºæŸ¥è¯¢: æŸ¥æ‰¾ç›¸å…³å®ä½“ç¾¤ç»„")
            print("  5. è‡ªç”±é—®ç­”: åŸºäºçŸ¥è¯†å›¾è°±çš„å¼€æ”¾å¼é—®ç­”")
            print("\nè¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºç³»ç»Ÿ")
            print("="*60 + "\n")
        
        while True:
            try:
                # è·å–ç”¨æˆ·è¾“å…¥
                if console and Prompt:
                    query = Prompt.ask("\n[bold cyan]ğŸ” è¯·è¾“å…¥æ‚¨çš„é—®é¢˜[/bold cyan]").strip()
                else:
                    query = input("ğŸ” è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ").strip()
                
                if query.lower() in ['quit', 'exit', 'é€€å‡º']:
                    print_success("æ„Ÿè°¢ä½¿ç”¨ AgenticX GraphRAG ç³»ç»Ÿï¼")
                    break
                
                if not query:
                    continue
                
                # å¤„ç†æŸ¥è¯¢
                await self._process_query(query)
                
            except KeyboardInterrupt:
                print_success("\næ„Ÿè°¢ä½¿ç”¨ AgenticX GraphRAG ç³»ç»Ÿï¼")
                break
            except Exception as e:
                self.logger.error(f"æŸ¥è¯¢å¤„ç†é”™è¯¯: {e}")
                print_error(f"æŸ¥è¯¢å¤„ç†å‡ºé”™: {e}")
    
    async def _process_query(self, query: str) -> None:
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢"""
        print(f"\nğŸ”„ æ­£åœ¨å¤„ç†æŸ¥è¯¢: {query}")
        self.logger.info(f"å¼€å§‹å¤„ç†æŸ¥è¯¢: {query}")
        
        try:
            # ğŸ”§ ä¿®å¤ï¼šæ­£ç¡®è·å–RAGå’Œæ£€ç´¢é…ç½®
            rag_config = self.config.get('rag', {})
            rag_retrieval_config = rag_config.get('retrieval', {})
            retrieval_config = self.config.get('retrieval', {})
            vector_config = retrieval_config.get('vector', {})
            graph_config = retrieval_config.get('graph', {})
            
            # ğŸ”§ è°ƒè¯•ï¼šæ‰“å°é…ç½®å†…å®¹
            self.logger.info(f"ğŸ” é…ç½®è°ƒè¯•:")
            self.logger.info(f"  rag_config keys: {list(rag_config.keys())}")
            self.logger.info(f"  rag_retrieval_config: {rag_retrieval_config}")
            self.logger.info(f"  vector_config top_k: {vector_config.get('top_k', 'NOT_FOUND')}")
            self.logger.info(f"  graph_config max_nodes: {graph_config.get('max_nodes', 'NOT_FOUND')}")
            
            # ä½¿ç”¨RAGé…ç½®ä¸­çš„default_top_kï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨å‘é‡é…ç½®çš„top_k
            hybrid_top_k = rag_retrieval_config.get('default_top_k', vector_config.get('top_k', 20))
            graph_top_k = graph_config.get('max_nodes', 50)  # ä½¿ç”¨å›¾é…ç½®ä¸­çš„max_nodesä½œä¸ºtop_k
            similarity_threshold = vector_config.get('similarity_threshold', 0.2)
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å›¾æ£€ç´¢é˜ˆå€¼ï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç è®¡ç®—
            graph_similarity_threshold = graph_config.get('similarity_threshold', 0.3)  # ä»é…ç½®è¯»å–å›¾æ£€ç´¢é˜ˆå€¼

            self.logger.info(f"ğŸ¯ æœ€ç»ˆæ£€ç´¢å‚æ•°: hybrid_top_k={hybrid_top_k}, graph_top_k={graph_top_k}, vector_threshold={similarity_threshold}, graph_threshold={graph_similarity_threshold}")
            

            # 1. æ‰§è¡Œæ··åˆæ£€ç´¢ - ğŸ”§ ä¿®å¤ï¼šä¼ é€’ç›¸ä¼¼åº¦é˜ˆå€¼
            self.logger.info(f"ğŸ” å¼€å§‹æ··åˆæ£€ç´¢ï¼Œè¯·æ±‚top_k={hybrid_top_k}, min_score={similarity_threshold}")
            hybrid_results = await self.retriever.retrieve(query, top_k=hybrid_top_k, min_score=similarity_threshold)
            self.logger.info(f"ğŸ” æ··åˆæ£€ç´¢å®é™…è¿”å›: {len(hybrid_results)}æ¡")
            
            # 2. æ‰§è¡Œå›¾æ£€ç´¢ - ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨é…ç½®çš„top_kå’Œæ›´ä½çš„ç›¸ä¼¼åº¦é˜ˆå€¼
            graph_results = []
            if hasattr(self, 'graph_retriever') and self.graph_retriever:
                try:
                    self.logger.info(f"ğŸ”— å¼€å§‹å›¾æ£€ç´¢ï¼Œè¯·æ±‚top_k={graph_top_k}, min_score={graph_similarity_threshold}")
                    graph_results = await self.graph_retriever.retrieve(query, top_k=graph_top_k, min_score=graph_similarity_threshold)
                    self.logger.info(f"ğŸ”— å›¾æ£€ç´¢å®é™…è¿”å›: {len(graph_results)}æ¡")
                except Exception as e:
                    self.logger.warning(f"å›¾æ£€ç´¢å¤±è´¥: {e}")
            else:
                self.logger.warning("ğŸ”— å›¾æ£€ç´¢å™¨ä¸å¯ç”¨")
            
            # 3. åˆå¹¶å’Œå»é‡
            all_results = hybrid_results + graph_results
            seen_ids = set()
            unique_results = []
            for result in all_results:
                result_id = getattr(result, 'id', str(hash(result.content)))
                if result_id not in seen_ids:
                    seen_ids.add(result_id)
                    unique_results.append(result)
            
            # 4. æŒ‰ç›¸ä¼¼åº¦æ’åºå’Œç­›é€‰
            unique_results.sort(key=lambda x: getattr(x, 'score', 0), reverse=True)
            results = unique_results[:hybrid_top_k]
            
            # 5. ç»Ÿè®¡ä¸åŒç±»å‹çš„ç»“æœ
            type_counts = {}
            for result in results:
                result_type = "å…¶ä»–"
                if hasattr(result, 'metadata') and result.metadata:
                    if 'search_source' in result.metadata:
                        result_type = result.metadata['search_source']
                    elif 'type' in result.metadata:
                        result_type = result.metadata['type']
                type_counts[result_type] = type_counts.get(result_type, 0) + 1
            
            # 6. ä¼˜åŒ–åçš„ç»Ÿä¸€æ—¥å¿—è¾“å‡º
            self.logger.info(f"å®Œæˆæ‰§è¡Œæ··åˆæ£€ç´¢ (top_k={hybrid_top_k}ï¼Œé˜ˆå€¼={similarity_threshold})")
            
            if not results:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯")
                self.logger.warning("æ£€ç´¢æ— ç»“æœï¼Œå°è¯•ç›´æ¥å®ä½“æœç´¢")
                await self._search_entity_directly(query)
                return
            
            # ç»Ÿä¸€çš„æ£€ç´¢ç»Ÿè®¡ä¿¡æ¯
            stats_info = f"æ£€ç´¢ç»Ÿè®¡:\nğŸ” æ··åˆæ£€ç´¢: {len(hybrid_results)}æ¡\nğŸ”— å›¾æ£€ç´¢: {len(graph_results)}æ¡\nğŸ”„ å»é‡å: {len(unique_results)}æ¡\nâœ… æœ€ç»ˆé‡‡ç”¨: {len(results)}æ¡ï¼Œå…¶ä¸­ï¼š"
            for result_type, count in type_counts.items():
                stats_info += f"\n    {result_type}: {count}æ¡"
            
            self.logger.info(stats_info)
            
            # ç”Ÿæˆç­”æ¡ˆ
            await self._generate_answer(query, results)
        
        except Exception as e:
            self.logger.error(f"æŸ¥è¯¢å¤„ç†é”™è¯¯: {e}")
            print(f"âŒ æŸ¥è¯¢å¤„ç†å‡ºé”™: {e}")
    
    async def _search_entity_directly(self, query: str) -> None:
        """ç›´æ¥åœ¨Neo4jä¸­æœç´¢å®ä½“"""
        try:
            from agenticx.storage import StorageType
            graph_storage = self.storage_manager.get_storage(StorageType.NEO4J)
            
            if not graph_storage:
                print("âš ï¸ å›¾å­˜å‚¨ä¸å¯ç”¨")
                return
            
            # æå–å¯èƒ½çš„å®ä½“åç§°
            entity_name = query.replace("æ˜¯å•¥", "").replace("æ˜¯ä»€ä¹ˆ", "").replace("?", "").replace("ï¼Ÿ", "").strip()
            
            # åœ¨Neo4jä¸­æœç´¢å®ä½“
            cypher_query = """
            MATCH (n:Entity) 
            WHERE n.name CONTAINS $entity_name OR n.name =~ ('(?i).*' + $entity_name + '.*')
            RETURN n.name as name, n.description as description, labels(n) as type
            LIMIT 5
            """
            
            results = graph_storage.execute_query(cypher_query, {"entity_name": entity_name})
            
            if results:
                print(f"\nğŸ” åœ¨çŸ¥è¯†å›¾è°±ä¸­æ‰¾åˆ°ç›¸å…³å®ä½“:")
                for result in results:
                    print(f"ğŸ“ å®ä½“: {result['name']}")
                    print(f"   ç±»å‹: {result['type']}")
                    if result['description']:
                        print(f"   æè¿°: {result['description']}")
                    print()
            else:
                print(f"âŒ åœ¨çŸ¥è¯†å›¾è°±ä¸­æœªæ‰¾åˆ° '{entity_name}' ç›¸å…³çš„å®ä½“")
                
        except Exception as e:
            self.logger.error(f"ç›´æ¥å®ä½“æœç´¢å¤±è´¥: {e}")
            print(f"âŒ å®ä½“æœç´¢å‡ºé”™: {e}")
    
    async def _generate_answer(self, query: str, results: List[Any]) -> None:
        """åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆç­”æ¡ˆ"""
        try:
            self.logger.info(f"å¼€å§‹ç”Ÿæˆç­”æ¡ˆï¼Œè¾“å…¥{len(results)}æ¡æ£€ç´¢ç»“æœ")
            
            # è·å–ä¸Šä¸‹æ–‡é…ç½®
            rag_config = self.config.get('rag', {})
            retrieval_config = rag_config.get('retrieval', {})
            context_top_k = retrieval_config.get('default_top_k', 10)
            
            # åˆ†ç±»æ£€ç´¢ç»“æœ
            graph_results = [r for r in results if r.metadata and r.metadata.get('search_source') == 'graph_vector']
            doc_results = [r for r in results if r.metadata and (
                r.metadata.get('type') in ['document_chunk', 'bm25_chunk'] or 
                'document_id' in r.metadata or
                'document_title' in r.metadata
            )]
            other_results = [r for r in results if r not in graph_results and r not in doc_results]
            
            # æ„å»ºå¹³è¡¡çš„ä¸Šä¸‹æ–‡
            context_results = []
            doc_count = min(len(doc_results), context_top_k // 2)
            graph_count = min(len(graph_results), context_top_k - doc_count)
            
            context_results.extend(doc_results[:doc_count])
            context_results.extend(graph_results[:graph_count])
            
            # æ·»åŠ å…¶ä»–ç»“æœ
            remaining = context_top_k - len(context_results)
            if remaining > 0:
                context_results.extend(other_results[:remaining])
            
            # ğŸ”§ é‡æ–°è®¾è®¡ä¸Šä¸‹æ–‡æ ¼å¼ï¼Œå‚è€ƒyoutu-graphragçš„ç»“æ„åŒ–æ ¼å¼
            context_sections = []
            
            # === å›¾æ£€ç´¢ç»“æœ ===
            if graph_results:
                context_sections.append("=== çŸ¥è¯†å›¾è°±ä¿¡æ¯ ===")
                
                # åˆ†ç±»å›¾æ£€ç´¢ç»“æœ
                entities = []
                relations = []
                triples = []
                communities = []
                other_graph = []
                
                for result in graph_results[:graph_count]:
                    if not result.content.strip():
                        continue
                        
                    vector_type = result.metadata.get('vector_type', 'unknown') if result.metadata else 'unknown'
                    score = getattr(result, 'score', 0.0)
                    content = result.content.strip()
                    
                    # æ ¹æ®ç±»å‹åˆ†ç±»ï¼Œä¿æŒåŸå§‹å†…å®¹å®Œæ•´æ€§
                    if vector_type == 'node' or 'Entity:' in content:
                        entities.append(f"â€¢ {content} [ç›¸å…³åº¦: {score:.3f}]")
                    elif vector_type == 'relation' or 'Relationship:' in content:
                        relations.append(f"â€¢ {content} [ç›¸å…³åº¦: {score:.3f}]")
                    elif vector_type == 'triple':
                        triples.append(f"â€¢ {content} [ç›¸å…³åº¦: {score:.3f}]")
                    elif vector_type == 'community':
                        communities.append(f"â€¢ {content} [ç›¸å…³åº¦: {score:.3f}]")
                    else:
                        # å…¶ä»–ç±»å‹çš„å›¾æ£€ç´¢ç»“æœ
                        other_graph.append(f"â€¢ {content} [ç›¸å…³åº¦: {score:.3f}]")
                
                # æŒ‰ç±»å‹æ·»åŠ ç»“æœï¼Œä¿æŒç»“æ„åŒ–å±•ç¤º
                if entities:
                    context_sections.append("å®ä½“ä¿¡æ¯:")
                    context_sections.extend(entities)
                if relations:
                    context_sections.append("\nå…³ç³»ä¿¡æ¯:")
                    context_sections.extend(relations)
                if triples:
                    context_sections.append("\nä¸‰å…ƒç»„ä¿¡æ¯:")
                    context_sections.extend(triples)
                if communities:
                    context_sections.append("\nç¤¾åŒºä¿¡æ¯:")
                    context_sections.extend(communities)
                if other_graph:
                    context_sections.append("\nå…¶ä»–å›¾è°±ä¿¡æ¯:")
                    context_sections.extend(other_graph)
            
            # === æ–‡æ¡£æ£€ç´¢ç»“æœ ===
            if doc_results:
                if context_sections:
                    context_sections.append("\n=== æ–‡æ¡£å†…å®¹ ===")
                else:
                    context_sections.append("=== æ–‡æ¡£å†…å®¹ ===")
                
                for i, result in enumerate(doc_results[:doc_count]):
                    if result.content.strip():
                        score = getattr(result, 'score', 0.0)
                        
                        # æå–æ–‡æ¡£å…ƒä¿¡æ¯
                        doc_info = ""
                        if result.metadata:
                            # æå–é¡µç ä¿¡æ¯
                            if 'page' in result.metadata:
                                doc_info = f"Page {result.metadata['page']}"
                            # æå–æ–‡æ¡£æ ‡é¢˜æˆ–æ¥æº
                            elif 'document_title' in result.metadata:
                                doc_info = f"{result.metadata['document_title']}"
                            elif 'source' in result.metadata:
                                doc_info = f"{result.metadata['source']}"
                        
                        # ä»å†…å®¹ä¸­æå–é¡µç ä¿¡æ¯ï¼ˆå¦‚æœmetadataä¸­æ²¡æœ‰ï¼‰
                        if not doc_info and "--- Page" in result.content:
                            import re
                            page_match = re.search(r'--- Page (\d+) ---', result.content)
                            if page_match:
                                doc_info = f"Page {page_match.group(1)}"
                        
                        # ä¿æŒæ–‡æ¡£å†…å®¹å®Œæ•´æ€§ï¼ŒåªåšåŸºæœ¬æ ¼å¼æ¸…ç†
                        content = result.content.strip()
                        # è§„èŒƒåŒ–é¡µç åˆ†éš”ç¬¦æ ¼å¼
                        content = content.replace('--- Page', '\n--- Page')
                        
                        # æ„å»ºæ–‡æ¡£æ¡ç›®
                        doc_prefix = f"{doc_info}: " if doc_info else ""
                        context_sections.append(f"{doc_prefix}{content} [ç›¸å…³åº¦: {score:.3f}]")
            
            context = "\n".join(context_sections)
            
            # ä½¿ç”¨æç¤ºè¯ç®¡ç†å™¨åŠ è½½æ¨¡æ¿
            try:
                prompt_template = self.prompt_manager.get_prompt_template("rag_qa", "template")
                if prompt_template:
                    prompt = prompt_template.format(context=context, query=query)
                else:
                    # å›é€€åˆ°é»˜è®¤æ¨¡æ¿
                    prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ™ºèƒ½é—®ç­”åŠ©æ‰‹ï¼Œèƒ½å¤ŸåŸºäºå¤šç§æ¥æºçš„ä¿¡æ¯ä¸ºç”¨æˆ·æä¾›å‡†ç¡®ã€å…¨é¢çš„ç­”æ¡ˆã€‚

## æ£€ç´¢åˆ°çš„ç›¸å…³ä¿¡æ¯
{context}

## ç”¨æˆ·é—®é¢˜
{query}

## è¯·æä¾›ç­”æ¡ˆ"""
            except Exception as e:
                self.logger.warning(f"æç¤ºè¯æ¨¡æ¿åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿: {e}")
                prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ™ºèƒ½é—®ç­”åŠ©æ‰‹ï¼Œèƒ½å¤ŸåŸºäºå¤šç§æ¥æºçš„ä¿¡æ¯ä¸ºç”¨æˆ·æä¾›å‡†ç¡®ã€å…¨é¢çš„ç­”æ¡ˆã€‚

## æ£€ç´¢åˆ°çš„ç›¸å…³ä¿¡æ¯
{context}

## ç”¨æˆ·é—®é¢˜
{query}

## è¯·æä¾›ç­”æ¡ˆ"""
            
            # è®°å½•æç¤ºè¯ä¿¡æ¯
            self.logger.info(f"æç¤ºè¯æ„å»ºå®Œæˆ - ä¸Šä¸‹æ–‡:{len(context)}å­—ç¬¦, æ€»é•¿åº¦:{len(prompt)}å­—ç¬¦")
            
            # æ˜¾ç¤ºå®Œæ•´æç¤ºè¯
            print("\n" + "="*60)
            print("ğŸ“ æœ€ç»ˆå‘é€ç»™å¤§æ¨¡å‹çš„æç¤ºè¯:")
            print("="*60)
            print(prompt)
            print("="*60)
            
            # è°ƒç”¨ LLM ç”Ÿæˆç­”æ¡ˆï¼ˆæµå¼è¿”å›ï¼‰
            print(f"\nğŸ¤– AI å›ç­”:")
            print("-" * 50)
            self.logger.info("å¼€å§‹è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆç­”æ¡ˆ")
            
            # æ£€æŸ¥æ˜¯å¦æ”¯æŒæµå¼è°ƒç”¨
            if hasattr(self.llm_client, 'astream'):
                # ä½¿ç”¨æµå¼è°ƒç”¨
                full_response = ""
                async for chunk in self.llm_client.astream(prompt):
                    if hasattr(chunk, 'content') and chunk.content:
                        print(chunk.content, end='', flush=True)
                        full_response += chunk.content
                    elif isinstance(chunk, str):
                        print(chunk, end='', flush=True)
                        full_response += chunk
                
                print()  # æ¢è¡Œ
                self.logger.info(f"ç­”æ¡ˆç”Ÿæˆå®Œæˆ: {len(full_response)}å­—ç¬¦")
            else:
                # å›é€€åˆ°éæµå¼è°ƒç”¨
                response = await self.llm_client.ainvoke(prompt)
                print(response.content)
                self.logger.info(f"ç­”æ¡ˆç”Ÿæˆå®Œæˆ: {len(response.content)}å­—ç¬¦")
            
            print("-" * 50)
            
        except Exception as e:
            self.logger.error(f"ç­”æ¡ˆç”Ÿæˆé”™è¯¯: {e}")
            print(f"âŒ ç­”æ¡ˆç”Ÿæˆå‡ºé”™: {e}")
    
    async def run_demo(self) -> None:
        """è¿è¡Œå®Œæ•´æ¼”ç¤ºæµç¨‹"""
        try:
            print("ğŸš€ å¯åŠ¨ AgenticX GraphRAG æ¼”ç¤ºç³»ç»Ÿ...")
            
            # 1. åˆå§‹åŒ–ç»„ä»¶
            await self.initialize_components()
            
            # 2. éªŒè¯æ•°æ®è·¯å¾„
            file_paths = self.validate_data_path()
            
            # 3. åŠ è½½æ–‡æ¡£
            documents = await self.load_documents(file_paths)
            
            # 4. æ„å»ºçŸ¥è¯†å›¾è°±
            await self.build_knowledge_graph(documents)
            
            # 5. å­˜å‚¨å’Œç´¢å¼•
            await self.store_and_index()
            
            # 6. å¯åŠ¨äº¤äº’å¼é—®ç­”
            await self.interactive_qa()
            
        except Exception as e:
            self.logger.error(f"æ¼”ç¤ºè¿è¡Œé”™è¯¯: {e}")
            print(f"âŒ æ¼”ç¤ºè¿è¡Œå‡ºé”™: {e}")
            raise
    
    async def run_build_only(self) -> None:
        """ä»…æ„å»ºæ¨¡å¼ï¼Œæ‰§è¡Œæ–‡æ¡£è§£æå’ŒçŸ¥è¯†åº“æ„å»ºï¼Œä¸å¯åŠ¨é—®ç­”"""
        try:
            print("ğŸ”¨ å¯åŠ¨ AgenticX GraphRAG æ„å»ºæ¨¡å¼...")
            print("ğŸ“‹ æ‰§è¡Œæ–‡æ¡£è§£æå’ŒçŸ¥è¯†åº“æ„å»ºï¼Œå®Œæˆåé€€å‡º")
            
            # 1. åˆå§‹åŒ–ç»„ä»¶
            await self.initialize_components()
            
            # 2. éªŒè¯æ•°æ®è·¯å¾„
            file_paths = self.validate_data_path()
            
            # 3. åŠ è½½æ–‡æ¡£
            documents = await self.load_documents(file_paths)
            
            # 4. æ„å»ºçŸ¥è¯†å›¾è°±
            await self.build_knowledge_graph(documents)
            
            # 5. å­˜å‚¨å’Œç´¢å¼•
            await self.store_and_index()
            
            print("âœ… çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼")
            print("ğŸ’¡ ç°åœ¨å¯ä»¥ä½¿ç”¨ 'python main.py --mode qa' å¯åŠ¨é—®ç­”ç³»ç»Ÿ")
            
        except Exception as e:
            self.logger.error(f"æ„å»ºæ¨¡å¼è¿è¡Œé”™è¯¯: {e}")
            print(f"âŒ æ„å»ºæ¨¡å¼è¿è¡Œå‡ºé”™: {e}")
            raise

    async def run_qa_only(self) -> None:
        """ä»…è¿è¡Œé—®ç­”æ¨¡å¼ï¼Œè·³è¿‡æ–‡æ¡£è§£æå’ŒçŸ¥è¯†åº“æ„å»º"""
        try:
            print("å¯åŠ¨ AgenticX GraphRAG é—®ç­”æ¨¡å¼...")
            print("ğŸ“‹ è·³è¿‡æ–‡æ¡£è§£æå’ŒçŸ¥è¯†åº“æ„å»ºï¼Œç›´æ¥ä½¿ç”¨å·²æœ‰æ•°æ®")
            
            # 1. åˆå§‹åŒ–ç»„ä»¶
            await self.initialize_components()
            
            # 2. éªŒè¯å·²æœ‰æ•°æ®
            await self._validate_existing_data()
            
            # 3. å¯åŠ¨äº¤äº’å¼é—®ç­”
            await self.interactive_qa()
            
        except Exception as e:
            self.logger.error(f"é—®ç­”æ¨¡å¼è¿è¡Œé”™è¯¯: {e}")
            print(f"âŒ é—®ç­”æ¨¡å¼è¿è¡Œå‡ºé”™: {e}")
            raise
    
    async def _validate_existing_data(self) -> None:
        """éªŒè¯å·²æœ‰çš„å‘é‡å’Œå›¾æ•°æ®åº“æ•°æ®"""
        self.logger.info("ğŸ” éªŒè¯å·²æœ‰æ•°æ®...")
        
        # æ£€æŸ¥å‘é‡æ•°æ®åº“
        try:
            from agenticx.storage import StorageType
            vector_storage = await self.storage_manager.get_vector_storage('default')
            if not vector_storage:
                vector_storage = self.storage_manager.get_storage(StorageType.MILVUS)
            
            if vector_storage:
                # å°è¯•éªŒè¯å‘é‡æ•°æ®åº“è¿æ¥å’Œæ•°æ®
                try:
                    # é¦–å…ˆæ£€æŸ¥å¯¹è±¡çš„æ‰€æœ‰å¯ç”¨æ–¹æ³•
                    available_methods = [method for method in dir(vector_storage) if not method.startswith('_')]
                    # ç§»é™¤å†—ä½™æ—¥å¿—
                    
                    # å°è¯•ç®€å•çš„è¿æ¥éªŒè¯ï¼Œè€Œä¸æ˜¯æ•°æ®æœç´¢
                    if hasattr(vector_storage, 'collection') and vector_storage.collection:
                        # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
                        collection_info = vector_storage.collection.describe()
                        self.logger.debug(f"Milvusé›†åˆ: {collection_info['collection_name']}")
                        print(f"âœ… å‘é‡æ•°æ®åº“è¿æ¥æ­£å¸¸ï¼Œé›†åˆå·²å­˜åœ¨")
                        
                        # å°è¯•è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯
                        if hasattr(vector_storage.collection, 'num_entities'):
                            entity_count = vector_storage.collection.num_entities
                            self.logger.debug(f"å‘é‡æ•°æ®åº“è®°å½•æ•°: {entity_count}")
                            print(f"å‘é‡æ•°æ®åº“: {entity_count}æ¡è®°å½•")
                        
                    elif hasattr(vector_storage, 'client'):
                        # å¦‚æœæœ‰clientå±æ€§ï¼Œå°è¯•æ£€æŸ¥è¿æ¥
                        self.logger.info("âœ… Milvuså®¢æˆ·ç«¯è¿æ¥æ­£å¸¸")
                        print(f"âœ… å‘é‡æ•°æ®åº“è¿æ¥æ­£å¸¸")
                    else:
                        # ç®€å•çš„è¿æ¥éªŒè¯
                        self.logger.info("âœ… å‘é‡æ•°æ®åº“å¯¹è±¡åˆ›å»ºæˆåŠŸ")
                        print(f"âœ… å‘é‡æ•°æ®åº“è¿æ¥æ­£å¸¸")
                        
                except Exception as validation_error:
                    self.logger.warning(f"å‘é‡æ•°æ®åº“éªŒè¯å¤±è´¥: {validation_error}")
                    print(f"âœ… å‘é‡æ•°æ®åº“è¿æ¥æ­£å¸¸ï¼ˆè·³è¿‡è¯¦ç»†éªŒè¯ï¼‰")
            else:
                self.logger.error("âŒ æ— æ³•è¿æ¥åˆ°å‘é‡æ•°æ®åº“")
                print("âŒ æ— æ³•è¿æ¥åˆ°å‘é‡æ•°æ®åº“")
                
        except Exception as e:
            self.logger.error(f"å‘é‡æ•°æ®åº“éªŒè¯å¤±è´¥: {e}")
            print(f"âš ï¸ å‘é‡æ•°æ®åº“éªŒè¯å¤±è´¥: {e}")
        
        # æ£€æŸ¥å›¾æ•°æ®åº“
        try:
            graph_storage = await self.storage_manager.get_graph_storage('default')
            if not graph_storage:
                graph_storage = self.storage_manager.get_storage(StorageType.NEO4J)
            
            if graph_storage:
                # æ£€æŸ¥å›¾æ•°æ®åº“ä¸­çš„èŠ‚ç‚¹æ•°é‡
                count_query = "MATCH (n) RETURN count(n) as node_count"
                result = graph_storage.execute_query(count_query)
                
                if result and len(result) > 0:
                    node_count = result[0]['node_count']
                    self.logger.debug(f"å›¾æ•°æ®åº“éªŒè¯: {node_count}ä¸ªèŠ‚ç‚¹")
                    print(f"âœ… å›¾æ•°æ®åº“è¿æ¥æ­£å¸¸ï¼ŒåŒ…å« {node_count} ä¸ªèŠ‚ç‚¹")
                    
                    # æ£€æŸ¥å…³ç³»æ•°é‡
                    rel_count_query = "MATCH ()-[r]->() RETURN count(r) as rel_count"
                    rel_result = graph_storage.execute_query(rel_count_query)
                    if rel_result and len(rel_result) > 0:
                        rel_count = rel_result[0]['rel_count']
                        self.logger.debug(f"å›¾æ•°æ®åº“å…³ç³»æ•°: {rel_count}")
                        print(f"âœ… å›¾æ•°æ®åº“åŒ…å« {rel_count} ä¸ªå…³ç³»")
                else:
                    self.logger.warning("âš ï¸ å›¾æ•°æ®åº“ä¸ºç©º")
                    print("âš ï¸ å›¾æ•°æ®åº“ä¼¼ä¹ä¸ºç©ºï¼Œå¯èƒ½éœ€è¦é‡æ–°æ„å»º")
            else:
                self.logger.error("âŒ æ— æ³•è¿æ¥åˆ°å›¾æ•°æ®åº“")
                print("âŒ æ— æ³•è¿æ¥åˆ°å›¾æ•°æ®åº“")
                
        except Exception as e:
            self.logger.error(f"å›¾æ•°æ®åº“éªŒè¯å¤±è´¥: {e}")
            print(f"âš ï¸ å›¾æ•°æ®åº“éªŒè¯å¤±è´¥: {e}")
        
        self.logger.info("æ•°æ®éªŒè¯å®Œæˆ")

    async def cleanup(self) -> None:
        """æ¸…ç†èµ„æº"""
        try:
            # å…³é—­å›¾æ•°æ®åº“è¿æ¥
            if hasattr(self, 'storage_manager') and self.storage_manager:
                graph_storage = self.storage_manager.get_storage(StorageType.NEO4J)
                if graph_storage and hasattr(graph_storage, 'close'):
                    graph_storage.close()
                    logger.info("âœ… Neo4j è¿æ¥å·²å…³é—­")
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†èµ„æºå¤±è´¥: {e}")


async def interactive_mode():
    """äº¤äº’å¼æ¨¡å¼ä¸»å‡½æ•°"""
    # æ˜¾ç¤ºæ¬¢è¿ç•Œé¢
    print_welcome()
    
    # åˆå§‹åŒ–é…ç½®
    data_path = None
    run_mode = None
    demo_instance = None
    
    while True:
        try:
            # è·å–ç”¨æˆ·è¾“å…¥
            if console and Prompt:
                user_input = Prompt.ask("\n[bold green]è¯·è¾“å…¥å‘½ä»¤æˆ–é—®é¢˜[/bold green] ([dim]/help æŸ¥çœ‹å¸®åŠ©[/dim])").strip()
            else:
                user_input = input("\nè¯·è¾“å…¥å‘½ä»¤æˆ–é—®é¢˜ (/help æŸ¥çœ‹å¸®åŠ©): ").strip()
            
            if not user_input:
                continue
            
            # å¤„ç†å‘½ä»¤
            if user_input.startswith('/'):
                command = user_input.lower()
                
                if command == '/help':
                    print_help()
                
                elif command == '/clear':
                    if console:
                        console.clear()
                    else:
                        os.system('clear' if os.name == 'posix' else 'cls')
                    print_welcome()
                
                elif command == '/mode':
                    run_mode = select_run_mode()
                    print_success(f"å·²é€‰æ‹©è¿è¡Œæ¨¡å¼: {run_mode}")
                
                elif command == '/data':
                    data_path = display_data_selection()
                    print_success(f"å·²é€‰æ‹©æ•°æ®ç›®å½•: {data_path}")
                
                elif command == '/rebuild':
                    if console and Confirm:
                        rebuild = Confirm.ask("ç¡®å®šè¦é‡æ–°æ„å»ºçŸ¥è¯†åº“å—ï¼Ÿè¿™å°†åˆ é™¤ç°æœ‰çš„ç´¢å¼•")
                    else:
                        rebuild_input = input("ç¡®å®šè¦é‡æ–°æ„å»ºçŸ¥è¯†åº“å—ï¼Ÿ(y/N): ").strip().lower()
                        rebuild = rebuild_input in ['y', 'yes']
                    
                    if rebuild:
                        print_info("å°†åœ¨ä¸‹æ¬¡è¿è¡Œæ—¶é‡æ–°æ„å»ºçŸ¥è¯†åº“")
                        # è¿™é‡Œå¯ä»¥æ·»åŠ åˆ é™¤ç°æœ‰ç´¢å¼•çš„é€»è¾‘
                    else:
                        print_info("å–æ¶ˆé‡æ–°æ„å»º")
                
                elif command == '/exit':
                    print_success("æ„Ÿè°¢ä½¿ç”¨ AgenticX GraphRAG ç³»ç»Ÿï¼")
                    break
                
                else:
                    print_error(f"æœªçŸ¥å‘½ä»¤: {command}")
                    print_info("è¾“å…¥ /help æŸ¥çœ‹å¯ç”¨å‘½ä»¤")
            
            else:
                # å¤„ç†é—®ç­”
                if not demo_instance:
                    # å¦‚æœè¿˜æ²¡æœ‰åˆå§‹åŒ–ï¼Œå…ˆè¿›è¡Œé…ç½®
                    if not data_path:
                        print_mode_selection("è¯·å…ˆé€‰æ‹©æ•°æ®ç›®å½•")
                        data_path = display_data_selection()
                    
                    if not run_mode:
                        print_mode_selection("è¯·å…ˆé€‰æ‹©è¿è¡Œæ¨¡å¼")
                        run_mode = select_run_mode()
                    
                    # åˆå§‹åŒ– demo å®ä¾‹
                    print_action("æ­£åœ¨åˆå§‹åŒ– GraphRAG ç³»ç»Ÿ...")
                    demo_instance = AgenticXGraphRAGDemo(config_path="configs.yml", mode=run_mode)
                    
                    if run_mode in ['full', 'build']:
                        print_action("æ­£åœ¨æ„å»ºçŸ¥è¯†åº“...")
                        await demo_instance.run_build_only()
                        print_success("çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼")
                        
                        if run_mode == 'build':
                            print_info("æ„å»ºæ¨¡å¼å®Œæˆï¼Œè¾“å…¥ /mode åˆ‡æ¢åˆ°é—®ç­”æ¨¡å¼")
                            continue
                    
                    elif run_mode == 'qa':
                        print_action("æ­£åœ¨åŠ è½½å·²æœ‰çŸ¥è¯†åº“...")
                        await demo_instance.run_qa_only()
                
                # æ‰§è¡Œå•æ¬¡é—®ç­”
                if demo_instance and hasattr(demo_instance, 'retrieval_agent'):
                    print_thinking(f"æ­£åœ¨æ€è€ƒæ‚¨çš„é—®é¢˜: {user_input}")
                    
                    start_time = time.time()
                    
                    # æ˜¾ç¤ºè¿›åº¦æ¡ï¼ˆå¦‚æœæœ‰ Richï¼‰
                    if console and Progress:
                        with Progress(
                            "[progress.description]{task.description}",
                            "[progress.percentage]{task.percentage:>3.0f}%",
                            console=console,
                            transient=True
                        ) as progress:
                            task = progress.add_task("æ­£åœ¨æŸ¥è¯¢...", total=100)
                            progress.update(task, advance=30)
                            
                            # ä½¿ç”¨ retrieval_agent è¿›è¡ŒæŸ¥è¯¢
                            result = await demo_instance.retrieval_agent.aquery(user_input)
                            progress.update(task, advance=70)
                    else:
                        result = await demo_instance.retrieval_agent.aquery(user_input)
                    
                    end_time = time.time()
                    
                    # æ˜¾ç¤ºç»“æœ
                    if console and Panel and box:
                        response_text = Text()
                        response_text.append(f"ğŸ’¡ å›ç­” (è€—æ—¶: {end_time - start_time:.2f}ç§’)\n\n", style="bold green")
                        response_text.append(str(result), style="white")
                        
                        response_panel = Panel(
                            response_text,
                            title="æŸ¥è¯¢ç»“æœ",
                            border_style="green",
                            box=box.ROUNDED,
                            padding=(1, 2)
                        )
                        console.print(response_panel)
                    else:
                        print(f"\nğŸ’¡ å›ç­” (è€—æ—¶: {end_time - start_time:.2f}ç§’):")
                        print("-" * 50)
                        print(str(result))
                        print("-" * 50)
                else:
                    print_error("ç³»ç»Ÿå°šæœªåˆå§‹åŒ–ï¼Œè¯·å…ˆé€‰æ‹©è¿è¡Œæ¨¡å¼")
        
        except KeyboardInterrupt:
            print_success("\næ„Ÿè°¢ä½¿ç”¨ AgenticX GraphRAG ç³»ç»Ÿï¼")
            break
        except Exception as e:
            print_error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            logger.error(f"Interactive mode error: {e}", exc_info=True)

async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(
        description='AgenticX GraphRAG æ¼”ç¤ºç³»ç»Ÿ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
è¿è¡Œæ¨¡å¼è¯´æ˜:
  full   - å®Œæ•´æµç¨‹: æ–‡æ¡£è§£æ + çŸ¥è¯†å›¾è°±æ„å»º + å‘é‡ç´¢å¼• + é—®ç­”ç³»ç»Ÿ
  build  - ä»…æ„å»º: æ–‡æ¡£è§£æ + çŸ¥è¯†å›¾è°±æ„å»º + å‘é‡ç´¢å¼• (ä¸å¯åŠ¨é—®ç­”)
  qa     - ä»…é—®ç­”: ç›´æ¥ä½¿ç”¨å·²æœ‰æ•°æ®å¯åŠ¨é—®ç­”ç³»ç»Ÿ (ä¸é‡å»ºæ•°æ®)
  interactive - äº¤äº’å¼æ¨¡å¼: ç¾è§‚çš„ç”¨æˆ·ç•Œé¢ï¼Œæ”¯æŒåŠ¨æ€é…ç½®

ä½¿ç”¨ç¤ºä¾‹:
  python demo.py                    # äº¤äº’å¼æ¨¡å¼ (é»˜è®¤)
  python demo.py --mode full        # å®Œæ•´æµç¨‹
  python demo.py --mode build       # ä»…é‡å»ºçŸ¥è¯†åº“
  python demo.py --mode qa          # ä»…å¯åŠ¨é—®ç­”
        """
    )
    
    parser.add_argument('--mode', choices=['full', 'build', 'qa', 'interactive'], default='interactive',
                       help='è¿è¡Œæ¨¡å¼: interactive=äº¤äº’å¼(é»˜è®¤), full=å®Œæ•´æµç¨‹, build=ä»…æ„å»ºçŸ¥è¯†åº“, qa=ä»…é—®ç­”æ¨¡å¼')
    parser.add_argument('--config', default='configs.yml',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: configs.yml)')
    parser.add_argument('--data-path', default='data',
                       help='æ•°æ®ç›®å½•è·¯å¾„ (é»˜è®¤: data)')
    
    args = parser.parse_args()
    
    # å¦‚æœæ˜¯äº¤äº’å¼æ¨¡å¼ï¼Œç›´æ¥å¯åŠ¨
    if args.mode == 'interactive':
        await interactive_mode()
        return
    
    # æ˜¾ç¤ºæ¨¡å¼ä¿¡æ¯
    mode_descriptions = {
        'full': 'ğŸ”„ å®Œæ•´æ¨¡å¼ - æ–‡æ¡£è§£æ + çŸ¥è¯†åº“æ„å»º + é—®ç­”ç³»ç»Ÿ',
        'build': 'ğŸ”¨ æ„å»ºæ¨¡å¼ - ä»…é‡å»ºçŸ¥è¯†åº“å’Œå‘é‡ç´¢å¼•',
        'qa': 'ğŸ’¬ é—®ç­”æ¨¡å¼ - ä½¿ç”¨å·²æœ‰æ•°æ®å¯åŠ¨é—®ç­”ç³»ç»Ÿ'
    }
    
    print(f"\n{mode_descriptions[args.mode]}")
    print(f"ğŸ“ é…ç½®æ–‡ä»¶: {args.config}")
    print(f"ğŸ“‚ æ•°æ®ç›®å½•: {args.data_path}")
    print("=" * 60)
    
    demo = None
    try:
        # åˆ›å»ºæ¼”ç¤ºç³»ç»Ÿ
        demo = AgenticXGraphRAGDemo(config_path=args.config, mode=args.mode)
        
        # æ ¹æ®æ¨¡å¼è¿è¡Œ
        if args.mode == 'qa':
            await demo.run_qa_only()
        elif args.mode == 'build':
            await demo.run_build_only()
        else:  # full
            await demo.run_demo()
        
    except Exception as e:
        print_error(f"ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {e}")
        sys.exit(1)
    finally:
        # æ¸…ç†èµ„æº
        if demo:
            await demo.cleanup()


if __name__ == "__main__":
    # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
    asyncio.run(main())