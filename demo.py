import os
os.environ['GRPC_VERBOSITY'] = 'ERROR'
os.environ['GLOG_minloglevel'] = '2'

#!/usr/bin/env python3
"""
AgenticX GraphRAG æ¼”ç¤ºç³»ç»Ÿä¸»ç¨‹åº

åŸºäº AgenticX æ ¸å¿ƒæ¨¡å—çš„å®Œæ•´ GraphRAG å®ç°ï¼ŒåŒ…æ‹¬ï¼š
- æ–‡æ¡£è§£æå’Œæ™ºèƒ½åˆ†å—
- å±‚çº§åŒ–çŸ¥è¯†å›¾è°±æ„å»º
- å¤šæ¨¡æ€å­˜å‚¨å’Œç´¢å¼•
- æ™ºèƒ½æ··åˆæ£€ç´¢
- äº¤äº’å¼é—®ç­”ç³»ç»Ÿ
"""
import absl.logging
absl.logging.set_verbosity('info')

import sys
import yaml
import asyncio
import warnings
import time
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime, timezone
from loguru import logger

# å¯¼å…¥ Rich ç¾åŒ–åº“
try:
    from rich.console import Console
    from rich.panel import Panel
    from rich.text import Text
    from rich.table import Table
    from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn
    from rich.layout import Layout
    from rich.align import Align
    from rich.rule import Rule
    from rich import box
    from rich.prompt import Prompt, Confirm
    try:
        from pyboxen import boxen
    except ImportError:
        boxen = None
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€ç‰ˆæœ¬
    Console = None
    Panel = None
    Table = None
    Text = None
    Progress = None
    SpinnerColumn = None
    TextColumn = None
    BarColumn = None
    TimeElapsedColumn = None
    Layout = None
    Align = None
    Rule = None
    box = None
    Prompt = None
    Confirm = None
    boxen = None

# è¿‡æ»¤è­¦å‘Šä¿¡æ¯
warnings.filterwarnings("ignore", category=DeprecationWarning, module="importlib._bootstrap")
warnings.filterwarnings("ignore", message=".*datetime.datetime.utcnow.*")
warnings.filterwarnings("ignore", message=".*SwigPy.*")
warnings.filterwarnings("ignore", message=".*builtin type.*has no __module__ attribute.*")
warnings.filterwarnings("ignore", category=DeprecationWarning, module="neo4j")
warnings.filterwarnings("ignore", message=".*session.*")
warnings.filterwarnings("ignore", message=".*connection.*")

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
# ç¡®ä¿ä»è„šæœ¬æ‰€åœ¨ç›®å½•åŠ è½½ .env æ–‡ä»¶
script_dir = Path(__file__).parent
env_path = script_dir / ".env"
load_dotenv(env_path)

# å¯¼å…¥ os æ¨¡å—ç”¨äºç¯å¢ƒå˜é‡
import os

# AgenticX æ ¸å¿ƒæ¨¡å—å¯¼å…¥
from agenticx.knowledge import (
    Knowledge,
    Document,
    DocumentProcessor,
    KnowledgeGraphBuilder,   SemanticChunker,
    AgenticChunker,
    get_chunker
)
from agenticx.knowledge.readers import (
    PDFReader,
    TextReader,
    JSONReader,
    CSVReader,
    WordReader,
    PowerPointReader
)
from agenticx.embeddings import (
    EmbeddingRouter,
    OpenAIEmbeddingProvider,
    SiliconFlowEmbeddingProvider,
    BailianEmbeddingProvider
)
from agenticx.storage import (
    StorageManager,
    StorageConfig,
    StorageType,
    Neo4jStorage,
    ChromaStorage,
    RedisStorage
)
from agenticx.storage.vectordb_storages.base import VectorRecord
from agenticx.retrieval import (
    HybridRetriever,
    GraphRetriever,
    GraphVectorConfig,
    VectorRetriever,
    BM25Retriever,
    AutoRetriever,
    Reranker,
    QueryAnalysisAgent,
    RetrievalAgent
)
from agenticx.llms import LlmFactory

# å¯¼å…¥æœ¬åœ°æ¨¡å—
from prompt_manager import PromptManager

# åˆ›å»º Rich Console å®ä¾‹
console = Console() if Console else None

# ANSI é¢œè‰²ä»£ç ï¼ˆä¿ç•™ä½œä¸ºåå¤‡ï¼‰
class Colors:
    RESET = '\033[0m'
    BOLD = '\033[1m'
    DIM = '\033[2m'
    
    # åŸºç¡€é¢œè‰²
    BLACK = '\033[30m'
    RED = '\033[31m'
    GREEN = '\033[32m'
    YELLOW = '\033[33m'
    BLUE = '\033[34m'
    MAGENTA = '\033[35m'
    CYAN = '\033[36m'
    WHITE = '\033[37m'
    
    # äº®è‰²
    BRIGHT_BLACK = '\033[90m'
    BRIGHT_RED = '\033[91m'
    BRIGHT_GREEN = '\033[92m'
    BRIGHT_YELLOW = '\033[93m'
    BRIGHT_BLUE = '\033[94m'
    BRIGHT_MAGENTA = '\033[95m'
    BRIGHT_CYAN = '\033[96m'
    BRIGHT_WHITE = '\033[97m'

def print_thinking(message: str):
    """æ˜¾ç¤ºAIæ€è€ƒè¿‡ç¨‹ï¼ˆç™½è‰²ç‚¹ï¼‰"""
    if console:
        console.print(f"â— {message}", style="white dim")
    else:
        print(f"{Colors.WHITE}â— {Colors.DIM}{message}{Colors.RESET}")

def print_action(message: str):
    """æ˜¾ç¤ºå·¥å…·è°ƒç”¨ï¼ˆç»¿è‰²ç‚¹ï¼‰"""
    if console:
        console.print(f"â— {message}", style="green")
    else:
        print(f"{Colors.BRIGHT_GREEN}â— {message}{Colors.RESET}")

def print_error(message: str):
    """æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯ï¼ˆçº¢è‰²ï¼‰"""
    if console:
        console.print(f"â— {message}", style="bright_red bold")
    else:
        print(f"{Colors.BRIGHT_RED}â— {message}{Colors.RESET}")

def print_success(message: str):
    """æ˜¾ç¤ºæˆåŠŸä¿¡æ¯ï¼ˆç»¿è‰²ç‚¹ï¼‰"""
    if console:
        console.print(f"â— {message}", style="bright_green bold")
    else:
        print(f"{Colors.BRIGHT_GREEN}â— {message}{Colors.RESET}")

def print_info(message: str):
    """æ˜¾ç¤ºä¿¡æ¯ï¼ˆç™½è‰²ç‚¹ï¼‰"""
    if console:
        console.print(f"â— {message}", style="white")
    else:
        print(f"{Colors.WHITE}â— {message}{Colors.RESET}")

def print_mode_selection(message: str):
    """æ˜¾ç¤ºæ¨¡å¼é€‰æ‹©ï¼ˆæ©™è‰²ç‚¹ï¼‰"""
    if console:
        console.print(f"â— {message}", style="bright_yellow bold")
    else:
        print(f"{Colors.BRIGHT_YELLOW}â— {message}{Colors.RESET}")

def print_welcome():
    """æ˜¾ç¤ºæ¬¢è¿ç•Œé¢"""
    # AgenticX-GraphRAG ASCII Logo
    graphrag_logo = """

 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—
â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â• â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘      â•šâ–ˆâ–ˆâ–ˆâ•”â• 
â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘      â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— 
â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•—
â•šâ•â•  â•šâ•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•â•   â•šâ•â•   â•šâ•â• â•šâ•â•â•â•â•â•â•šâ•â•  â•šâ•â•

â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— 
â–ˆâ–ˆâ•”â•â•â•â•â• â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â• 
â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•—
â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â• â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘
â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•     â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â• â•šâ•â•â•â•â•â• 
                                                                      
    """
    
    if console and Panel:
        # ä½¿ç”¨ Rich æ˜¾ç¤ºæ´»åŠ›æ©™è‰²ä¸»é¢˜çš„ logo å’Œä¿¡æ¯
        console.print(graphrag_logo, style="bold #FF6B35")
        
        # ç¯å¢ƒé…ç½®ä¿¡æ¯
        api_key = os.getenv('BAILIAN_API_KEY', 'sk-***')
        api_key_display = f"{api_key[:8]}..." if len(api_key) > 8 else api_key
        
        console.print("â— æ™ºèƒ½çŸ¥è¯†å›¾è°±é—®ç­”ç³»ç»Ÿ:", style="bold #FF6B35")
        console.print("  â¿  æ–‡æ¡£è§£æ + çŸ¥è¯†å›¾è°±æ„å»º + æ··åˆæ£€ç´¢ + æ™ºèƒ½é—®ç­”", style="dim")
        console.print("  â¿  æ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼ï¼šPDFã€Wordã€PPTã€TXT", style="dim")
        console.print("  â¿  å¤šè·³æ¨ç†ã€å®ä½“å…³ç³»æŸ¥è¯¢ã€ç¤¾åŒºå‘ç°\n", style="dim")
        
        console.print("â— ç¯å¢ƒé…ç½®:", style="bold #FF6B35")
        console.print(f"  â¿  API Key: {api_key_display}", style="dim")
        console.print(f"  â¿  å·¥ä½œç›®å½•: {os.getcwd()}", style="dim")
        console.print(f"  â¿  é…ç½®æ–‡ä»¶: configs.yml\n", style="dim")

    elif boxen:
        # ä½¿ç”¨ pyboxen åˆ›å»ºæ¡†æ¡†
        print(graphrag_logo)
        content = (
            "ğŸš€ AgenticX GraphRAG æ™ºèƒ½çŸ¥è¯†å›¾è°±é—®ç­”ç³»ç»Ÿ\n\n"
            "åŠŸèƒ½ç‰¹æ€§:\n"
            "â— æ–‡æ¡£è§£æ + çŸ¥è¯†å›¾è°±æ„å»º + æ··åˆæ£€ç´¢ + æ™ºèƒ½é—®ç­”\n"
            "â— æ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼ï¼šPDFã€Wordã€PPTã€TXT\n"
            "â— å¤šè·³æ¨ç†ã€å®ä½“å…³ç³»æŸ¥è¯¢ã€ç¤¾åŒºå‘ç°\n\n"
            "ç¯å¢ƒé…ç½®:\n"
            f"â— API Key: {os.getenv('BAILIAN_API_KEY', 'sk-***')[:8]}...\n"
            f"â— å·¥ä½œç›®å½•: {os.getcwd()}\n"
            f"â— é…ç½®æ–‡ä»¶: configs.yml"
        )
        print(boxen(
            content,
            title="AgenticX-GraphRAG",
            title_alignment="center",
            style="rounded",
            color="orange",
            padding=1
        ))
    else:
        # åå¤‡æ–¹æ¡ˆï¼šä½¿ç”¨åŸå§‹çš„ ASCII è‰ºæœ¯
        print(graphrag_logo)
        print(f"""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸš€ AgenticX GraphRAG æ™ºèƒ½çŸ¥è¯†å›¾è°±é—®ç­”ç³»ç»Ÿ                    â”‚
â”‚                                                             â”‚
â”‚ åŠŸèƒ½ç‰¹æ€§:                                                   â”‚
â”‚ â— æ–‡æ¡£è§£æ + çŸ¥è¯†å›¾è°±æ„å»º + æ··åˆæ£€ç´¢ + æ™ºèƒ½é—®ç­”              â”‚
â”‚ â— æ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼ï¼šPDFã€Wordã€PPTã€TXT                     â”‚
â”‚ â— å¤šè·³æ¨ç†ã€å®ä½“å…³ç³»æŸ¥è¯¢ã€ç¤¾åŒºå‘ç°                          â”‚
â”‚                                                             â”‚
â”‚ ç¯å¢ƒé…ç½®:                                                   â”‚
â”‚ â— API Key: {os.getenv('BAILIAN_API_KEY', 'sk-***')[:8]}...{' ' * (43 - len(os.getenv('BAILIAN_API_KEY', 'sk-***')[:8]))} â”‚
â”‚ â— å·¥ä½œç›®å½•: {os.getcwd():<51} â”‚
â”‚ â— é…ç½®æ–‡ä»¶: configs.yml{' ' * 42} â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")

def print_help():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
    if console and Table and box:
        # ä½¿ç”¨ Rich åˆ›å»ºç¾è§‚çš„å¸®åŠ©è¡¨æ ¼
        table = Table(title="[bold #FF6B35]å¯ç”¨å‘½ä»¤[/bold #FF6B35]", box=box.ROUNDED)
        table.add_column("å‘½ä»¤", style="bold #FF6B35", width=12)
        table.add_column("æè¿°", style="white")
        
        table.add_row("/help", "æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯")
        table.add_row("/clear", "æ¸…å±")
        table.add_row("/mode", "é€‰æ‹©è¿è¡Œæ¨¡å¼å¹¶åˆå§‹åŒ–ç³»ç»Ÿ")
        table.add_row("/data", "é€‰æ‹©æ–‡æ¡£è·¯å¾„")
        table.add_row("/rebuild", "ç«‹å³é‡æ–°æ„å»ºçŸ¥è¯†åº“")
        table.add_row("/exit", "é€€å‡ºç¨‹åº")
        table.add_row("", "")
        table.add_row("[dim]ç›´æ¥è¾“å…¥[/dim]", "[dim]è¾“å…¥é—®é¢˜å¼€å§‹æ™ºèƒ½é—®ç­”[/dim]")
        
        console.print(table)
    elif boxen:
        # ä½¿ç”¨ pyboxen åˆ›å»ºå¸®åŠ©æ¡†
        content = (
            "å¯ç”¨å‘½ä»¤:\n\n"
            "/help     æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯\n"
            "/clear    æ¸…å±\n"
            "/mode     é€‰æ‹©è¿è¡Œæ¨¡å¼å¹¶åˆå§‹åŒ–ç³»ç»Ÿ\n"
            "/data     é€‰æ‹©æ–‡æ¡£è·¯å¾„\n"
            "/rebuild  ç«‹å³é‡æ–°æ„å»ºçŸ¥è¯†åº“\n"
            "/exit     é€€å‡ºç¨‹åº\n\n"
            "ç›´æ¥è¾“å…¥é—®é¢˜å¼€å§‹æ™ºèƒ½é—®ç­”"
        )
        print(boxen(
            content,
            title="å¸®åŠ©",
            style="rounded",
            color="orange",
            padding=1
        ))
    else:
        # åå¤‡æ–¹æ¡ˆ
        print(f"""
{Colors.BOLD}å¯ç”¨å‘½ä»¤:{Colors.RESET}

/help     æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
/clear    æ¸…å±
/mode     é€‰æ‹©è¿è¡Œæ¨¡å¼å¹¶åˆå§‹åŒ–ç³»ç»Ÿ
/data     é€‰æ‹©æ–‡æ¡£è·¯å¾„
/rebuild  ç«‹å³é‡æ–°æ„å»ºçŸ¥è¯†åº“
/exit     é€€å‡ºç¨‹åº

ç›´æ¥è¾“å…¥é—®é¢˜å¼€å§‹æ™ºèƒ½é—®ç­”
""")

def scan_data_directories() -> Dict[str, List[Dict[str, Any]]]:
    """æ‰«ææ•°æ®ç›®å½•ï¼Œè¿”å›æ–‡ä»¶ä¿¡æ¯"""
    data_dirs = ["data", "data2"]
    file_info = {}
    
    for data_dir in data_dirs:
        dir_path = Path(data_dir)
        if dir_path.exists():
            files = []
            for file_path in dir_path.iterdir():
                if file_path.is_file():
                    stat = file_path.stat()
                    files.append({
                        "name": file_path.name,
                        "path": str(file_path),
                        "size": stat.st_size,
                        "size_mb": round(stat.st_size / (1024 * 1024), 2),
                        "type": file_path.suffix.lower(),
                        "modified": datetime.fromtimestamp(stat.st_mtime).strftime("%Y-%m-%d %H:%M")
                    })
            file_info[data_dir] = files
    
    return file_info

def display_data_selection() -> str:
    """æ˜¾ç¤ºæ•°æ®ç›®å½•é€‰æ‹©ç•Œé¢"""
    file_info = scan_data_directories()
    
    if console and Table and box:
        # ä½¿ç”¨ Rich æ˜¾ç¤ºæ–‡ä»¶é€‰æ‹©è¡¨æ ¼
        table = Table(title="[bold #FF6B35]ğŸ“ å¯ç”¨æ–‡æ¡£ç›®å½•[/bold #FF6B35]", box=box.ROUNDED)
        table.add_column("ç›®å½•", style="bold #FF6B35", width=10)
        table.add_column("æ–‡ä»¶æ•°", style="bold #FF6B35", width=8)
        table.add_column("æ–‡ä»¶åˆ—è¡¨", style="white")
        
        for dir_name, files in file_info.items():
            file_list = []
            for file in files:
                file_list.append(f"{file['name']} ({file['size_mb']}MB)")
            
            table.add_row(
                dir_name,
                str(len(files)),
                "\n".join(file_list) if file_list else "æ— æ–‡ä»¶"
            )
        
        console.print(table)
        
        # æ˜¾ç¤ºè¯¦ç»†æ–‡ä»¶ä¿¡æ¯
        for dir_name, files in file_info.items():
            if files:
                detail_table = Table(title=f"[bold #FF6B35]{dir_name}/ ç›®å½•è¯¦æƒ…[/bold #FF6B35]", box=box.SIMPLE)
                detail_table.add_column("æ–‡ä»¶å", style="cyan")
                detail_table.add_column("å¤§å°", style="bold #FF6B35")
                detail_table.add_column("ç±»å‹", style="magenta")
                detail_table.add_column("ä¿®æ”¹æ—¶é—´", style="dim")
                
                for file in files:
                    detail_table.add_row(
                        file['name'],
                        f"{file['size_mb']} MB",
                        file['type'].upper(),
                        file['modified']
                    )
                
                console.print(detail_table)
                console.print()
    
    # é€‰æ‹©ç›®å½•
    available_dirs = [dir_name for dir_name, files in file_info.items() if files]
    
    if not available_dirs:
        print_error("æœªæ‰¾åˆ°å¯ç”¨çš„æ–‡æ¡£ç›®å½•")
        return "data"  # é»˜è®¤è¿”å› data ç›®å½•
    
    if len(available_dirs) == 1:
        print_info(f"è‡ªåŠ¨é€‰æ‹©å”¯ä¸€å¯ç”¨ç›®å½•: {available_dirs[0]}")
        return available_dirs[0]
    
    # å¤šä¸ªç›®å½•æ—¶è®©ç”¨æˆ·é€‰æ‹©
    if console and Prompt:
        choices = "/".join(available_dirs)
        selected = Prompt.ask(
            f"è¯·é€‰æ‹©æ–‡æ¡£ç›®å½• ({choices})",
            choices=available_dirs,
            default=available_dirs[0]
        )
        return selected
    else:
        print(f"å¯ç”¨ç›®å½•: {', '.join(available_dirs)}")
        while True:
            choice = input(f"è¯·é€‰æ‹©ç›®å½• ({'/'.join(available_dirs)}): ").strip()
            if choice in available_dirs:
                return choice
            elif not choice and available_dirs:
                return available_dirs[0]
            print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

def select_run_mode() -> str:
    """é€‰æ‹©è¿è¡Œæ¨¡å¼"""
    if console and Panel and Text and box:
        mode_text = Text()
        mode_text.append("1. Full Mode", style="bold green")
        mode_text.append(" - å®Œæ•´æµç¨‹ï¼ˆæ–‡æ¡£è§£æ + çŸ¥è¯†åº“æ„å»º + é—®ç­”ï¼‰\n", style="white")
        mode_text.append("   é€‚ç”¨: é¦–æ¬¡è¿è¡Œæˆ–éœ€è¦é‡æ–°å¤„ç†æ–‡æ¡£\n", style="dim")
        
        mode_text.append("2. Build Mode", style="bold #FF6B35")
        mode_text.append(" - ä»…æ„å»ºæ¨¡å¼ï¼ˆæ–‡æ¡£è§£æ + çŸ¥è¯†åº“æ„å»ºï¼‰\n", style="white")
        mode_text.append("   é€‚ç”¨: åªéœ€è¦æ„å»ºçŸ¥è¯†åº“ï¼Œä¸å¯åŠ¨é—®ç­”\n", style="dim")
        
        mode_text.append("3. QA Mode", style="bold magenta")
        mode_text.append(" - ä»…é—®ç­”æ¨¡å¼ï¼ˆä½¿ç”¨å·²æœ‰çŸ¥è¯†åº“ï¼‰\n", style="white")
        mode_text.append("   é€‚ç”¨: çŸ¥è¯†åº“å·²å­˜åœ¨ï¼Œç›´æ¥å¼€å§‹é—®ç­”\n", style="dim")
        
        panel = Panel(
            mode_text,
            title="é€‰æ‹©è¿è¡Œæ¨¡å¼",
            border_style="#FF6B35",
            box=box.ROUNDED,
            padding=(1, 2)
        )
        console.print(panel)
    elif boxen:
        content = (
            "é€‰æ‹©è¿è¡Œæ¨¡å¼:\n\n"
            "1. Full Mode - å®Œæ•´æµç¨‹ï¼ˆæ–‡æ¡£è§£æ + çŸ¥è¯†åº“æ„å»º + é—®ç­”ï¼‰\n"
            "   é€‚ç”¨: é¦–æ¬¡è¿è¡Œæˆ–éœ€è¦é‡æ–°å¤„ç†æ–‡æ¡£\n\n"
            "2. Build Mode - ä»…æ„å»ºæ¨¡å¼ï¼ˆæ–‡æ¡£è§£æ + çŸ¥è¯†åº“æ„å»ºï¼‰\n"
            "   é€‚ç”¨: åªéœ€è¦æ„å»ºçŸ¥è¯†åº“ï¼Œä¸å¯åŠ¨é—®ç­”\n\n"
            "3. QA Mode - ä»…é—®ç­”æ¨¡å¼ï¼ˆä½¿ç”¨å·²æœ‰çŸ¥è¯†åº“ï¼‰\n"
            "   é€‚ç”¨: çŸ¥è¯†åº“å·²å­˜åœ¨ï¼Œç›´æ¥å¼€å§‹é—®ç­”"
        )
        print(boxen(
            content,
            title="è¿è¡Œæ¨¡å¼é€‰æ‹©",
            style="rounded",
            color="orange",
            padding=1
        ))
    else:
        print("""
é€‰æ‹©è¿è¡Œæ¨¡å¼:

1. Full Mode - å®Œæ•´æµç¨‹ï¼ˆæ–‡æ¡£è§£æ + çŸ¥è¯†åº“æ„å»º + é—®ç­”ï¼‰
   é€‚ç”¨: é¦–æ¬¡è¿è¡Œæˆ–éœ€è¦é‡æ–°å¤„ç†æ–‡æ¡£

2. Build Mode - ä»…æ„å»ºæ¨¡å¼ï¼ˆæ–‡æ¡£è§£æ + çŸ¥è¯†åº“æ„å»ºï¼‰
   é€‚ç”¨: åªéœ€è¦æ„å»ºçŸ¥è¯†åº“ï¼Œä¸å¯åŠ¨é—®ç­”

3. QA Mode - ä»…é—®ç­”æ¨¡å¼ï¼ˆä½¿ç”¨å·²æœ‰çŸ¥è¯†åº“ï¼‰
   é€‚ç”¨: çŸ¥è¯†åº“å·²å­˜åœ¨ï¼Œç›´æ¥å¼€å§‹é—®ç­”
""")
    
    mode_map = {"1": "full", "2": "build", "3": "qa"}
    
    if console and Prompt:
        choice = Prompt.ask(
            "è¯·é€‰æ‹©æ¨¡å¼",
            choices=["1", "2", "3"],
            default="1"
        )
        return mode_map[choice]
    else:
        while True:
            try:
                choice = input("\nè¯·é€‰æ‹©æ¨¡å¼ (1-3): ").strip()
                if choice == '' or choice == '1':
                    return 'full'
                elif choice == '2':
                    return 'build'
                elif choice == '3':
                    return 'qa'
                else:
                    print("è¯·è¾“å…¥ 1ã€2 æˆ– 3")
            except (EOFError, KeyboardInterrupt):
                return 'full'


class AgenticXGraphRAGDemo:
    """AgenticX GraphRAG æ¼”ç¤ºç³»ç»Ÿä¸»ç±»"""
    
    def __init__(self, config_path: str = "configs.yml", mode: str = "full"):
        """åˆå§‹åŒ–æ¼”ç¤ºç³»ç»Ÿ"""
        self.config_path = config_path
        self.mode = mode  # è¿è¡Œæ¨¡å¼ï¼šfull æˆ– qa
        self.config = self._load_config()
        self.logger = self._setup_logging()
        
        # æ ¸å¿ƒç»„ä»¶
        self.llm_client = None
        self.embedding_router = None
        self.storage_manager = None
        self.knowledge_graph = None
        self.retriever = None
        
        # æç¤ºè¯ç®¡ç†å™¨
        self.prompt_manager = PromptManager("prompts")
        
        # æ•°æ®è·¯å¾„
        self.data_dir = Path("./data")
        self.workspace_dir = Path(self.config['system']['workspace']['base_dir'])
        
        self.logger.info(f"AgenticX GraphRAG æ¼”ç¤ºç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ (æ¨¡å¼: {self.mode})")
    
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        config_file = Path(self.config_path)
        if not config_file.exists():
            # å¦‚æœå½“å‰ç›®å½•æ²¡æœ‰é…ç½®æ–‡ä»¶ï¼Œå°è¯•ä»æ–‡æ¡£ç›®å½•åŠ è½½
            config_file = Path(".trae/documents/configs.yml")
            
        if not config_file.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {self.config_path}")
            
        with open(config_file, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
            
        # ç¯å¢ƒå˜é‡æ›¿æ¢
        self._replace_env_vars(config)
        
        return config
    
    def _replace_env_vars(self, obj: Any) -> None:
        """é€’å½’æ›¿æ¢é…ç½®ä¸­çš„ç¯å¢ƒå˜é‡"""
        if isinstance(obj, dict):
            for key, value in obj.items():
                if isinstance(value, str) and value.startswith('${') and value.endswith('}'):
                    env_var = value[2:-1]
                    obj[key] = os.getenv(env_var, value)
                else:
                    self._replace_env_vars(value)
        elif isinstance(obj, list):
            for item in obj:
                self._replace_env_vars(item)
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        # è¿‡æ»¤æ‰ç‰¹å®šçš„è­¦å‘Š
        warnings.filterwarnings("ignore", category=DeprecationWarning, module="importlib._bootstrap")
        warnings.filterwarnings("ignore", message=".*datetime.datetime.utcnow.*")
        warnings.filterwarnings("ignore", message=".*SwigPy.*")
        
        log_config = self.config.get('monitoring', {}).get('logging', {})
        
        # åˆ›å»ºæ—¥å¿—ç›®å½•
        log_dir = Path(self.config['system']['workspace']['logs_dir'])
        log_dir.mkdir(parents=True, exist_ok=True)
        
        # ç§»é™¤é»˜è®¤çš„loguruå¤„ç†å™¨
        logger.remove()
        
        # é…ç½®æ§åˆ¶å°è¾“å‡º
        logger.add(
            sys.stdout,
            level=log_config.get('level', 'DEBUG'),  # ä¸´æ—¶å¯ç”¨DEBUGçº§åˆ«
            format="<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
            colorize=True
        )
        
        # é…ç½®æ–‡ä»¶è¾“å‡º
        logger.add(
            log_dir / "agenticx_graphrag.log",
            level=log_config.get('level', 'INFO'),
            format="{time:YYYY-MM-DD HH:mm:ss.SSS} | {level: <8} | {name}:{function}:{line} - {message}",
            rotation="10 MB",
            retention="7 days",
            compression="zip"
        )
        
        return logger
    
    async def initialize_components(self) -> None:
        """åˆå§‹åŒ–æ‰€æœ‰æ ¸å¿ƒç»„ä»¶"""
        self.logger.info("å¼€å§‹åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶...")
        
        # 1. åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
        await self._initialize_llm()
        
        # 2. åˆå§‹åŒ–åµŒå…¥æœåŠ¡
        await self._initialize_embeddings()
        
        # 3. åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨
        await self._initialize_storage()
        
        # 4. åˆå§‹åŒ–æ£€ç´¢å™¨
        await self._initialize_retriever()
        
        self.logger.info("ç³»ç»Ÿç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
    
    async def _initialize_llm(self) -> None:
        """åˆå§‹åŒ– LLM å®¢æˆ·ç«¯"""
        from agenticx.knowledge.graphers.config import LLMConfig
        
        llm_config_dict = self.config['llm']
        provider = llm_config_dict.get('provider', 'litellm')
        
        # æä¾›å•†ç±»å‹æ˜ å°„
        provider_type_mapping = {
            'openai': 'litellm',
            'anthropic': 'litellm', 
            'litellm': 'litellm',
            'bailian': 'bailian',
            'kimi': 'kimi'
        }
        
        llm_type = provider_type_mapping.get(provider, 'litellm')
        
        # å°†å­—å…¸é…ç½®è½¬æ¢ä¸º LLMConfig å¯¹è±¡
        llm_config = LLMConfig(
            type=llm_type,
            model=llm_config_dict.get('model'),
            api_key=llm_config_dict.get('api_key'),
            base_url=llm_config_dict.get('base_url'),
            provider=provider,
            timeout=llm_config_dict.get('timeout'),
            max_retries=llm_config_dict.get('retry_attempts'),  # é…ç½®æ–‡ä»¶ä¸­æ˜¯retry_attempts
            temperature=llm_config_dict.get('temperature'),
            max_tokens=llm_config_dict.get('max_tokens')
        )
        
        self.llm_client = LlmFactory.create_llm(llm_config)
        self.logger.info(f"LLMåˆå§‹åŒ–å®Œæˆ: {llm_config.provider}/{llm_config.model}")
    
    async def _initialize_embeddings(self) -> None:
        """åˆå§‹åŒ–åµŒå…¥æœåŠ¡è·¯ç”±å™¨"""
        embed_config = self.config['embeddings']
        
        # åˆ›å»ºåµŒå…¥æä¾›å•†åˆ—è¡¨
        providers = []
        provider_names = []
        
        # æ ¹æ®é…ç½®çš„ä¼˜å…ˆçº§é¡ºåºæ·»åŠ æä¾›å•†
        router_config = embed_config.get('router', {})
        primary_provider = router_config.get('primary_provider', 'bailian')
        fallback_providers = router_config.get('fallback_providers', [])
        
        # æŒ‰ä¼˜å…ˆçº§é¡ºåºæ·»åŠ æä¾›å•†
        provider_order = [primary_provider] + fallback_providers
        
        for provider_name in provider_order:
            if provider_name == 'bailian' and 'bailian' in embed_config:
                config = embed_config['bailian']
                provider = BailianEmbeddingProvider(
                    api_key=config['api_key'],
                    model=config.get('model', 'text-embedding-v4'),
                    api_url=config.get('base_url'),
                    dimensions=config.get('dimensions', 1536),
                    batch_size=config.get('batch_size', 10)  # ä¿®å¤ï¼šæ·»åŠ batch_sizeå‚æ•°
                )
                providers.append(provider)
                provider_names.append('bailian')
                
            elif provider_name == 'openai' and 'openai' in embed_config:
                config = embed_config['openai']
                provider = OpenAIEmbeddingProvider(
                    api_key=config['api_key'],
                    model=config.get('model', 'text-embedding-3-small'),
                    base_url=config.get('base_url'),
                    dimensions=config.get('dimensions', 1536)
                )
                providers.append(provider)
                provider_names.append('openai')
                
            elif provider_name == 'siliconflow' and 'siliconflow' in embed_config:
                config = embed_config['siliconflow']
                provider = SiliconFlowEmbeddingProvider(
                    api_key=config['api_key'],
                    model=config.get('model', 'BAAI/bge-large-zh-v1.5'),
                    dimensions=config.get('dimensions', 1024)
                )
                providers.append(provider)
                provider_names.append('siliconflow')
        
        # åˆ›å»ºè·¯ç”±å™¨ï¼ˆåªä¼ å…¥providersåˆ—è¡¨ï¼‰
        self.embedding_router = EmbeddingRouter(providers=providers)
        
        self.logger.info(f"åµŒå…¥æœåŠ¡åˆå§‹åŒ–å®Œæˆ: {len(provider_names)}ä¸ªæä¾›å•†")

    async def _initialize_storage(self) -> None:
        """åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨"""
        from agenticx.storage import StorageConfig, StorageType
        
        storage_config = self.config['storage']
        configs = []
        
        # åŠ¨æ€è·å–åµŒå…¥ç»´åº¦
        embedding_dim = self.embedding_router.get_embedding_dim()
        self.logger.info(f"åŠ¨æ€è·å–çš„åµŒå…¥ç»´åº¦: {embedding_dim}")

        # é…ç½®å‘é‡å­˜å‚¨
        vector_config = storage_config['vector']
        if vector_config['provider'] == 'milvus':
            try:
                milvus_config = vector_config.get('milvus', {})
                # æ„å»ºextra_paramsï¼Œè¿‡æ»¤æ‰Noneå€¼
                # æ ¹æ®è¿è¡Œæ¨¡å¼å†³å®šæ˜¯å¦æ¸…ç†æ•°æ®
                recreate_if_exists = self.mode in ["full", "build"]  # fullå’Œbuildæ¨¡å¼é‡æ–°åˆ›å»ºï¼Œqaæ¨¡å¼ä¿ç•™
                
                extra_params = {
                    'dimension': embedding_dim,
                    'collection_name': milvus_config.get('collection_name', 'agenticx_graphrag'),
                    'database': milvus_config.get('database', 'default'),
                    'recreate_if_exists': recreate_if_exists  # æ ¹æ®æ¨¡å¼å†³å®šæ˜¯å¦é‡æ–°åˆ›å»º
                }
                
                # åªåœ¨usernameå’Œpasswordä¸ä¸ºNoneæ—¶æ‰æ·»åŠ 
                username = milvus_config.get('username')
                password = milvus_config.get('password')
                if username is not None:
                    extra_params['username'] = username
                if password is not None:
                    extra_params['password'] = password
                
                # ç®€åŒ–æ—¥å¿—ï¼šåªè®°å½•å…³é”®ä¿¡æ¯
                self.logger.debug(f"Milvusé…ç½®: {milvus_config.get('host', 'localhost')}:{milvus_config.get('port', 19530)}")
                
                configs.append(StorageConfig(
                    storage_type=StorageType.MILVUS,
                    host=milvus_config.get('host', 'localhost'),
                    port=milvus_config.get('port', 19530),
                    extra_params=extra_params
                ))
            except Exception as e:
                self.logger.error(f"âŒ é…ç½®Milvuså­˜å‚¨å¤±è´¥: {e}")
                self.logger.warning(f"âš ï¸ Milvusé…ç½®å¤±è´¥: {e}ï¼Œå›é€€åˆ°Chroma")
                # å›é€€åˆ°Chroma
                chroma_config = vector_config.get('chroma', {})
                configs.append(StorageConfig(
                    storage_type=StorageType.CHROMA,
                    extra_params={
                        'dimension': embedding_dim,
                        'persist_directory': chroma_config.get('persist_directory', './storage/chroma'),
                        'collection_name': chroma_config.get('collection_name', 'agenticx_graphrag')
                    }
                ))
                self.logger.info("âœ… é…ç½®Chromaå‘é‡å­˜å‚¨ï¼ˆå›é€€ï¼‰")
        elif vector_config['provider'] == 'chroma':
            chroma_config = vector_config['chroma'].copy()
            configs.append(StorageConfig(
                storage_type=StorageType.CHROMA,
                extra_params={
                    'dimension': embedding_dim,
                    'persist_directory': chroma_config.get('persist_directory', './storage/chroma'),
                    'collection_name': chroma_config.get('collection_name', 'agenticx_graphrag')
                }
            ))
            self.logger.info("âœ… é…ç½®Chromaå‘é‡å­˜å‚¨")
        elif vector_config['provider'] == 'faiss':
            configs.append(StorageConfig(
                storage_type=StorageType.FAISS,
                extra_params={
                    'dimension': embedding_dim,  # ä½¿ç”¨åŠ¨æ€è·å–çš„ç»´åº¦
                    'index_path': './storage/faiss_index'
                }
            ))
            self.logger.info("âœ… é…ç½®FAISSå‘é‡å­˜å‚¨")
        
        # é…ç½®å›¾å­˜å‚¨
        graph_config = storage_config['graph']
        if graph_config['provider'] == 'neo4j':
            neo4j_config = graph_config['neo4j'].copy()
            
            # å¤„ç†URIæ ¼å¼çš„é…ç½®
            uri = neo4j_config.get('uri', 'bolt://localhost:7687')
            # å°†å®¹å™¨åneo4jæ›¿æ¢ä¸ºlocalhostï¼ˆç”¨äºå¤–éƒ¨è®¿é—®ï¼‰
            if 'neo4j:' in uri:
                uri = uri.replace('neo4j:', 'localhost:')
            
            configs.append(StorageConfig(
                storage_type=StorageType.NEO4J,
                connection_string=uri,
                username=neo4j_config.get('username', 'neo4j'),
                password=neo4j_config.get('password', None),
                database=neo4j_config.get('database', 'neo4j'),
                extra_params={
                    'max_connection_lifetime': neo4j_config.get('max_connection_lifetime', 3600),
                    'max_connection_pool_size': neo4j_config.get('max_connection_pool_size', 50),
                    'connection_acquisition_timeout': neo4j_config.get('connection_acquisition_timeout', 60)
                }
            ))
        
        # é…ç½®é”®å€¼å­˜å‚¨
        kv_config = storage_config['key_value']
        if kv_config['provider'] == 'redis':
            redis_config = kv_config['redis'].copy()
            configs.append(StorageConfig(
                storage_type=StorageType.REDIS,
                host=redis_config.pop('host', 'localhost'),
                port=redis_config.pop('port', 6379),
                password=redis_config.pop('password', None),
                database=redis_config.pop('database', 0),
                **redis_config
            ))
        elif kv_config['provider'] == 'sqlite':
            sqlite_config = kv_config.get('sqlite', {})
            configs.append(StorageConfig(
                storage_type=StorageType.SQLITE,
                connection_string=sqlite_config.get('database_path', './storage/cache.db')
            ))
            self.logger.info("âœ… é…ç½®SQLiteé”®å€¼å­˜å‚¨")
        
        # åˆ›å»ºå­˜å‚¨ç®¡ç†å™¨
        self.storage_manager = StorageManager(configs=configs)
        await self.storage_manager.initialize()
        
        # è°ƒè¯•ï¼šæ£€æŸ¥é”®å€¼å­˜å‚¨æ˜¯å¦å¯ç”¨
        kv_storage = await self.storage_manager.get_key_value_storage('default')
        if kv_storage:
            self.logger.debug(f"é”®å€¼å­˜å‚¨: {type(kv_storage).__name__}")
        else:
            self.logger.warning("âš ï¸ é”®å€¼å­˜å‚¨ä¸å¯ç”¨")
    
    async def _initialize_retriever(self) -> None:
        """åˆå§‹åŒ–æ£€ç´¢å™¨"""
        from agenticx.storage import StorageType
        
        retrieval_config = self.config['retrieval']
        
        # ğŸ”§ ç¡®ä¿æ–‡æ¡£å‘é‡å­˜å‚¨å®ä¾‹å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
        if not hasattr(self, '_document_vector_storage') or not self._document_vector_storage:
            from agenticx.storage.vectordb_storages.milvus import MilvusStorage
            storage_config = self.config['storage']['vector']['milvus']
            self.logger.info(f"ğŸ”§ æ£€ç´¢å™¨åˆå§‹åŒ–: mode={self.mode}, æ–‡æ¡£å‘é‡å­˜å‚¨recreate_if_exists=False")
            self._document_vector_storage = MilvusStorage(
                dimension=1024,  # ä½¿ç”¨åµŒå…¥ç»´åº¦
                host=storage_config['host'],
                port=storage_config['port'],
                collection_name=storage_config['collection_name'],  # ä½¿ç”¨æ–‡æ¡£ä¸“ç”¨é›†åˆå
                database=storage_config.get('database', 'default'),
                username=storage_config.get('username'),
                password=storage_config.get('password'),
                recreate_if_exists=False  # æ£€ç´¢å™¨åˆå§‹åŒ–æ—¶ä¸é‡æ–°åˆ›å»º
            )
        
        # åˆ›å»ºå‘é‡æ£€ç´¢å™¨
        vector_retriever = VectorRetriever(
            tenant_id="default",
            vector_storage=self._document_vector_storage,  # ä½¿ç”¨ç»Ÿä¸€çš„æ–‡æ¡£å‘é‡å­˜å‚¨å®ä¾‹
            embedding_provider=self.embedding_router,
            **retrieval_config.get('vector', {})
        )
        
        self.logger.info(f"ğŸ“„ æ–‡æ¡£æ£€ç´¢å­˜å‚¨é›†åˆ: {storage_config['collection_name']}")
        
        # åˆ›å»ºBM25æ£€ç´¢å™¨
        bm25_retriever = BM25Retriever(
            tenant_id="default",
            **retrieval_config.get('bm25', {})
        )
        
        # åˆ›å»ºå¢å¼ºçš„å›¾æ£€ç´¢å™¨ï¼ˆæ”¯æŒå‘é‡ç´¢å¼•ï¼‰
        graph_storage = self.storage_manager.get_storage(StorageType.NEO4J)
        vector_storage = self.storage_manager.get_storage(StorageType.MILVUS)
        
        # ğŸ”§ ç¡®ä¿å›¾å‘é‡å­˜å‚¨å®ä¾‹å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
        if not hasattr(self, '_graph_vector_storage') or not self._graph_vector_storage:
            from agenticx.storage.vectordb_storages.milvus import MilvusStorage
            storage_config = self.config['storage']['vector']['milvus']
            # æ ¹æ®è¿è¡Œæ¨¡å¼å†³å®šæ˜¯å¦é‡æ–°åˆ›å»ºå›¾å‘é‡é›†åˆ
            recreate_graph_collection = self.mode in ["full", "build"]
            self.logger.info(f"ğŸ”§ å›¾å‘é‡å­˜å‚¨é…ç½®: mode={self.mode}, recreate_if_exists={recreate_graph_collection}")
            self._graph_vector_storage = MilvusStorage(
                dimension=1024,  # ä½¿ç”¨åµŒå…¥ç»´åº¦
                host=storage_config['host'],
                port=storage_config['port'],
                collection_name=storage_config['graph_collection_name'],  # ä½¿ç”¨å›¾ä¸“ç”¨é›†åˆå
                database=storage_config.get('database', 'default'),
                username=storage_config.get('username'),
                password=storage_config.get('password'),
                recreate_if_exists=recreate_graph_collection  # ğŸ”§ ä¿®å¤ï¼šæ ¹æ®æ¨¡å¼å†³å®šæ˜¯å¦é‡æ–°åˆ›å»º
            )
        
        # é…ç½®å›¾å‘é‡ç´¢å¼•
        graph_vector_config = GraphVectorConfig(
            enable_vector_indexing=True,
            **retrieval_config.get('graph', {}).get('vector_config', {})
        )
        
        graph_retriever = GraphRetriever(
            tenant_id="default",
            graph_storage=graph_storage,
            vector_storage=self._graph_vector_storage,  # ä½¿ç”¨ç»Ÿä¸€çš„å›¾å‘é‡å­˜å‚¨å®ä¾‹
            embedding_provider=self.embedding_router,
            vector_config=graph_vector_config,
            **retrieval_config.get('graph', {})
        )
        
        self.logger.info(f"ğŸ”— å›¾å‘é‡å­˜å‚¨é›†åˆ: {storage_config['graph_collection_name']}")
        
        # åˆ›å»ºä¸‰è·¯æ··åˆæ£€ç´¢å™¨
        from agenticx.retrieval.hybrid_retriever import HybridConfig
        hybrid_config = HybridConfig(**retrieval_config.get('hybrid', {}))
        self.retriever = HybridRetriever(
            vector_retriever=vector_retriever,
            bm25_retriever=bm25_retriever,
            graph_retriever=graph_retriever,  # é›†æˆå›¾æ£€ç´¢å™¨
            config=hybrid_config
        )
        
        # å­˜å‚¨å›¾æ£€ç´¢å™¨ä»¥å¤‡åç”¨
        self.graph_retriever = graph_retriever
        
        # å¦‚æœé…ç½®äº†é‡æ’åºå™¨ï¼Œæ·»åŠ é‡æ’åºå™¨
        if 'reranker' in retrieval_config:
            reranker = Reranker(retrieval_config['reranker'])
            # æ³¨æ„ï¼šHybridRetriever å¯èƒ½æ²¡æœ‰ set_reranker æ–¹æ³•ï¼Œè¿™é‡Œå…ˆæ³¨é‡Šæ‰
            # self.retriever.set_reranker(reranker)
        
        self.logger.debug("æ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def validate_data_path(self) -> List[Path]:
        """éªŒè¯æ•°æ®è·¯å¾„å¹¶è¿”å›æ–‡ä»¶åˆ—è¡¨"""
        self.logger.info(f"éªŒè¯æ•°æ®è·¯å¾„: {self.data_dir}")
        
        if not self.data_dir.exists():
            raise FileNotFoundError(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.data_dir}")
        
        # æ”¯æŒçš„æ–‡ä»¶ç±»å‹
        supported_extensions = {'.pdf', '.txt', '.json', '.csv', '.md', '.doc', '.docx', '.ppt', '.pptx'}
        
        # æ‰«ææ–‡ä»¶
        files = []
        for file_path in self.data_dir.rglob('*'):
            if file_path.is_file() and file_path.suffix.lower() in supported_extensions:
                files.append(file_path)
        
        if not files:
            raise ValueError(f"æ•°æ®ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {supported_extensions}")
        
        self.logger.info(f"æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶: {[f.name for f in files]}")
        return files
    
    async def load_documents(self, file_paths: List[Path]) -> List[Document]:
        """åŠ è½½æ–‡æ¡£"""
        self.logger.info(f"å¼€å§‹åŠ è½½ {len(file_paths)} ä¸ªæ–‡æ¡£...")
        
        documents = []
        reader_config = self.config['knowledge']['readers']
        
        for file_path in file_paths:
            try:
                # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©è¯»å–å™¨
                if file_path.suffix.lower() == '.pdf' and reader_config['pdf']['enabled']:
                    pdf_config = reader_config['pdf'].copy()
                    pdf_config.pop('enabled', None)  # ç§»é™¤enabledå­—æ®µ
                    reader = PDFReader(**pdf_config)
                elif file_path.suffix.lower() in ['.txt', '.md'] and reader_config['text']['enabled']:
                    text_config = reader_config['text'].copy()
                    text_config.pop('enabled', None)  # ç§»é™¤enabledå­—æ®µ
                    self.logger.debug(f"TextReaderé…ç½®: {text_config}")
                    reader = TextReader(**text_config)
                elif file_path.suffix.lower() == '.json' and reader_config['json']['enabled']:
                    json_config = reader_config['json'].copy()
                    json_config.pop('enabled', None)  # ç§»é™¤enabledå­—æ®µ
                    reader = JSONReader(**json_config)
                elif file_path.suffix.lower() == '.csv' and reader_config['csv']['enabled']:
                    csv_config = reader_config['csv'].copy()
                    csv_config.pop('enabled', None)  # ç§»é™¤enabledå­—æ®µ
                    reader = CSVReader(**csv_config)
                elif file_path.suffix.lower() in ['.doc', '.docx'] and reader_config.get('word', {}).get('enabled', True):
                    word_config = reader_config.get('word', {}).copy()
                    word_config.pop('enabled', None)  # ç§»é™¤enabledå­—æ®µ
                    reader = WordReader(**word_config)
                elif file_path.suffix.lower() in ['.ppt', '.pptx'] and reader_config.get('powerpoint', {}).get('enabled', True):
                    ppt_config = reader_config.get('powerpoint', {}).copy()
                    ppt_config.pop('enabled', None)  # ç§»é™¤enabledå­—æ®µ
                    reader = PowerPointReader(**ppt_config)
                else:
                    self.logger.warning(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹æˆ–å·²ç¦ç”¨: {file_path}")
                    continue
                
                # è¯»å–æ–‡æ¡£
                self.logger.debug(f"å¼€å§‹è¯»å–æ–‡æ¡£: {file_path}")
                result = await reader.read(str(file_path))
                self.logger.debug(f"è¯»å–ç»“æœç±»å‹: {type(result)}, å†…å®¹: {result if not isinstance(result, list) else f'åˆ—è¡¨é•¿åº¦: {len(result)}'}")
                
                # å¤„ç†è¿”å›ç»“æœï¼ˆå¯èƒ½æ˜¯å•ä¸ªæ–‡æ¡£æˆ–æ–‡æ¡£åˆ—è¡¨ï¼‰
                if isinstance(result, list):
                    # å¦‚æœè¿”å›çš„æ˜¯åˆ—è¡¨ï¼Œéå†æ¯ä¸ªæ–‡æ¡£
                    for doc in result:
                        documents.append(doc)
                        self.logger.info(f"æˆåŠŸåŠ è½½æ–‡æ¡£: {file_path.name} ({len(doc.content)} å­—ç¬¦)")
                else:
                    # å¦‚æœè¿”å›çš„æ˜¯å•ä¸ªæ–‡æ¡£
                    documents.append(result)
                    self.logger.info(f"æˆåŠŸåŠ è½½æ–‡æ¡£: {file_path.name} ({len(result.content)} å­—ç¬¦)")
                
            except Exception as e:
                self.logger.error(f"åŠ è½½æ–‡æ¡£å¤±è´¥ {file_path}: {e}")
                continue
        
        self.logger.info(f"æ–‡æ¡£åŠ è½½å®Œæˆ: {len(documents)}ä¸ªæ–‡æ¡£")
        return documents
    
    async def build_knowledge_graph(self, documents: List[Document]) -> None:
        """æ„å»ºçŸ¥è¯†å›¾è°±"""
        self.logger.info("å¼€å§‹æ„å»ºçŸ¥è¯†å›¾è°±")
        
        # æ‰“å°å…¥å‚ä¿¡æ¯
        doc_info = [f"{getattr(doc.metadata, 'title', None) or getattr(doc.metadata, 'name', 'Unknown')}({len(doc.content)}å­—ç¬¦)" for doc in documents]
        self.logger.info(f"è¾“å…¥æ–‡æ¡£: {len(documents)}ä¸ª - {', '.join(doc_info[:3])}{'...' if len(documents) > 3 else ''}")
        
        # ä¿å­˜documentsä»¥ä¾›å‘é‡ç´¢å¼•ä½¿ç”¨
        self.documents = documents
        
        # é…ç½® GraphRAG æ„é€ å™¨
        from agenticx.knowledge.graphers.config import LLMConfig, GraphRagConfig
        from agenticx.knowledge.base import ChunkingConfig
        
        graph_knowledge_config_dict = self.config['knowledge']['graph_knowledge']
        
        # æ‰“å°å…³é”®é…ç½®
        self.logger.info(f"é…ç½®å‚æ•°: extraction_method={graph_knowledge_config_dict.get('extraction_method', 'æœªè®¾ç½®')}, "
                        f"spo_batch_size={graph_knowledge_config_dict.get('spo_batch_size', 'æœªè®¾ç½®')}")
        
        # å°†å­—å…¸è½¬æ¢ä¸º GraphRagConfig å¯¹è±¡
        graph_knowledge_config = GraphRagConfig.from_dict(graph_knowledge_config_dict)
        llm_config_dict = self.config['llm']
        
        # è½¬æ¢ä¸º LLMConfig å¯¹è±¡
        provider = llm_config_dict.get('provider', 'litellm')
        
        # æä¾›å•†ç±»å‹æ˜ å°„
        provider_type_mapping = {
            'openai': 'litellm',
            'anthropic': 'litellm', 
            'litellm': 'litellm',
            'bailian': 'bailian',
            'kimi': 'kimi'
        }
        
        llm_type = provider_type_mapping.get(provider, 'litellm')
        
        # æ‰‹åŠ¨åˆ›å»º LLMConfigï¼Œç¡®ä¿ type å­—æ®µæ­£ç¡®
        llm_config = LLMConfig(
            type=llm_type,
            model=llm_config_dict.get('model'),
            api_key=llm_config_dict.get('api_key'),
            base_url=llm_config_dict.get('base_url'),
            provider=provider,
            timeout=llm_config_dict.get('timeout'),
            max_retries=llm_config_dict.get('retry_attempts'),  # é…ç½®æ–‡ä»¶ä¸­æ˜¯retry_attempts
            temperature=llm_config_dict.get('temperature'),
            max_tokens=llm_config_dict.get('max_tokens')
        )
        
        # åˆ›å»ºå¼ºæ¨¡å‹é…ç½®ï¼ˆç”¨äºæ–‡æ¡£åˆ†æå’ŒSchemaç”Ÿæˆï¼‰
        strong_model_dict = llm_config_dict.get('strong_model', llm_config_dict)
        strong_provider = strong_model_dict.get('provider', provider)
        strong_llm_type = provider_type_mapping.get(strong_provider, 'litellm')
        
        strong_llm_config = LLMConfig(
            type=strong_llm_type,
            model=strong_model_dict.get('model'),
            api_key=strong_model_dict.get('api_key'),
            base_url=strong_model_dict.get('base_url'),
            provider=strong_provider,
            timeout=strong_model_dict.get('timeout'),
            max_retries=strong_model_dict.get('retry_attempts', 3),
            temperature=strong_model_dict.get('temperature'),
            max_tokens=strong_model_dict.get('max_tokens')
        )
        
        # å°†å¼ºæ¨¡å‹é…ç½®æ·»åŠ åˆ°graph_knowledge_configä¸­
        graph_knowledge_config.strong_model_config = strong_llm_config
        
        self.logger.info(f"LLMé…ç½®: é»˜è®¤æ¨¡å‹={llm_config.model}, å¼ºæ¨¡å‹={strong_llm_config.model}")
        
        # ä½¿ç”¨çŸ¥è¯†å›¾è°±ä¸“ç”¨åˆ†å—é…ç½®
        graph_chunking_config = self.config['knowledge']['chunking']['graph_knowledge']
        strategy = graph_chunking_config.get('strategy', 'fixed_size')
        chunk_size = graph_chunking_config.get('chunk_size', 3000)
        chunk_overlap = graph_chunking_config.get('chunk_overlap', 300)
        
        chunking_config = ChunkingConfig(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap
        )
        
        self.logger.info(f"åˆ†å—é…ç½®: strategy={strategy}, chunk_size={chunk_size}, overlap={chunk_overlap}")
        
        # å¯¹æ‰€æœ‰æ–‡æ¡£è¿›è¡Œåˆ†å—
        all_chunks = []
        for i, document in enumerate(documents):
            doc_name = document.metadata.name
            doc_length = len(document.content)
            
            # æ£€æŸ¥æ–‡æ¡£æ˜¯å¦éœ€è¦åˆ†å—
            if doc_length > chunk_size:
                self.logger.info(f"åˆ†å—æ–‡æ¡£ {i+1}/{len(documents)}: {doc_name} ({doc_length}å­—ç¬¦)")
                
                # ä½¿ç”¨åˆ†å—å™¨
                chunker_kwargs = {}
                if strategy == "semantic":
                    chunker_kwargs['embedding_model'] = self.embedding_router
                    chunker_kwargs['similarity_threshold'] = graph_chunking_config.get('semantic', {}).get('similarity_threshold', 0.7)
                    chunker_kwargs['min_chunk_size'] = graph_chunking_config.get('min_chunk_size', 1500)
                    chunker_kwargs['max_chunk_size'] = graph_chunking_config.get('max_chunk_size', 5000)
                elif strategy == "agentic":
                    chunker_kwargs['llm_client'] = self.llm_client
                    agentic_config = graph_chunking_config.get('agentic', {})
                    chunker_kwargs.update(agentic_config)
                
                chunker = get_chunker(strategy, chunking_config, **chunker_kwargs)
                chunks = await chunker.chunk_document_async(document)
                
                if hasattr(chunks, 'chunks'):
                    chunk_docs = chunks.chunks
                else:
                    chunk_docs = chunks
                
                all_chunks.extend(chunk_docs)
                self.logger.info(f"åˆ†å—ç»“æœ: {len(chunk_docs)}ä¸ªå—")
            else:
                # æ–‡æ¡£è¶³å¤Ÿå°ï¼Œä¸éœ€è¦åˆ†å—
                all_chunks.append(document)
                self.logger.info(f"æ–‡æ¡£ {i+1}/{len(documents)}: {doc_name} æ— éœ€åˆ†å—")
        
        self.logger.info(f"åˆ†å—å®Œæˆ: æ€»è®¡{len(all_chunks)}ä¸ªæ–‡æœ¬å—")
        
        # ä½¿ç”¨æ–°çš„KnowledgeGraphBuilderè¿›è¡Œä¸¤é˜¶æ®µSPOæŠ½å–
        builder = KnowledgeGraphBuilder(
            config=graph_knowledge_config,
            llm_config=llm_config
        )
        
        # æå–åˆ†å—åçš„æ–‡æ¡£æ–‡æœ¬
        texts = [chunk.content for chunk in all_chunks]
        metadata = [chunk.metadata.__dict__ for chunk in all_chunks]
        
        # æ„å»ºå›¾è°±ï¼ˆä½¿ç”¨æ‰¹å¤„ç†SPOæŠ½å–ï¼‰
        self.logger.info(f"å¼€å§‹SPOæŠ½å–: {len(texts)}ä¸ªæ–‡æœ¬å—")
        self.knowledge_graph = await builder.build_from_texts(
            texts=texts,
            metadata=metadata
        )
        
        # æ‰“å°æ„å»ºç»“æœ
        entity_count = len(self.knowledge_graph.entities)
        relation_count = len(self.knowledge_graph.relationships)
        self.logger.info(f"âœ… çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆ: {entity_count}ä¸ªå®ä½“, {relation_count}ä¸ªå…³ç³»")
    
    async def store_and_index(self) -> None:
        """å­˜å‚¨å’Œç´¢å¼•çŸ¥è¯†å›¾è°±"""
        self.logger.info("å¼€å§‹å­˜å‚¨å’Œç´¢å¼•")
        
        # æ‰“å°è¾“å…¥æ•°æ®ç»Ÿè®¡
        entity_count = len(self.knowledge_graph.entities)
        relation_count = len(self.knowledge_graph.relationships)
        self.logger.info(f"è¾“å…¥æ•°æ®: {entity_count}ä¸ªå®ä½“, {relation_count}ä¸ªå…³ç³»")
        
        # 1. å­˜å‚¨åˆ°å›¾æ•°æ®åº“
        try:
            graph_storage = await self.storage_manager.get_graph_storage('default')
            
            if graph_storage:
                clear_existing = self.mode in ["full", "build"]
                self.logger.info(f"å›¾æ•°æ®åº“å­˜å‚¨: æ¸…ç†æ¨¡å¼={clear_existing}")
                graph_storage.store_graph(self.knowledge_graph, clear_existing=clear_existing)
                self.logger.info("âœ… å›¾æ•°æ®åº“å­˜å‚¨å®Œæˆ")
            else:
                self.logger.warning("âŒ æœªæ‰¾åˆ°å›¾æ•°æ®åº“å­˜å‚¨ï¼Œè·³è¿‡")
        except Exception as e:
            self.logger.error(f"âŒ å›¾æ•°æ®åº“å­˜å‚¨å¤±è´¥: {e}")
            self.logger.warning("ç»§ç»­æ‰§è¡Œå…¶ä»–ç´¢å¼•æ­¥éª¤")
        
        # 2. æ„å»ºå‘é‡ç´¢å¼•
        try:
            await self._build_vector_index()
        except Exception as e:
            self.logger.error(f"âŒ å‘é‡ç´¢å¼•æ„å»ºå¤±è´¥: {e}")
        
        # 3. æ„å»ºBM25ç´¢å¼•
        try:
            await self._build_bm25_index()
        except Exception as e:
            self.logger.error(f"âŒ BM25ç´¢å¼•æ„å»ºå¤±è´¥: {e}")
        
        # 4. æ„å»º SPO ç´¢å¼•
        try:
            await self._build_spo_index()
        except Exception as e:
            self.logger.error(f"âŒ SPOç´¢å¼•æ„å»ºå¤±è´¥: {e}")
        
        # 5. ç¼“å­˜å…³é”®æ•°æ®
        try:
            await self._cache_key_data()
        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®ç¼“å­˜å¤±è´¥: {e}")
        
        # ç»Ÿè®¡å‘é‡ç´¢å¼•æ€»æ•° - ç»Ÿè®¡æ‰€æœ‰ç‹¬ç«‹å‘é‡å­˜å‚¨å®ä¾‹
        total_vectors = 0
        
        # ç»Ÿè®¡æ–‡æ¡£å‘é‡å­˜å‚¨
        if hasattr(self, '_document_vector_storage') and self._document_vector_storage:
            try:
                doc_status = self._document_vector_storage.status()
                doc_vectors = doc_status.vector_count
                total_vectors += doc_vectors
                self.logger.debug(f"æ–‡æ¡£å‘é‡å­˜å‚¨: {doc_vectors}æ¡è®°å½•")
            except Exception as e:
                self.logger.debug(f"è·å–æ–‡æ¡£å‘é‡å­˜å‚¨çŠ¶æ€å¤±è´¥: {e}")
        
        # ç»Ÿè®¡å›¾å‘é‡å­˜å‚¨
        if hasattr(self, '_graph_vector_storage') and self._graph_vector_storage:
            try:
                graph_status = self._graph_vector_storage.status()
                graph_vectors = graph_status.vector_count
                total_vectors += graph_vectors
                self.logger.debug(f"å›¾å‘é‡å­˜å‚¨: {graph_vectors}æ¡è®°å½•")
            except Exception as e:
                self.logger.debug(f"è·å–å›¾å‘é‡å­˜å‚¨çŠ¶æ€å¤±è´¥: {e}")
        
        self.logger.info(f"å­˜å‚¨å’Œç´¢å¼•å®Œæˆ: å›¾æ•°æ®åº“{len(self.knowledge_graph.entities)}ä¸ªå®ä½“/{len(self.knowledge_graph.relationships)}ä¸ªå…³ç³», å‘é‡æ•°æ®åº“{total_vectors}æ¡è®°å½•")
    
    async def _build_vector_index(self) -> None:
        """æ„å»ºå‘é‡ç´¢å¼• - ç°åœ¨åˆ†ç¦»ä¸ºæ–‡æ¡£å‘é‡å’Œå›¾å‘é‡"""
        self.logger.info("å¼€å§‹æ„å»ºå‘é‡ç´¢å¼•")
        
        # æ„å»ºæ–‡æ¡£å‘é‡ç´¢å¼•ï¼ˆç”¨äºå‘é‡æ£€ç´¢ï¼‰
        await self._build_document_vector_index()
        
        # æ„å»ºå›¾å‘é‡ç´¢å¼•ï¼ˆç”¨äºå›¾æ£€ç´¢å¢å¼ºï¼‰
        await self._build_graph_vector_indices()
        
        self.logger.info("âœ… å‘é‡ç´¢å¼•æ„å»ºå®Œæˆ")
    
    async def _build_document_vector_index(self) -> None:
        """æ„å»ºæ–‡æ¡£åˆ†å—å‘é‡ç´¢å¼• - ä¸“ç”¨äºå‘é‡æ£€ç´¢è·¯å¾„"""
        from agenticx.storage import StorageType
        from agenticx.storage.vectordb_storages.milvus import MilvusStorage
        
        self.logger.info("æ„å»ºæ–‡æ¡£å‘é‡ç´¢å¼•")
        
        # ğŸ”§ ä¸ºæ–‡æ¡£å‘é‡åˆ›å»ºç‹¬ç«‹çš„Milvuså­˜å‚¨å®ä¾‹
        storage_config = self.config['storage']['vector']['milvus']
        # ğŸ”§ ä¿®å¤ï¼šæ ¹æ®è¿è¡Œæ¨¡å¼å†³å®šæ˜¯å¦é‡æ–°åˆ›å»ºæ–‡æ¡£å‘é‡é›†åˆ
        recreate_document_collection = self.mode in ["full", "build"]
        self.logger.info(f"ğŸ”§ æ–‡æ¡£å‘é‡å­˜å‚¨é…ç½®: mode={self.mode}, recreate_if_exists={recreate_document_collection}")
        self._document_vector_storage = MilvusStorage(
            dimension=1024,  # ä½¿ç”¨åµŒå…¥ç»´åº¦
            host=storage_config['host'],
            port=storage_config['port'],
            collection_name=storage_config['collection_name'],  # ä½¿ç”¨æ–‡æ¡£ä¸“ç”¨é›†åˆå
            database=storage_config.get('database', 'default'),
            username=storage_config.get('username'),
            password=storage_config.get('password'),
            recreate_if_exists=recreate_document_collection  # ğŸ”§ ä¿®å¤ï¼šæ ¹æ®æ¨¡å¼å†³å®šæ˜¯å¦é‡æ–°åˆ›å»º
        )
        
        self.logger.info(f"ğŸ“„ æ–‡æ¡£å‘é‡å­˜å‚¨é›†åˆ: {storage_config['collection_name']}")
        
        if not hasattr(self, 'documents') or not self.documents:
            self.logger.warning("âŒ æ²¡æœ‰æ–‡æ¡£å¯ä»¥ç´¢å¼•")
            return
        
        # ä½¿ç”¨å‘é‡æ£€ç´¢ä¸“ç”¨åˆ†å—é…ç½®
        vector_chunking_config = self.config['knowledge']['chunking'].get('vector', {
            'strategy': 'fixed_size',
            'chunk_size': 1500,
            'chunk_overlap': 150,
            'min_chunk_size': 500,
            'max_chunk_size': 2000
        })
        
        strategy = vector_chunking_config['strategy']
        chunk_size = vector_chunking_config['chunk_size']
        chunk_overlap = vector_chunking_config['chunk_overlap']
        self.logger.info(f"å‘é‡åˆ†å—é…ç½®: strategy={strategy}, chunk_size={chunk_size}, overlap={chunk_overlap}")
        
        # è·å–å‘é‡æ£€ç´¢ä¸“ç”¨åˆ†å—å™¨
        from agenticx.knowledge.base import ChunkingConfig
        vector_config = ChunkingConfig(
            chunk_size=vector_chunking_config['chunk_size'],
            chunk_overlap=vector_chunking_config['chunk_overlap']
        )
        vector_chunker = get_chunker(vector_chunking_config['strategy'], vector_config)
        
        document_records = []
        for doc_idx, document in enumerate(self.documents):
            # ä½¿ç”¨å‘é‡æ£€ç´¢ä¸“ç”¨åˆ†å—
            try:
                chunks_result = await vector_chunker.chunk_document_async(document)
                chunks = chunks_result.chunks if hasattr(chunks_result, 'chunks') else chunks_result
            except Exception as e:
                self.logger.warning(f"åˆ†å—å¤±è´¥ï¼Œä½¿ç”¨ç®€å•åˆ†å—: {e}")
                # ç®€å•åˆ†å—ä½œä¸ºå¤‡ç”¨
                chunk_size = vector_chunking_config['chunk_size']
                content = document.content
                chunks = []
                for i in range(0, len(content), chunk_size):
                    chunk_content = content[i:i + chunk_size]
                    chunk_metadata = type(document.metadata)(
                        name=f"{document.metadata.name}_chunk_{i//chunk_size}",
                        source=document.metadata.source,
                        source_type=document.metadata.source_type,
                        content_type=document.metadata.content_type,
                        parent_id=document.id,
                        chunk_index=i//chunk_size,
                        chunker_name="SimpleChunker"
                    )
                    chunk = type(document)(content=chunk_content, metadata=chunk_metadata)
                    chunks.append(chunk)
            
            for chunk_idx, chunk in enumerate(chunks):
                # ç”ŸæˆåµŒå…¥
                embedding = await self.embedding_router.aembed_text(chunk.content)
                
                # åˆ›å»ºå‘é‡è®°å½•
                record = VectorRecord(
                    id=f"doc_{doc_idx}_chunk_{chunk_idx}",
                    vector=embedding,
                    payload={
                        'content': chunk.content,  # ğŸ”§ ä¿®å¤ï¼šå°†contentæ”¾åˆ°payloadä¸­
                        'metadata': {
                            'type': 'document_chunk',
                            'document_id': document.id,
                            'document_title': getattr(document.metadata, 'title', None) or getattr(document.metadata, 'name', ''),
                            'chunk_index': chunk_idx,
                            'chunk_size': len(chunk.content),
                            'chunking_strategy': vector_chunking_config['strategy']
                        }
                    }
                )
                document_records.append(record)
        
        # æ‰¹é‡å­˜å‚¨æ–‡æ¡£åˆ†å—å‘é‡
        if document_records:
            await self._document_vector_storage.add(document_records)
            self.logger.info(f"âœ… æ–‡æ¡£å‘é‡ç´¢å¼•å®Œæˆ: {len(document_records)}æ¡è®°å½•")
            self.logger.info(f"ğŸ“„ å­˜å‚¨åˆ°é›†åˆ: {storage_config['collection_name']}")
        else:
            self.logger.warning("âŒ æ²¡æœ‰æ–‡æ¡£åˆ†å—å¯ä»¥ç´¢å¼•")
    
    async def _build_graph_vector_indices(self) -> None:
        """æ„å»ºå›¾å‘é‡ç´¢å¼• - ä¸“ç”¨äºå›¾æ£€ç´¢å¢å¼º"""
        self.logger.info("æ„å»ºå›¾å‘é‡ç´¢å¼•")
        
        # æ£€æŸ¥å›¾æ£€ç´¢å™¨æ˜¯å¦æ”¯æŒå‘é‡ç´¢å¼•
        if not hasattr(self, 'graph_retriever') or not self.graph_retriever:
            self.logger.warning("âŒ å›¾æ£€ç´¢å™¨æœªåˆå§‹åŒ–ï¼Œè·³è¿‡")
            return
        
        if not self.graph_retriever.enable_vector_search:
            self.logger.info("å›¾å‘é‡ç´¢å¼•å·²ç¦ç”¨ï¼Œè·³è¿‡æ„å»º")
            return
        
        try:
            # ä½¿ç”¨GraphRetrieverçš„å‘é‡ç´¢å¼•æ„å»ºåŠŸèƒ½
            results = await self.graph_retriever.build_vector_indices()
            
            # å¤„ç†ä¸åŒç±»å‹çš„ç»“æœçŠ¶æ€
            success_count = 0
            skipped_count = 0
            failed_count = 0
            
            for k, v in results.items():
                if k == 'error':
                    continue
                if v is True or v == "success":
                    success_count += 1
                elif v == "skipped":
                    skipped_count += 1
                else:
                    failed_count += 1
            
            total_count = len([k for k in results.keys() if k != 'error'])
            
            if 'error' in results:
                self.logger.error(f"âŒ å›¾å‘é‡ç´¢å¼•æ„å»ºå¤±è´¥: {results['error']}")
            else:
                self.logger.info(f"âœ… å›¾å‘é‡ç´¢å¼•æ„å»ºå®Œæˆ: {success_count}/{total_count}ä¸ªæˆåŠŸ")
                for index_type, result in results.items():
                    if index_type == 'error':
                        continue
                    if result is True or result == "success":
                        status = "âœ…"
                    elif result == "skipped":
                        status = "â­ï¸"  # è·³è¿‡ç¬¦å·
                    else:
                        status = "âŒ"
                    self.logger.info(f"  {status} {index_type}ç´¢å¼•")
                
        except Exception as e:
            self.logger.error(f"âŒ å›¾å‘é‡ç´¢å¼•æ„å»ºå¼‚å¸¸: {e}")
    
    async def _build_bm25_index(self) -> None:
        """æ„å»ºBM25å€’æ’ç´¢å¼• - åŸºäºä¸“ç”¨åˆ†å—é…ç½®"""
        self.logger.info("æ„å»ºBM25å€’æ’ç´¢å¼•")
        
        if not hasattr(self, 'documents') or not self.documents:
            self.logger.warning("âŒ æ²¡æœ‰æ–‡æ¡£å¯ä»¥æ„å»ºBM25ç´¢å¼•")
            return
        
        # æ£€æŸ¥BM25æ£€ç´¢å™¨æ˜¯å¦å·²åˆå§‹åŒ–
        if not hasattr(self, 'retriever') or not self.retriever:
            self.logger.warning("âŒ æ£€ç´¢å™¨æœªåˆå§‹åŒ–ï¼Œè·³è¿‡")
            return
        
        # è·å–BM25æ£€ç´¢å™¨
        bm25_retriever = None
        if hasattr(self.retriever, 'bm25_retriever'):
            bm25_retriever = self.retriever.bm25_retriever
        else:
            self.logger.warning("âŒ æœªæ‰¾åˆ°BM25æ£€ç´¢å™¨ï¼Œè·³è¿‡")
            return
        
        # ä½¿ç”¨BM25ä¸“ç”¨åˆ†å—é…ç½®
        bm25_chunking_config = self.config['knowledge']['chunking'].get('bm25', {
            'strategy': 'fixed_size',
            'chunk_size': 600,
            'chunk_overlap': 100,
            'min_chunk_size': 400,
            'max_chunk_size': 1000
        })
        
        strategy = bm25_chunking_config['strategy']
        chunk_size = bm25_chunking_config['chunk_size']
        chunk_overlap = bm25_chunking_config['chunk_overlap']
        self.logger.info(f"BM25åˆ†å—é…ç½®: strategy={strategy}, chunk_size={chunk_size}, overlap={chunk_overlap}")
        
        # è·å–BM25ä¸“ç”¨åˆ†å—å™¨
        from agenticx.knowledge.base import ChunkingConfig
        bm25_config = ChunkingConfig(
            chunk_size=bm25_chunking_config['chunk_size'],
            chunk_overlap=bm25_chunking_config['chunk_overlap']
        )
        bm25_chunker = get_chunker(bm25_chunking_config['strategy'], bm25_config)
        
        # å‡†å¤‡BM25æ–‡æ¡£
        bm25_documents = []
        for doc_idx, document in enumerate(self.documents):
            # ä½¿ç”¨BM25ä¸“ç”¨åˆ†å—
            try:
                chunks_result = await bm25_chunker.chunk_document_async(document)
                chunks = chunks_result.chunks if hasattr(chunks_result, 'chunks') else chunks_result
            except Exception as e:
                self.logger.warning(f"BM25åˆ†å—å¤±è´¥ï¼Œä½¿ç”¨ç®€å•åˆ†å—: {e}")
                # ç®€å•åˆ†å—ä½œä¸ºå¤‡ç”¨
                chunk_size = bm25_chunking_config['chunk_size']
                content = document.content
                chunks = []
                for i in range(0, len(content), chunk_size):
                    chunk_content = content[i:i + chunk_size]
                    chunk_metadata = type(document.metadata)(
                        name=f"{document.metadata.name}_bm25_chunk_{i//chunk_size}",
                        source=document.metadata.source,
                        source_type=document.metadata.source_type,
                        content_type=document.metadata.content_type,
                        parent_id=document.id,
                        chunk_index=i//chunk_size,
                        chunker_name="SimpleChunker"
                    )
                    chunk = type(document)(content=chunk_content, metadata=chunk_metadata)
                    chunks.append(chunk)
            
            for chunk_idx, chunk in enumerate(chunks):
                # åˆ›å»ºBM25æ–‡æ¡£è®°å½•
                bm25_doc = {
                    'id': f"bm25_doc_{doc_idx}_chunk_{chunk_idx}",
                    'content': chunk.content,
                    'metadata': {
                        'type': 'bm25_chunk',
                        'document_id': document.id,
                        'document_title': getattr(document.metadata, 'title', None) or getattr(document.metadata, 'name', ''),
                        'chunk_index': chunk_idx,
                        'chunk_size': len(chunk.content),
                        'chunking_strategy': bm25_chunking_config['strategy']
                    }
                }
                bm25_documents.append(bm25_doc)
        
        # æ‰¹é‡æ·»åŠ åˆ°BM25æ£€ç´¢å™¨
        if bm25_documents:
            try:
                document_ids = await bm25_retriever.add_documents(bm25_documents)
                self.logger.info(f"âœ… BM25ç´¢å¼•æ„å»ºå®Œæˆ: {len(bm25_documents)}æ¡è®°å½•")
                self.logger.debug(f"BM25æ–‡æ¡£ID: {document_ids[:5]}..." if len(document_ids) > 5 else f"BM25æ–‡æ¡£ID: {document_ids}")
            except Exception as e:
                self.logger.error(f"âŒ BM25ç´¢å¼•æ·»åŠ å¤±è´¥: {e}")
        else:
            self.logger.warning("âš ï¸ æ²¡æœ‰BM25æ–‡æ¡£å¯ä»¥ç´¢å¼•")
    
    async def _build_legacy_entity_relation_vectors(self) -> None:
        """æ„å»ºä¼ ç»Ÿçš„å®ä½“å’Œå…³ç³»å‘é‡ï¼ˆä¿ç•™ç”¨äºå…¼å®¹æ€§ï¼‰"""
        from agenticx.storage import StorageType
        
        self.logger.debug("æ„å»ºä¼ ç»Ÿå®ä½“å…³ç³»å‘é‡...")
        
        vector_storage = await self.storage_manager.get_vector_storage('default')
        if not vector_storage:
            vector_storage = self.storage_manager.get_storage(StorageType.CHROMA)
            if not vector_storage:
                return
        
        # ä¸ºå®ä½“æ„å»ºå‘é‡ç´¢å¼•
        entity_records = []
        for entity in self.knowledge_graph.entities.values():
            entity_text = f"{entity.name}: {entity.description or ''}"
            embedding = await self.embedding_router.aembed_text(entity_text)
            
            record = VectorRecord(
                id=f"legacy_entity_{entity.id}",
                vector=embedding,
                metadata={
                    'type': 'legacy_entity',
                    'entity_type': entity.entity_type.value,
                    'name': entity.name,
                    'confidence': entity.confidence
                },
                content=entity_text
            )
            entity_records.append(record)
        
        # ä¸ºå…³ç³»æ„å»ºå‘é‡ç´¢å¼•
        relationship_records = []
        for relationship in self.knowledge_graph.relationships.values():
            source_entity = self.knowledge_graph.get_entity(relationship.source_entity_id)
            target_entity = self.knowledge_graph.get_entity(relationship.target_entity_id)
            
            if source_entity and target_entity:
                rel_text = f"{source_entity.name} {relationship.relation_type.value} {target_entity.name}"
                embedding = await self.embedding_router.aembed_text(rel_text)
                
                record = VectorRecord(
                    id=f"legacy_relation_{relationship.id}",
                    vector=embedding,
                    metadata={
                        'type': 'legacy_relationship',
                        'relation_type': relationship.relation_type.value,
                        'source_entity': source_entity.name,
                        'target_entity': target_entity.name,
                        'confidence': relationship.confidence
                    },
                    content=rel_text
                )
                relationship_records.append(record)
        
        # æ‰¹é‡å­˜å‚¨
        all_records = entity_records + relationship_records
        if all_records:
            vector_storage.add(all_records)
            self.logger.debug(f"ä¼ ç»Ÿå‘é‡ç´¢å¼•: {len(entity_records)}ä¸ªå®ä½“ + {len(relationship_records)}ä¸ªå…³ç³»")
    
    async def _build_spo_index(self) -> None:
        """æ„å»º SPO ä¸‰å…ƒç»„ç´¢å¼•"""
        import json
        self.logger.info("æ„å»º SPO ä¸‰å…ƒç»„ç´¢å¼•...")
        
        # è°ƒè¯•ï¼šæ£€æŸ¥å­˜å‚¨ç®¡ç†å™¨çŠ¶æ€
        self.logger.info(f"å­˜å‚¨ç®¡ç†å™¨åˆå§‹åŒ–çŠ¶æ€: {self.storage_manager.initialized}")
        self.logger.info(f"å­˜å‚¨å®ä¾‹æ•°é‡: {len(self.storage_manager.storages)}")
        
        kv_storage = await self.storage_manager.get_key_value_storage('default')
        self.logger.info(f"è·å–åˆ°çš„é”®å€¼å­˜å‚¨: {type(kv_storage) if kv_storage else 'None'}")
        
        if not kv_storage:
            self.logger.warning("âš ï¸ æœªæ‰¾åˆ°é”®å€¼å­˜å‚¨ï¼Œè·³è¿‡SPOç´¢å¼•æ„å»º")
            return
        
        # æ„å»º SPO ç´¢å¼•
        spo_index = {
            'subject_index': {},  # ä¸»è¯­ç´¢å¼•
            'predicate_index': {},  # è°“è¯­ç´¢å¼•
            'object_index': {}  # å®¾è¯­ç´¢å¼•
        }
        
        for relationship in self.knowledge_graph.relationships.values():
            source_entity = self.knowledge_graph.get_entity(relationship.source_entity_id)
            target_entity = self.knowledge_graph.get_entity(relationship.target_entity_id)
            
            if source_entity and target_entity:
                subject = source_entity.name
                predicate = relationship.relation_type.value
                object_name = target_entity.name
                
                # ä¸»è¯­ç´¢å¼•
                if subject not in spo_index['subject_index']:
                    spo_index['subject_index'][subject] = []
                spo_index['subject_index'][subject].append({
                    'predicate': predicate,
                    'object': object_name,
                    'relationship_id': relationship.id
                })
                
                # è°“è¯­ç´¢å¼•
                if predicate not in spo_index['predicate_index']:
                    spo_index['predicate_index'][predicate] = []
                spo_index['predicate_index'][predicate].append({
                    'subject': subject,
                    'object': object_name,
                    'relationship_id': relationship.id
                })
                
                # å®¾è¯­ç´¢å¼•
                if object_name not in spo_index['object_index']:
                    spo_index['object_index'][object_name] = []
                spo_index['object_index'][object_name].append({
                    'subject': subject,
                    'predicate': predicate,
                    'relationship_id': relationship.id
                })
        
        # å­˜å‚¨ç´¢å¼•ï¼ˆåºåˆ—åŒ–ä¸ºJSONï¼‰
        kv_storage.set('spo_index', json.dumps(spo_index, ensure_ascii=False))
        
        self.logger.info(
            f"SPO ç´¢å¼•æ„å»ºå®Œæˆ: "
            f"{len(spo_index['subject_index'])} ä¸ªä¸»è¯­, "
            f"{len(spo_index['predicate_index'])} ä¸ªè°“è¯­, "
            f"{len(spo_index['object_index'])} ä¸ªå®¾è¯­"
        )
    
    async def _cache_key_data(self) -> None:
        """ç¼“å­˜å…³é”®æ•°æ®"""
        import json
        from datetime import datetime, timezone
        self.logger.info("ç¼“å­˜å…³é”®æ•°æ®...")
        
        kv_storage = await self.storage_manager.get_key_value_storage('default')
        if not kv_storage:
            self.logger.warning("âš ï¸ æœªæ‰¾åˆ°é”®å€¼å­˜å‚¨ï¼Œè·³è¿‡æ•°æ®ç¼“å­˜")
            return
        
        # ç¼“å­˜å›¾è°±ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'entity_count': len(self.knowledge_graph.entities),
            'relationship_count': len(self.knowledge_graph.relationships),
            'entity_types': {},
            'relationship_types': {},
            'build_time': datetime.now(timezone.utc).isoformat()
        }
        
        # ç»Ÿè®¡å®ä½“ç±»å‹
        for entity in self.knowledge_graph.entities.values():
            entity_type = entity.entity_type.value
            stats['entity_types'][entity_type] = stats['entity_types'].get(entity_type, 0) + 1
        
        # ç»Ÿè®¡å…³ç³»ç±»å‹
        for relationship in self.knowledge_graph.relationships.values():
            rel_type = relationship.relation_type.value
            stats['relationship_types'][rel_type] = stats['relationship_types'].get(rel_type, 0) + 1
        
        kv_storage.set('graph_stats', json.dumps(stats, ensure_ascii=False))
        self.logger.info("å…³é”®æ•°æ®ç¼“å­˜å®Œæˆ")
    
    async def interactive_qa(self) -> None:
        """äº¤äº’å¼é—®ç­”ç³»ç»Ÿ"""
        self.logger.info("å¯åŠ¨äº¤äº’å¼é—®ç­”ç³»ç»Ÿ...")
        
        if console and Panel and box:
            # ä½¿ç”¨ Rich æ˜¾ç¤ºé—®ç­”ç•Œé¢
            qa_text = Text()
            qa_text.append("ğŸ¤– AgenticX GraphRAG é—®ç­”ç³»ç»Ÿ\n\n", style="bold cyan")
            qa_text.append("æ”¯æŒçš„æŸ¥è¯¢ç±»å‹:\n", style="bold white")
            qa_text.append("â— å®ä½“æŸ¥è¯¢: æŸ¥æ‰¾ç‰¹å®šå®ä½“çš„ä¿¡æ¯\n", style="white")
            qa_text.append("â— å…³ç³»æŸ¥è¯¢: æŸ¥æ‰¾å®ä½“é—´çš„å…³ç³»\n", style="white")
            qa_text.append("â— è·¯å¾„æŸ¥è¯¢: æŸ¥æ‰¾å®ä½“é—´çš„è¿æ¥è·¯å¾„\n", style="white")
            qa_text.append("â— ç¤¾åŒºæŸ¥è¯¢: æŸ¥æ‰¾ç›¸å…³å®ä½“ç¾¤ç»„\n", style="white")
            qa_text.append("â— è‡ªç”±é—®ç­”: åŸºäºçŸ¥è¯†å›¾è°±çš„å¼€æ”¾å¼é—®ç­”\n\n", style="white")
            qa_text.append("è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºç³»ç»Ÿ", style="dim")
            
            panel = Panel(
                qa_text,
                title="æ™ºèƒ½é—®ç­”",
                border_style="#FF6B35",
                box=box.ROUNDED,
                padding=(1, 2)
            )
            console.print(panel)
        else:
            print("\n" + "="*60)
            print("ğŸ¤– AgenticX GraphRAG é—®ç­”ç³»ç»Ÿ")
            print("="*60)
            print("æ”¯æŒçš„æŸ¥è¯¢ç±»å‹:")
            print("  1. å®ä½“æŸ¥è¯¢: æŸ¥æ‰¾ç‰¹å®šå®ä½“çš„ä¿¡æ¯")
            print("  2. å…³ç³»æŸ¥è¯¢: æŸ¥æ‰¾å®ä½“é—´çš„å…³ç³»")
            print("  3. è·¯å¾„æŸ¥è¯¢: æŸ¥æ‰¾å®ä½“é—´çš„è¿æ¥è·¯å¾„")
            print("  4. ç¤¾åŒºæŸ¥è¯¢: æŸ¥æ‰¾ç›¸å…³å®ä½“ç¾¤ç»„")
            print("  5. è‡ªç”±é—®ç­”: åŸºäºçŸ¥è¯†å›¾è°±çš„å¼€æ”¾å¼é—®ç­”")
            print("\nè¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºç³»ç»Ÿ")
            print("="*60 + "\n")
        
        while True:
            try:
                # è·å–ç”¨æˆ·è¾“å…¥
                if console and Prompt:
                    query = Prompt.ask("\n[bold cyan]ğŸ” è¯·è¾“å…¥æ‚¨çš„é—®é¢˜[/bold cyan]").strip()
                else:
                    query = input("ğŸ” è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ").strip()
                
                if query.lower() in ['quit', 'exit', 'é€€å‡º']:
                    print_success("æ„Ÿè°¢ä½¿ç”¨ AgenticX GraphRAG ç³»ç»Ÿï¼")
                    break
                
                if not query:
                    continue
                
                # å¤„ç†æŸ¥è¯¢
                await self._process_query(query)
                
            except KeyboardInterrupt:
                print_success("\næ„Ÿè°¢ä½¿ç”¨ AgenticX GraphRAG ç³»ç»Ÿï¼")
                break
            except Exception as e:
                self.logger.error(f"æŸ¥è¯¢å¤„ç†é”™è¯¯: {e}")
                print_error(f"æŸ¥è¯¢å¤„ç†å‡ºé”™: {e}")
    
    async def _process_query(self, query: str) -> None:
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢ - å¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒæ™ºèƒ½æŸ¥è¯¢å¤„ç†å’Œå¤šçº§å›é€€"""
        print(f"\nğŸ”„ æ­£åœ¨å¤„ç†æŸ¥è¯¢: {query}")
        self.logger.info(f"å¼€å§‹å¤„ç†æŸ¥è¯¢: {query}")
        
        try:
            # ğŸš€ æ–°å¢ï¼šä½¿ç”¨å¢å¼ºæ£€ç´¢å™¨
            if not hasattr(self, '_enhanced_retriever'):
                # å»¶è¿Ÿå¯¼å…¥å¢å¼ºæ£€ç´¢å™¨
                try:
                    from enhanced_retriever import EnhancedRetriever
                    self._enhanced_retriever = EnhancedRetriever(
                        base_retriever=self.retriever,
                        graph_retriever=getattr(self, 'graph_retriever', None),
                        storage_manager=self.storage_manager
                    )
                    self.logger.info("âœ… å¢å¼ºæ£€ç´¢å™¨åˆå§‹åŒ–æˆåŠŸ")
                except ImportError as e:
                    self.logger.warning(f"å¢å¼ºæ£€ç´¢å™¨å¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ£€ç´¢: {e}")
                    self._enhanced_retriever = None
            
            # ä½¿ç”¨å¢å¼ºæ£€ç´¢å™¨è¿›è¡Œå¤šçº§å›é€€æ£€ç´¢
            if self._enhanced_retriever:
                results, retrieval_report = await self._enhanced_retriever.retrieve_with_fallback(query)
                
                # æ˜¾ç¤ºæ£€ç´¢æŠ¥å‘Š
                if retrieval_report.get('success', False):
                    print(f"âœ… æ£€ç´¢æˆåŠŸï¼ä½¿ç”¨ç­–ç•¥: {retrieval_report.get('strategy_used', 'unknown')}")
                    print(f"ğŸ“Š æ‰¾åˆ° {retrieval_report.get('total_results', 0)} æ¡ç›¸å…³ä¿¡æ¯")
                    
                    # æ˜¾ç¤ºå¤„ç†åçš„æŸ¥è¯¢ä¿¡æ¯
                    processed_query = retrieval_report.get('processed_query')
                    if processed_query:
                        self.logger.info(f"ğŸ” æŸ¥è¯¢åˆ†æ: ç±»å‹={processed_query.query_type}, ç½®ä¿¡åº¦={processed_query.confidence:.2f}")
                        self.logger.info(f"ğŸ” å…³é”®è¯: {processed_query.keywords}")
                        self.logger.info(f"ğŸ” å®ä½“: {processed_query.entities}")
                    
                    # ç”Ÿæˆç­”æ¡ˆ
                    await self._generate_answer(query, results)
                    return
                else:
                    print("âŒ å¢å¼ºæ£€ç´¢ä¹Ÿæœªæ‰¾åˆ°ç»“æœ")
                    
                    # ğŸš€ æ–°å¢ï¼šè¿è¡Œè¯Šæ–­æ£€æŸ¥
                    print("\nğŸ” æ­£åœ¨è¿è¡Œç³»ç»Ÿè¯Šæ–­...")
                    await self._run_quick_diagnostics()
                    
                    # æä¾›æŸ¥è¯¢å»ºè®®
                    suggestions = await self._enhanced_retriever.suggest_related_queries(query)
                    if suggestions:
                        print("\nğŸ’¡ æ‚¨å¯ä»¥å°è¯•ä»¥ä¸‹ç›¸å…³æŸ¥è¯¢:")
                        for i, suggestion in enumerate(suggestions, 1):
                            print(f"   {i}. {suggestion}")
                    return
            
            # ğŸ”§ å›é€€åˆ°åŸå§‹æ£€ç´¢é€»è¾‘ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
            self.logger.info("ä½¿ç”¨åŸå§‹æ£€ç´¢é€»è¾‘")
            
            # è·å–é…ç½®
            rag_config = self.config.get('rag', {})
            rag_retrieval_config = rag_config.get('retrieval', {})
            retrieval_config = self.config.get('retrieval', {})
            vector_config = retrieval_config.get('vector', {})
            graph_config = retrieval_config.get('graph', {})
            
            # ğŸ”§ è°ƒè¯•ï¼šæ‰“å°é…ç½®å†…å®¹
            self.logger.info(f"ğŸ” é…ç½®è°ƒè¯•:")
            self.logger.info(f"  rag_config keys: {list(rag_config.keys())}")
            self.logger.info(f"  rag_retrieval_config: {rag_retrieval_config}")
            self.logger.info(f"  vector_config top_k: {vector_config.get('top_k', 'NOT_FOUND')}")
            self.logger.info(f"  graph_config max_nodes: {graph_config.get('max_nodes', 'NOT_FOUND')}")
            
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨åˆç†çš„æ£€ç´¢å‚æ•°
            hybrid_top_k = rag_retrieval_config.get('default_top_k', vector_config.get('top_k', 20))
            graph_top_k = graph_config.get('max_nodes', 15)
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨é…ç½®ä¸­çš„åŸå§‹é˜ˆå€¼ï¼Œä¸å†äººä¸ºé™ä½
            similarity_threshold = vector_config.get('similarity_threshold', 0.5)  # ä½¿ç”¨åˆç†çš„é˜ˆå€¼
            graph_similarity_threshold = graph_config.get('similarity_threshold', 0.3)  # ä½¿ç”¨åˆç†çš„é˜ˆå€¼

            self.logger.info(f"ğŸ¯ ä¼˜åŒ–åæ£€ç´¢å‚æ•°: hybrid_top_k={hybrid_top_k}, graph_top_k={graph_top_k}, vector_threshold={similarity_threshold}, graph_threshold={graph_similarity_threshold}")
            
            # ğŸš€ æ–°å¢ï¼šæ™ºèƒ½æŸ¥è¯¢é¢„å¤„ç†
            processed_queries = [query]
            try:
                from query_processor import ChineseQueryProcessor
                processor = ChineseQueryProcessor()
                processed_query = processor.process_query(query)
                additional_queries = processor.generate_search_queries(processed_query)
                processed_queries.extend(additional_queries)
                self.logger.info(f"ğŸ” ç”Ÿæˆæœç´¢æŸ¥è¯¢: {processed_queries}")
            except ImportError:
                self.logger.warning("æŸ¥è¯¢å¤„ç†å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢")

            # å¯¹æ¯ä¸ªå¤„ç†åçš„æŸ¥è¯¢æ‰§è¡Œæ£€ç´¢
            all_hybrid_results = []
            all_graph_results = []
            
            for search_query in processed_queries[:3]:  # é™åˆ¶æœ€å¤š3ä¸ªæŸ¥è¯¢é¿å…è¿‡åº¦æ£€ç´¢
                # 1. æ‰§è¡Œæ··åˆæ£€ç´¢
                self.logger.info(f"ğŸ” å¼€å§‹æ··åˆæ£€ç´¢: '{search_query}', top_k={hybrid_top_k}, min_score={similarity_threshold}")
                try:
                    hybrid_results = await self.retriever.retrieve(search_query, top_k=hybrid_top_k, min_score=similarity_threshold)
                    all_hybrid_results.extend(hybrid_results)
                    self.logger.info(f"ğŸ” æ··åˆæ£€ç´¢ '{search_query}' è¿”å›: {len(hybrid_results)}æ¡")
                except Exception as e:
                    self.logger.warning(f"æ··åˆæ£€ç´¢å¤±è´¥: {e}")
                
                # 2. æ‰§è¡Œå›¾æ£€ç´¢
                if hasattr(self, 'graph_retriever') and self.graph_retriever:
                    try:
                        self.logger.info(f"ğŸ”— å¼€å§‹å›¾æ£€ç´¢: '{search_query}', top_k={graph_top_k}, min_score={graph_similarity_threshold}")
                        graph_results = await self.graph_retriever.retrieve(search_query, top_k=graph_top_k, min_score=graph_similarity_threshold)
                        all_graph_results.extend(graph_results)
                        self.logger.info(f"ğŸ”— å›¾æ£€ç´¢ '{search_query}' è¿”å›: {len(graph_results)}æ¡")
                    except Exception as e:
                        self.logger.warning(f"å›¾æ£€ç´¢å¤±è´¥: {e}")
            
            # 3. åˆå¹¶å’Œå»é‡
            all_results = all_hybrid_results + all_graph_results
            seen_ids = set()
            unique_results = []
            for result in all_results:
                result_id = getattr(result, 'id', str(hash(result.content)))
                if result_id not in seen_ids:
                    seen_ids.add(result_id)
                    unique_results.append(result)
            
            # 4. æŒ‰ç›¸ä¼¼åº¦æ’åºå’Œç­›é€‰
            unique_results.sort(key=lambda x: getattr(x, 'score', 0), reverse=True)
            results = unique_results[:hybrid_top_k]
            
            # 5. ç»Ÿè®¡ä¸åŒç±»å‹çš„ç»“æœ
            type_counts = {}
            for result in results:
                result_type = "å…¶ä»–"
                if hasattr(result, 'metadata') and result.metadata:
                    if 'search_source' in result.metadata:
                        result_type = result.metadata['search_source']
                    elif 'type' in result.metadata:
                        result_type = result.metadata['type']
                type_counts[result_type] = type_counts.get(result_type, 0) + 1
            
            # 6. ä¼˜åŒ–åçš„ç»Ÿä¸€æ—¥å¿—è¾“å‡º
            self.logger.info(f"å®Œæˆæ‰§è¡Œå¤šæŸ¥è¯¢æ£€ç´¢ï¼Œæ€»æŸ¥è¯¢æ•°: {len(processed_queries)}")
            
            if not results:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯")
                self.logger.warning("æ£€ç´¢æ— ç»“æœï¼Œå°è¯•ç›´æ¥å®ä½“æœç´¢")
                await self._search_entity_directly(query)
                
                # ğŸš€ æ–°å¢ï¼šæä¾›æŸ¥è¯¢å»ºè®®
                print("\nğŸ’¡ æ‚¨å¯ä»¥å°è¯•:")
                print("   1. ä½¿ç”¨æ›´å…·ä½“çš„å…³é”®è¯")
                print("   2. æ£€æŸ¥æ‹¼å†™æ˜¯å¦æ­£ç¡®")
                print("   3. å°è¯•ç›¸å…³çš„åŒä¹‰è¯")
                return
            
            # ç»Ÿä¸€çš„æ£€ç´¢ç»Ÿè®¡ä¿¡æ¯
            stats_info = f"æ£€ç´¢ç»Ÿè®¡:\nğŸ” æ··åˆæ£€ç´¢: {len(all_hybrid_results)}æ¡\nğŸ”— å›¾æ£€ç´¢: {len(all_graph_results)}æ¡\nğŸ”„ å»é‡å: {len(unique_results)}æ¡\nâœ… æœ€ç»ˆé‡‡ç”¨: {len(results)}æ¡ï¼Œå…¶ä¸­ï¼š"
            for result_type, count in type_counts.items():
                stats_info += f"\n    {result_type}: {count}æ¡"
            
            self.logger.info(stats_info)
            
            # ç”Ÿæˆç­”æ¡ˆ
            await self._generate_answer(query, results)
        
        except Exception as e:
            self.logger.error(f"æŸ¥è¯¢å¤„ç†é”™è¯¯: {e}")
            print(f"âŒ æŸ¥è¯¢å¤„ç†å‡ºé”™: {e}")
            
            # ğŸš€ æ–°å¢ï¼šé”™è¯¯æ—¶çš„å‹å¥½æç¤º
            print("\nğŸ’¡ é‡åˆ°é—®é¢˜æ—¶ï¼Œæ‚¨å¯ä»¥:")
            print("   1. ç®€åŒ–æŸ¥è¯¢å†…å®¹")
            print("   2. ä½¿ç”¨ä¸­æ–‡å…³é”®è¯")
            print("   3. æ£€æŸ¥ç½‘ç»œè¿æ¥")
            print("   4. ç¨åé‡è¯•")
    
    async def _run_quick_diagnostics(self) -> None:
        """è¿è¡Œå¿«é€Ÿè¯Šæ–­æ£€æŸ¥"""
        try:
            print("ğŸ“Š ç³»ç»ŸçŠ¶æ€æ£€æŸ¥:")
            
            # æ£€æŸ¥æ–‡æ¡£æ•°é‡
            doc_count = len(self.documents) if hasattr(self, 'documents') and self.documents else 0
            print(f"  ğŸ“„ å·²åŠ è½½æ–‡æ¡£: {doc_count} ä¸ª")
            
            # æ£€æŸ¥BM25ç´¢å¼•
            if hasattr(self, 'retriever') and hasattr(self.retriever, 'bm25_retriever'):
                bm25_retriever = self.retriever.bm25_retriever
                if hasattr(bm25_retriever, '_documents'):
                    bm25_doc_count = len(bm25_retriever._documents)
                    index_terms = len(bm25_retriever._inverted_index) if hasattr(bm25_retriever, '_inverted_index') else 0
                    print(f"  ğŸ” BM25ç´¢å¼•: {bm25_doc_count} ä¸ªæ–‡æ¡£, {index_terms} ä¸ªè¯æ±‡")
                else:
                    print(f"  ğŸ” BM25ç´¢å¼•: æœªåˆå§‹åŒ–")
            
            # æ£€æŸ¥å›¾æ•°æ®
            if hasattr(self, 'storage_manager'):
                try:
                    from agenticx.storage import StorageType
                    graph_storage = self.storage_manager.get_storage(StorageType.NEO4J)
                    if graph_storage:
                        # æ£€æŸ¥å®ä½“æ•°é‡
                        entity_result = graph_storage.execute_query("MATCH (n:Entity) RETURN count(n) as count")
                        entity_count = entity_result[0]['count'] if entity_result else 0
                        
                        # æ£€æŸ¥æ‰€æœ‰èŠ‚ç‚¹æ•°é‡
                        node_result = graph_storage.execute_query("MATCH (n) RETURN count(n) as count")
                        node_count = node_result[0]['count'] if node_result else 0
                        
                        print(f"  ğŸ”— çŸ¥è¯†å›¾è°±: {entity_count} ä¸ªå®ä½“, {node_count} ä¸ªæ€»èŠ‚ç‚¹")
                        
                        # ğŸš€ æ–°å¢ï¼šæ£€æŸ¥æ˜¯å¦æœ‰åŒ…å«å¸¸è§è¯æ±‡çš„èŠ‚ç‚¹
                        common_terms = ['ä¸­å›½', 'æŠ€æœ¯', 'ç³»ç»Ÿ', 'å…¬å¸', 'æœåŠ¡']
                        found_terms = []
                        for term in common_terms:
                            try:
                                result = graph_storage.execute_query(
                                    "MATCH (n) WHERE toString(n.name) CONTAINS $term OR toString(n.content) CONTAINS $term RETURN count(n) as count",
                                    {"term": term}
                                )
                                if result and result[0]['count'] > 0:
                                    found_terms.append(f"{term}({result[0]['count']})")
                            except:
                                continue
                        
                        if found_terms:
                            print(f"  ğŸ“ å¸¸è§è¯æ±‡: {', '.join(found_terms)}")
                        else:
                            print(f"  âš ï¸  æœªæ‰¾åˆ°å¸¸è§ä¸­æ–‡è¯æ±‡ï¼Œå¯èƒ½å­˜åœ¨ç´¢å¼•é—®é¢˜")
                    else:
                        print(f"  ğŸ”— çŸ¥è¯†å›¾è°±: è¿æ¥å¤±è´¥")
                except Exception as e:
                    print(f"  ğŸ”— çŸ¥è¯†å›¾è°±: æ£€æŸ¥å¤±è´¥ - {e}")
            
            # ğŸš€ æ–°å¢ï¼šæµ‹è¯•ç®€å•æŸ¥è¯¢
            print("\nğŸ§ª æµ‹è¯•åŸºç¡€æŸ¥è¯¢:")
            test_queries = ['æµ‹è¯•', 'ä¸­å›½', 'æŠ€æœ¯']
            for test_query in test_queries:
                try:
                    if hasattr(self, 'retriever'):
                        results = await self.retriever.retrieve(test_query, top_k=1, min_score=0.0)
                        print(f"  '{test_query}': {len(results)} æ¡ç»“æœ")
                    else:
                        print(f"  '{test_query}': æ£€ç´¢å™¨ä¸å¯ç”¨")
                except Exception as e:
                    print(f"  '{test_query}': æŸ¥è¯¢å¤±è´¥ - {str(e)[:50]}...")
            
            print("\nğŸ’¡ è¯Šæ–­å»ºè®®:")
            if doc_count == 0:
                print("  âš ï¸  æ²¡æœ‰åŠ è½½æ–‡æ¡£ï¼Œè¯·å…ˆè¿è¡Œæ„å»ºæ¨¡å¼")
            elif hasattr(self, 'retriever') and hasattr(self.retriever, 'bm25_retriever'):
                bm25_doc_count = len(getattr(self.retriever.bm25_retriever, '_documents', {}))
                if bm25_doc_count == 0:
                    print("  âš ï¸  BM25ç´¢å¼•ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ç´¢å¼•æ„å»ºè¿‡ç¨‹")
                else:
                    print("  âœ… ç³»ç»Ÿç»„ä»¶æ­£å¸¸ï¼Œå¯èƒ½æ˜¯æŸ¥è¯¢è¯æ±‡ä¸åœ¨çŸ¥è¯†åº“ä¸­")
            
        except Exception as e:
            print(f"  âŒ è¯Šæ–­è¿‡ç¨‹å‡ºé”™: {e}")
    
    async def _search_entity_directly(self, query: str) -> None:
        """ç›´æ¥åœ¨Neo4jä¸­æœç´¢å®ä½“"""
        try:
            from agenticx.storage import StorageType
            graph_storage = self.storage_manager.get_storage(StorageType.NEO4J)
            
            if not graph_storage:
                print("âš ï¸ å›¾å­˜å‚¨ä¸å¯ç”¨")
                return
            
            # æå–å¯èƒ½çš„å®ä½“åç§°
            entity_name = query.replace("æ˜¯å•¥", "").replace("æ˜¯ä»€ä¹ˆ", "").replace("?", "").replace("ï¼Ÿ", "").strip()
            
            # åœ¨Neo4jä¸­æœç´¢å®ä½“
            cypher_query = """
            MATCH (n:Entity) 
            WHERE n.name CONTAINS $entity_name OR n.name =~ ('(?i).*' + $entity_name + '.*')
            RETURN n.name as name, n.description as description, labels(n) as type
            LIMIT 5
            """
            
            results = graph_storage.execute_query(cypher_query, {"entity_name": entity_name})
            
            if results:
                print(f"\nğŸ” åœ¨çŸ¥è¯†å›¾è°±ä¸­æ‰¾åˆ°ç›¸å…³å®ä½“:")
                for result in results:
                    print(f"ğŸ“ å®ä½“: {result['name']}")
                    print(f"   ç±»å‹: {result['type']}")
                    if result['description']:
                        print(f"   æè¿°: {result['description']}")
                    print()
            else:
                print(f"âŒ åœ¨çŸ¥è¯†å›¾è°±ä¸­æœªæ‰¾åˆ° '{entity_name}' ç›¸å…³çš„å®ä½“")
                
        except Exception as e:
            self.logger.error(f"ç›´æ¥å®ä½“æœç´¢å¤±è´¥: {e}")
            print(f"âŒ å®ä½“æœç´¢å‡ºé”™: {e}")
    
    async def _generate_answer(self, query: str, results: List[Any]) -> None:
        """åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆç­”æ¡ˆ"""
        try:
            self.logger.info(f"å¼€å§‹ç”Ÿæˆç­”æ¡ˆï¼Œè¾“å…¥{len(results)}æ¡æ£€ç´¢ç»“æœ")
            
            # ğŸ”§ è°ƒè¯•ï¼šè¯¦ç»†æ£€æŸ¥è¾“å…¥ç»“æœ
            if results:
                for i, result in enumerate(results[:3]):  # åªæ£€æŸ¥å‰3ä¸ªç»“æœ
                    self.logger.info(f"ç»“æœ{i+1}: type={type(result)}, contenté•¿åº¦={len(getattr(result, 'content', ''))}, metadata={getattr(result, 'metadata', {})}")
            else:
                self.logger.warning("è¾“å…¥ç»“æœä¸ºç©ºï¼")
                print("âš ï¸ ä¼ å…¥çš„æ£€ç´¢ç»“æœä¸ºç©º")
                return
            
            # è·å–ä¸Šä¸‹æ–‡é…ç½®
            rag_config = self.config.get('rag', {})
            retrieval_config = rag_config.get('retrieval', {})
            context_top_k = retrieval_config.get('default_top_k', 10)
            max_context_length = retrieval_config.get('max_context_length', 4000)
            
            # ğŸ”§ ä¿®å¤ï¼šæ·»åŠ å•ä¸ªå†…å®¹ç‰‡æ®µçš„æœ€å¤§é•¿åº¦é™åˆ¶
            max_content_per_item = 500  # æ¯ä¸ªæ£€ç´¢ç»“æœæœ€å¤šä¿ç•™500å­—ç¬¦
            
            # ğŸ”§ ä¿®å¤ï¼šæ›´å®½æ¾çš„ç»“æœåˆ†ç±»ï¼Œç¡®ä¿æ‰€æœ‰ç»“æœéƒ½èƒ½è¢«å¤„ç†
            graph_results = []
            doc_results = []
            entity_results = []
            other_results = []
            
            for r in results:
                if not r.metadata:
                    # æ²¡æœ‰metadataçš„ç»“æœå½’ç±»ä¸ºå…¶ä»–ç»“æœ
                    other_results.append(r)
                    continue
                
                search_source = r.metadata.get('search_source', '')
                result_type = r.metadata.get('type', '')
                
                # å›¾æ£€ç´¢ç»“æœ
                if (search_source in ['graph_vector', 'graph', 'direct_entity', 'full_text'] or 
                    result_type in ['entity', 'relationship', 'triple', 'community']):
                    if result_type == 'entity' or search_source == 'direct_entity':
                        entity_results.append(r)
                    else:
                        graph_results.append(r)
                # æ–‡æ¡£ç»“æœ
                elif (result_type in ['document_chunk', 'bm25_chunk', 'vector_chunk'] or 
                      'document_id' in r.metadata or 
                      'document_title' in r.metadata or
                      search_source in ['vector', 'bm25', 'hybrid']):
                    doc_results.append(r)
                else:
                    other_results.append(r)
            
            # ğŸ”§ è°ƒè¯•ï¼šæ‰“å°ç»“æœåˆ†ç±»ä¿¡æ¯
            self.logger.info(f"ç»“æœåˆ†ç±»: å›¾æ£€ç´¢={len(graph_results)}, æ–‡æ¡£={len(doc_results)}, å®ä½“={len(entity_results)}, å…¶ä»–={len(other_results)}")
            
            # åˆå¹¶å›¾æ£€ç´¢å’Œå®ä½“ç»“æœ
            graph_results.extend(entity_results)
            
            # ğŸ”§ ä¿®å¤ï¼šä¼˜åŒ–å†…å®¹é€‰æ‹©ç­–ç•¥ï¼ŒæŒ‰ç›¸å…³åº¦æ’åº
            # é¦–å…ˆå¯¹æ‰€æœ‰ç»“æœæŒ‰ç›¸å…³åº¦æ’åº
            all_sorted_results = sorted(results, key=lambda x: getattr(x, 'score', 0), reverse=True)
            
            # ğŸ”§ ä¿®å¤ï¼šå¹³è¡¡é€‰æ‹©ä¸åŒç±»å‹çš„å†…å®¹ï¼Œç¡®ä¿å¤šæ ·æ€§
            context_results = []
            
            # æŒ‰ç›¸å…³åº¦é€‰æ‹©æœ€ä½³ç»“æœï¼Œä½†ä¿æŒç±»å‹å¹³è¡¡
            doc_selected = 0
            graph_selected = 0
            entity_selected = 0
            other_selected = 0
            
            max_per_type = max(2, context_top_k // 4)  # æ¯ç§ç±»å‹æœ€å¤šé€‰æ‹©çš„æ•°é‡
            
            for result in all_sorted_results:
                if len(context_results) >= context_top_k:
                    break
                
                if not result.metadata:
                    if other_selected < max_per_type:
                        context_results.append(result)
                        other_selected += 1
                    continue
                
                search_source = result.metadata.get('search_source', '')
                result_type = result.metadata.get('type', '')
                
                # ä¼˜å…ˆé€‰æ‹©é«˜è´¨é‡çš„å®ä½“ç»“æœ
                if (result_type == 'entity' or search_source == 'direct_entity') and entity_selected < max_per_type:
                    context_results.append(result)
                    entity_selected += 1
                # ç„¶åé€‰æ‹©æ–‡æ¡£ç»“æœ
                elif (result_type in ['document_chunk', 'bm25_chunk', 'vector_chunk'] or 
                      'document_id' in result.metadata or 
                      'document_title' in result.metadata or
                      search_source in ['vector', 'bm25', 'hybrid']) and doc_selected < max_per_type:
                    context_results.append(result)
                    doc_selected += 1
                # æœ€åé€‰æ‹©å›¾æ£€ç´¢ç»“æœ
                elif (search_source in ['graph_vector', 'graph', 'full_text'] or 
                      result_type in ['relationship', 'triple', 'community']) and graph_selected < max_per_type:
                    context_results.append(result)
                    graph_selected += 1
                # å…¶ä»–ç»“æœ
                elif other_selected < max_per_type:
                    context_results.append(result)
                    other_selected += 1
            
            # ğŸ”§ å¦‚æœè¿˜æœ‰ç©ºä½ï¼ŒæŒ‰ç›¸å…³åº¦å¡«å……å‰©ä½™ä½ç½®
            if len(context_results) < context_top_k:
                remaining_slots = context_top_k - len(context_results)
                selected_ids = {id(r) for r in context_results}
                for result in all_sorted_results:
                    if len(context_results) >= context_top_k:
                        break
                    if id(result) not in selected_ids:
                        context_results.append(result)
            
            # ğŸ”§ å¦‚æœåˆ†ç±»åæ²¡æœ‰ç»“æœï¼Œç›´æ¥ä½¿ç”¨æ‰€æœ‰åŸå§‹ç»“æœ
            if not context_results and results:
                self.logger.warning("åˆ†ç±»åæ— ç»“æœï¼Œç›´æ¥ä½¿ç”¨æ‰€æœ‰åŸå§‹ç»“æœ")
                context_results = all_sorted_results[:context_top_k]
            
            # ğŸ”§ é‡æ–°è®¾è®¡ä¸Šä¸‹æ–‡æ ¼å¼ï¼Œæ”¯æŒæ‰€æœ‰ç±»å‹çš„ç»“æœ
            context_sections = []
            
            # ğŸ”§ è°ƒè¯•ï¼šè®°å½•å®é™…ä½¿ç”¨çš„ç»“æœæ•°é‡
            self.logger.info(f"æ„å»ºä¸Šä¸‹æ–‡: ä½¿ç”¨{len(context_results)}æ¡ç»“æœ")
            
            # === å¤„ç†æ‰€æœ‰ç»“æœï¼ŒæŒ‰æ¥æºåˆ†ç»„ ===
            entity_info = []
            document_info = []
            graph_info = []
            other_info = []
            
            for i, result in enumerate(context_results):
                 try:
                     # ğŸ”§ å¢å¼ºï¼šæ›´å¼ºçš„å±æ€§è®¿é—®å®¹é”™
                     content = ""
                     if hasattr(result, 'content'):
                         content = str(result.content).strip()
                     elif isinstance(result, dict):
                         content = str(result.get('content', '')).strip()
                     
                     if not content:
                         self.logger.warning(f"ç»“æœ{i+1}å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡")
                         continue
                     
                     # ğŸ”§ ä¿®å¤ï¼šæˆªæ–­è¿‡é•¿çš„å†…å®¹
                     if len(content) > max_content_per_item:
                         content = content[:max_content_per_item] + "..."
                         self.logger.debug(f"ç»“æœ{i+1}å†…å®¹è¢«æˆªæ–­åˆ°{max_content_per_item}å­—ç¬¦")
                     
                     # è·å–åˆ†æ•°
                     score = 0.0
                     if hasattr(result, 'score'):
                         score = float(result.score)
                     elif isinstance(result, dict):
                         score = float(result.get('score', 0.0))
                     
                     # è·å–metadata
                     metadata = {}
                     if hasattr(result, 'metadata'):
                         metadata = result.metadata or {}
                     elif isinstance(result, dict):
                         metadata = result.get('metadata', {})
                     
                     # æ„å»ºæ¥æºä¿¡æ¯
                     source_info = ""
                     search_source = metadata.get('search_source', '')
                     result_type = metadata.get('type', '')
                     
                     if search_source:
                         source_info = f"[{search_source}]"
                     elif result_type:
                         source_info = f"[{result_type}]"
                     
                     # ğŸ”§ è°ƒè¯•ï¼šè®°å½•å¤„ç†çš„ç»“æœ
                    #  self.logger.info(f"å¤„ç†ç»“æœ{i+1}: content={content[:50]}..., score={score}, source={search_source}, type={result_type}")
                     
                     # åˆ†ç±»ç»“æœ
                     if result_type == 'entity' or search_source == 'direct_entity':
                         entity_info.append(f"â€¢ {content} {source_info} [ç›¸å…³åº¦: {score:.3f}]")
                     elif (result_type in ['document_chunk', 'bm25_chunk', 'vector_chunk'] or 
                           'document_title' in metadata or 
                           search_source in ['vector', 'bm25', 'hybrid']):
                         # æå–æ–‡æ¡£ä¿¡æ¯
                         doc_title = metadata.get('document_title', '')
                         if doc_title:
                             source_info = f"[{doc_title}]"
                         document_info.append(f"â€¢ {content} {source_info} [ç›¸å…³åº¦: {score:.3f}]")
                     elif (search_source in ['graph_vector', 'graph', 'full_text'] or 
                           result_type in ['relationship', 'triple', 'community']):
                         graph_info.append(f"â€¢ {content} {source_info} [ç›¸å…³åº¦: {score:.3f}]")
                     else:
                         # ğŸ”§ ä¿®å¤ï¼šç¡®ä¿æ‰€æœ‰ç»“æœéƒ½è¢«åŒ…å«
                         other_info.append(f"â€¢ {content} {source_info} [ç›¸å…³åº¦: {score:.3f}]")
                 
                 except Exception as e:
                     self.logger.error(f"å¤„ç†ç»“æœ{i+1}æ—¶å‡ºé”™: {e}")
                     # ğŸ”§ å®¹é”™ï¼šå³ä½¿å‡ºé”™ä¹Ÿå°è¯•æå–åŸºæœ¬ä¿¡æ¯
                     try:
                         content = str(result)[:200] if result else "æ— å†…å®¹"
                         other_info.append(f"â€¢ {content} [å¤„ç†å‡ºé”™]")
                     except:
                         pass
            
            # æŒ‰ä¼˜å…ˆçº§æ·»åŠ åˆ°ä¸Šä¸‹æ–‡
            if entity_info:
                context_sections.append("=== å®ä½“ä¿¡æ¯ ===")
                context_sections.extend(entity_info)
            
            if document_info:
                if context_sections:
                    context_sections.append("\n=== æ–‡æ¡£å†…å®¹ ===")
                else:
                    context_sections.append("=== æ–‡æ¡£å†…å®¹ ===")
                context_sections.extend(document_info)
            
            if graph_info:
                if context_sections:
                    context_sections.append("\n=== çŸ¥è¯†å›¾è°±ä¿¡æ¯ ===")
                else:
                    context_sections.append("=== çŸ¥è¯†å›¾è°±ä¿¡æ¯ ===")
                context_sections.extend(graph_info)
            
            if other_info:
                if context_sections:
                    context_sections.append("\n=== å…¶ä»–ç›¸å…³ä¿¡æ¯ ===")
                else:
                    context_sections.append("=== å…¶ä»–ç›¸å…³ä¿¡æ¯ ===")
                context_sections.extend(other_info)
            
            # ğŸ”§ æœ€ç»ˆå®‰å…¨ç½‘ï¼šå¦‚æœæ‰€æœ‰åˆ†ç±»éƒ½ä¸ºç©ºï¼Œç›´æ¥æ˜¾ç¤ºåŸå§‹ç»“æœ
            if not entity_info and not document_info and not graph_info and not other_info:
                self.logger.warning("æ‰€æœ‰åˆ†ç±»éƒ½ä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹ç»“æœ")
                context_sections.append("=== æ£€ç´¢ç»“æœ ===")
                for i, result in enumerate(context_results):
                    try:
                        content = str(getattr(result, 'content', result))[:500]
                        score = getattr(result, 'score', 0.0)
                        context_sections.append(f"â€¢ ç»“æœ{i+1}: {content} [ç›¸å…³åº¦: {score:.3f}]")
                    except:
                        context_sections.append(f"â€¢ ç»“æœ{i+1}: {str(result)[:200]}")
            
            context = "\n".join(context_sections)
            
            # ğŸ”§ ä¿®å¤ï¼šæ·»åŠ æœ€ç»ˆä¸Šä¸‹æ–‡é•¿åº¦æ£€æŸ¥å’Œæˆªæ–­
            if len(context) > max_context_length:
                self.logger.warning(f"ä¸Šä¸‹æ–‡é•¿åº¦{len(context)}è¶…è¿‡é™åˆ¶{max_context_length}ï¼Œè¿›è¡Œæˆªæ–­")
                context = context[:max_context_length] + "\n\n[æ³¨ï¼šå†…å®¹å› é•¿åº¦é™åˆ¶è¢«æˆªæ–­]"
            
            # ğŸ”§ è°ƒè¯•ï¼šæ£€æŸ¥æœ€ç»ˆä¸Šä¸‹æ–‡
            self.logger.info(f"æœ€ç»ˆä¸Šä¸‹æ–‡é•¿åº¦: {len(context)}å­—ç¬¦ (é™åˆ¶: {max_context_length})")
            if len(context) < 50:
                self.logger.warning(f"ä¸Šä¸‹æ–‡è¿‡çŸ­: '{context}'")
                # å¦‚æœä¸Šä¸‹æ–‡å¤ªçŸ­ï¼Œå¼ºåˆ¶æ·»åŠ ä¸€äº›å†…å®¹
                if context_results:
                    context = "=== æ£€ç´¢åˆ°çš„ä¿¡æ¯ ===\n"
                    for i, result in enumerate(context_results[:3]):
                        try:
                            content = str(getattr(result, 'content', result))[:300]  # é™åˆ¶æ¯ä¸ªç»“æœ300å­—ç¬¦
                            context += f"ç»“æœ{i+1}: {content}\n"
                        except:
                            context += f"ç»“æœ{i+1}: {str(result)[:200]}\n"
            
            # ä½¿ç”¨æç¤ºè¯ç®¡ç†å™¨åŠ è½½æ¨¡æ¿
            try:
                prompt_template = self.prompt_manager.get_prompt_template("rag_qa", "template")
                if prompt_template:
                    prompt = prompt_template.format(context=context, query=query)
                else:
                    # å›é€€åˆ°é»˜è®¤æ¨¡æ¿
                    prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ™ºèƒ½é—®ç­”åŠ©æ‰‹ï¼Œèƒ½å¤ŸåŸºäºå¤šç§æ¥æºçš„ä¿¡æ¯ä¸ºç”¨æˆ·æä¾›å‡†ç¡®ã€å…¨é¢çš„ç­”æ¡ˆã€‚

## æ£€ç´¢åˆ°çš„ç›¸å…³ä¿¡æ¯
{context}

## ç”¨æˆ·é—®é¢˜
{query}

## è¯·æä¾›ç­”æ¡ˆ"""
            except Exception as e:
                self.logger.warning(f"æç¤ºè¯æ¨¡æ¿åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿: {e}")
                prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ™ºèƒ½é—®ç­”åŠ©æ‰‹ï¼Œèƒ½å¤ŸåŸºäºå¤šç§æ¥æºçš„ä¿¡æ¯ä¸ºç”¨æˆ·æä¾›å‡†ç¡®ã€å…¨é¢çš„ç­”æ¡ˆã€‚

## æ£€ç´¢åˆ°çš„ç›¸å…³ä¿¡æ¯
{context}

## ç”¨æˆ·é—®é¢˜
{query}

## è¯·æä¾›ç­”æ¡ˆ"""
            
            # è®°å½•æç¤ºè¯ä¿¡æ¯
            self.logger.info(f"æç¤ºè¯æ„å»ºå®Œæˆ - ä¸Šä¸‹æ–‡:{len(context)}å­—ç¬¦, æ€»é•¿åº¦:{len(prompt)}å­—ç¬¦")
            
            # æ˜¾ç¤ºå®Œæ•´æç¤ºè¯
            print("\n" + "="*60)
            print("ğŸ“ æœ€ç»ˆå‘é€ç»™å¤§æ¨¡å‹çš„æç¤ºè¯:")
            print("="*60)
            print(prompt)
            print("="*60)
            
            # è°ƒç”¨ LLM ç”Ÿæˆç­”æ¡ˆï¼ˆæµå¼è¿”å›ï¼‰
            print(f"\nğŸ¤– AI å›ç­”:")
            print("-" * 50)
            self.logger.info("å¼€å§‹è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆç­”æ¡ˆ")
            
            # æ£€æŸ¥æ˜¯å¦æ”¯æŒæµå¼è°ƒç”¨
            if hasattr(self.llm_client, 'astream'):
                # ä½¿ç”¨æµå¼è°ƒç”¨
                full_response = ""
                async for chunk in self.llm_client.astream(prompt):
                    if hasattr(chunk, 'content') and chunk.content:
                        print(chunk.content, end='', flush=True)
                        full_response += chunk.content
                    elif isinstance(chunk, str):
                        print(chunk, end='', flush=True)
                        full_response += chunk
                
                print()  # æ¢è¡Œ
                self.logger.info(f"ç­”æ¡ˆç”Ÿæˆå®Œæˆ: {len(full_response)}å­—ç¬¦")
            else:
                # å›é€€åˆ°éæµå¼è°ƒç”¨
                response = await self.llm_client.ainvoke(prompt)
                print(response.content)
                self.logger.info(f"ç­”æ¡ˆç”Ÿæˆå®Œæˆ: {len(response.content)}å­—ç¬¦")
            
            print("-" * 50)
            
        except Exception as e:
            self.logger.error(f"ç­”æ¡ˆç”Ÿæˆé”™è¯¯: {e}")
            print(f"âŒ ç­”æ¡ˆç”Ÿæˆå‡ºé”™: {e}")
    
    async def run_demo(self) -> None:
        """è¿è¡Œå®Œæ•´æ¼”ç¤ºæµç¨‹"""
        try:
            print("ğŸš€ å¯åŠ¨ AgenticX GraphRAG æ¼”ç¤ºç³»ç»Ÿ...")
            
            # 1. åˆå§‹åŒ–ç»„ä»¶
            await self.initialize_components()
            
            # 2. éªŒè¯æ•°æ®è·¯å¾„
            file_paths = self.validate_data_path()
            
            # 3. åŠ è½½æ–‡æ¡£
            documents = await self.load_documents(file_paths)
            
            # 4. æ„å»ºçŸ¥è¯†å›¾è°±
            await self.build_knowledge_graph(documents)
            
            # 5. å­˜å‚¨å’Œç´¢å¼•
            await self.store_and_index()
            
            # 6. å¯åŠ¨äº¤äº’å¼é—®ç­”
            await self.interactive_qa()
            
        except Exception as e:
            self.logger.error(f"æ¼”ç¤ºè¿è¡Œé”™è¯¯: {e}")
            print(f"âŒ æ¼”ç¤ºè¿è¡Œå‡ºé”™: {e}")
            raise
    
    async def run_build_only(self) -> None:
        """ä»…æ„å»ºæ¨¡å¼ï¼Œæ‰§è¡Œæ–‡æ¡£è§£æå’ŒçŸ¥è¯†åº“æ„å»ºï¼Œä¸å¯åŠ¨é—®ç­”"""
        try:
            print("ğŸ”¨ å¯åŠ¨ AgenticX GraphRAG æ„å»ºæ¨¡å¼...")
            print("ğŸ“‹ æ‰§è¡Œæ–‡æ¡£è§£æå’ŒçŸ¥è¯†åº“æ„å»ºï¼Œå®Œæˆåé€€å‡º")
            
            # 1. åˆå§‹åŒ–ç»„ä»¶
            await self.initialize_components()
            
            # 2. éªŒè¯æ•°æ®è·¯å¾„
            file_paths = self.validate_data_path()
            
            # 3. åŠ è½½æ–‡æ¡£
            documents = await self.load_documents(file_paths)
            
            # 4. æ„å»ºçŸ¥è¯†å›¾è°±
            await self.build_knowledge_graph(documents)
            
            # 5. å­˜å‚¨å’Œç´¢å¼•
            await self.store_and_index()
            
            print("âœ… çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼")
            print("ğŸ’¡ ç°åœ¨å¯ä»¥ä½¿ç”¨ 'python main.py --mode qa' å¯åŠ¨é—®ç­”ç³»ç»Ÿ")
            
        except Exception as e:
            self.logger.error(f"æ„å»ºæ¨¡å¼è¿è¡Œé”™è¯¯: {e}")
            print(f"âŒ æ„å»ºæ¨¡å¼è¿è¡Œå‡ºé”™: {e}")
            raise

    async def run_qa_only(self) -> None:
        """ä»…è¿è¡Œé—®ç­”æ¨¡å¼ï¼Œè·³è¿‡æ–‡æ¡£è§£æå’ŒçŸ¥è¯†åº“æ„å»º"""
        try:
            print("å¯åŠ¨ AgenticX GraphRAG é—®ç­”æ¨¡å¼...")
            print("ğŸ“‹ è·³è¿‡æ–‡æ¡£è§£æå’ŒçŸ¥è¯†åº“æ„å»ºï¼Œç›´æ¥ä½¿ç”¨å·²æœ‰æ•°æ®")
            
            # 1. åˆå§‹åŒ–ç»„ä»¶
            await self.initialize_components()
            
            # 2. éªŒè¯å·²æœ‰æ•°æ®
            await self._validate_existing_data()
            
            # 3. å¯åŠ¨äº¤äº’å¼é—®ç­”
            await self.interactive_qa()
            
        except Exception as e:
            self.logger.error(f"é—®ç­”æ¨¡å¼è¿è¡Œé”™è¯¯: {e}")
            print(f"âŒ é—®ç­”æ¨¡å¼è¿è¡Œå‡ºé”™: {e}")
            raise
    
    async def _validate_existing_data(self) -> None:
        """éªŒè¯å·²æœ‰çš„å‘é‡å’Œå›¾æ•°æ®åº“æ•°æ®"""
        self.logger.info("ğŸ” éªŒè¯å·²æœ‰æ•°æ®...")
        
        # æ£€æŸ¥å‘é‡æ•°æ®åº“
        try:
            from agenticx.storage import StorageType
            vector_storage = await self.storage_manager.get_vector_storage('default')
            if not vector_storage:
                vector_storage = self.storage_manager.get_storage(StorageType.MILVUS)
            
            if vector_storage:
                # å°è¯•éªŒè¯å‘é‡æ•°æ®åº“è¿æ¥å’Œæ•°æ®
                try:
                    # é¦–å…ˆæ£€æŸ¥å¯¹è±¡çš„æ‰€æœ‰å¯ç”¨æ–¹æ³•
                    available_methods = [method for method in dir(vector_storage) if not method.startswith('_')]
                    # ç§»é™¤å†—ä½™æ—¥å¿—
                    
                    # å°è¯•ç®€å•çš„è¿æ¥éªŒè¯ï¼Œè€Œä¸æ˜¯æ•°æ®æœç´¢
                    if hasattr(vector_storage, 'collection') and vector_storage.collection:
                        # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
                        collection_info = vector_storage.collection.describe()
                        self.logger.debug(f"Milvusé›†åˆ: {collection_info['collection_name']}")
                        print(f"âœ… å‘é‡æ•°æ®åº“è¿æ¥æ­£å¸¸ï¼Œé›†åˆå·²å­˜åœ¨")
                        
                        # å°è¯•è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯
                        if hasattr(vector_storage.collection, 'num_entities'):
                            entity_count = vector_storage.collection.num_entities
                            self.logger.debug(f"å‘é‡æ•°æ®åº“è®°å½•æ•°: {entity_count}")
                            print(f"å‘é‡æ•°æ®åº“: {entity_count}æ¡è®°å½•")
                        
                    elif hasattr(vector_storage, 'client'):
                        # å¦‚æœæœ‰clientå±æ€§ï¼Œå°è¯•æ£€æŸ¥è¿æ¥
                        self.logger.info("âœ… Milvuså®¢æˆ·ç«¯è¿æ¥æ­£å¸¸")
                        print(f"âœ… å‘é‡æ•°æ®åº“è¿æ¥æ­£å¸¸")
                    else:
                        # ç®€å•çš„è¿æ¥éªŒè¯
                        self.logger.info("âœ… å‘é‡æ•°æ®åº“å¯¹è±¡åˆ›å»ºæˆåŠŸ")
                        print(f"âœ… å‘é‡æ•°æ®åº“è¿æ¥æ­£å¸¸")
                        
                except Exception as validation_error:
                    self.logger.warning(f"å‘é‡æ•°æ®åº“éªŒè¯å¤±è´¥: {validation_error}")
                    print(f"âœ… å‘é‡æ•°æ®åº“è¿æ¥æ­£å¸¸ï¼ˆè·³è¿‡è¯¦ç»†éªŒè¯ï¼‰")
            else:
                self.logger.error("âŒ æ— æ³•è¿æ¥åˆ°å‘é‡æ•°æ®åº“")
                print("âŒ æ— æ³•è¿æ¥åˆ°å‘é‡æ•°æ®åº“")
                
        except Exception as e:
            self.logger.error(f"å‘é‡æ•°æ®åº“éªŒè¯å¤±è´¥: {e}")
            print(f"âš ï¸ å‘é‡æ•°æ®åº“éªŒè¯å¤±è´¥: {e}")
        
        # æ£€æŸ¥å›¾æ•°æ®åº“
        try:
            graph_storage = await self.storage_manager.get_graph_storage('default')
            if not graph_storage:
                graph_storage = self.storage_manager.get_storage(StorageType.NEO4J)
            
            if graph_storage:
                # æ£€æŸ¥å›¾æ•°æ®åº“ä¸­çš„èŠ‚ç‚¹æ•°é‡
                count_query = "MATCH (n) RETURN count(n) as node_count"
                result = graph_storage.execute_query(count_query)
                
                if result and len(result) > 0:
                    node_count = result[0]['node_count']
                    self.logger.debug(f"å›¾æ•°æ®åº“éªŒè¯: {node_count}ä¸ªèŠ‚ç‚¹")
                    print(f"âœ… å›¾æ•°æ®åº“è¿æ¥æ­£å¸¸ï¼ŒåŒ…å« {node_count} ä¸ªèŠ‚ç‚¹")
                    
                    # æ£€æŸ¥å…³ç³»æ•°é‡
                    rel_count_query = "MATCH ()-[r]->() RETURN count(r) as rel_count"
                    rel_result = graph_storage.execute_query(rel_count_query)
                    if rel_result and len(rel_result) > 0:
                        rel_count = rel_result[0]['rel_count']
                        self.logger.debug(f"å›¾æ•°æ®åº“å…³ç³»æ•°: {rel_count}")
                        print(f"âœ… å›¾æ•°æ®åº“åŒ…å« {rel_count} ä¸ªå…³ç³»")
                else:
                    self.logger.warning("âš ï¸ å›¾æ•°æ®åº“ä¸ºç©º")
                    print("âš ï¸ å›¾æ•°æ®åº“ä¼¼ä¹ä¸ºç©ºï¼Œå¯èƒ½éœ€è¦é‡æ–°æ„å»º")
            else:
                self.logger.error("âŒ æ— æ³•è¿æ¥åˆ°å›¾æ•°æ®åº“")
                print("âŒ æ— æ³•è¿æ¥åˆ°å›¾æ•°æ®åº“")
                
        except Exception as e:
            self.logger.error(f"å›¾æ•°æ®åº“éªŒè¯å¤±è´¥: {e}")
            print(f"âš ï¸ å›¾æ•°æ®åº“éªŒè¯å¤±è´¥: {e}")
        
        self.logger.info("æ•°æ®éªŒè¯å®Œæˆ")

    async def cleanup(self) -> None:
        """æ¸…ç†èµ„æº"""
        try:
            # å…³é—­å›¾æ•°æ®åº“è¿æ¥
            if hasattr(self, 'storage_manager') and self.storage_manager:
                graph_storage = self.storage_manager.get_storage(StorageType.NEO4J)
                if graph_storage and hasattr(graph_storage, 'close'):
                    graph_storage.close()
                    logger.info("âœ… Neo4j è¿æ¥å·²å…³é—­")
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†èµ„æºå¤±è´¥: {e}")


async def interactive_mode():
    """äº¤äº’å¼æ¨¡å¼ä¸»å‡½æ•°"""
    # æ˜¾ç¤ºæ¬¢è¿ç•Œé¢
    print_welcome()
    
    # ğŸ”§ ä¿®å¤ï¼šå¯åŠ¨æ—¶ç›´æ¥æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
    print_help()
    
    # åˆå§‹åŒ–é…ç½®
    data_path = None
    run_mode = None
    demo_instance = None
    
    while True:
        try:
            # è·å–ç”¨æˆ·è¾“å…¥
            if console and Prompt:
                user_input = Prompt.ask("\n[bold green]è¯·è¾“å…¥å‘½ä»¤æˆ–é—®é¢˜[/bold green] ([dim]/help æŸ¥çœ‹å¸®åŠ©[/dim])").strip()
            else:
                user_input = input("\nè¯·è¾“å…¥å‘½ä»¤æˆ–é—®é¢˜ (/help æŸ¥çœ‹å¸®åŠ©): ").strip()
            
            if not user_input:
                continue
            
            # å¤„ç†å‘½ä»¤
            if user_input.startswith('/'):
                command = user_input.lower()
                
                if command == '/help':
                    print_help()
                
                elif command == '/clear':
                    if console:
                        console.clear()
                    else:
                        os.system('clear' if os.name == 'posix' else 'cls')
                    print_welcome()
                
                elif command == '/mode':
                    run_mode = select_run_mode()
                    print_success(f"å·²é€‰æ‹©è¿è¡Œæ¨¡å¼: {run_mode}")
                    
                    # ğŸ”§ ä¿®å¤ï¼šé€‰æ‹©æ¨¡å¼åç«‹å³è¿›è¡Œå®Œæ•´çš„åˆå§‹åŒ–æµç¨‹
                    try:
                        # 1. é€‰æ‹©æ•°æ®ç›®å½•
                        print_mode_selection("è¯·é€‰æ‹©æ•°æ®ç›®å½•")
                        data_path = display_data_selection()
                        print_success(f"å·²é€‰æ‹©æ•°æ®ç›®å½•: {data_path}")
                        
                        # 2. åˆå§‹åŒ–ç³»ç»Ÿ
                        print_action("æ­£åœ¨åˆå§‹åŒ– GraphRAG ç³»ç»Ÿ...")
                        demo_instance = AgenticXGraphRAGDemo(config_path="configs.yml", mode=run_mode)
                        demo_instance.data_dir = Path(data_path)  # è®¾ç½®æ•°æ®ç›®å½•
                        
                        # 3. æ ¹æ®æ¨¡å¼æ‰§è¡Œç›¸åº”çš„æ“ä½œ
                        if run_mode in ['full', 'build']:
                            print_action("æ­£åœ¨æ„å»ºçŸ¥è¯†åº“...")
                            await demo_instance.run_build_only()
                            print_success("çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼")
                            
                            if run_mode == 'build':
                                print_info("æ„å»ºæ¨¡å¼å®Œæˆï¼Œå¯ä»¥ä½¿ç”¨ /mode åˆ‡æ¢åˆ°é—®ç­”æ¨¡å¼")
                                continue
                            else:  # fullæ¨¡å¼
                                print_success("ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¼€å§‹é—®ç­”ï¼")
                        
                        elif run_mode == 'qa':
                            print_action("æ­£åœ¨åŠ è½½å·²æœ‰çŸ¥è¯†åº“...")
                            await demo_instance.initialize_components()
                            await demo_instance._validate_existing_data()
                            print_success("ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¼€å§‹é—®ç­”ï¼")
                        
                    except Exception as e:
                        print_error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
                        demo_instance = None
                        run_mode = None
                        data_path = None
                
                elif command == '/data':
                    data_path = display_data_selection()
                    print_success(f"å·²é€‰æ‹©æ•°æ®ç›®å½•: {data_path}")
                
                elif command == '/rebuild':
                    if console and Confirm:
                        rebuild = Confirm.ask("ç¡®å®šè¦é‡æ–°æ„å»ºçŸ¥è¯†åº“å—ï¼Ÿè¿™å°†åˆ é™¤ç°æœ‰çš„ç´¢å¼•")
                    else:
                        rebuild_input = input("ç¡®å®šè¦é‡æ–°æ„å»ºçŸ¥è¯†åº“å—ï¼Ÿ(y/N): ").strip().lower()
                        rebuild = rebuild_input in ['y', 'yes']
                    
                    if rebuild:
                        try:
                            # ğŸ”§ ä¿®å¤ï¼šç«‹å³æ‰§è¡Œé‡å»ºæ“ä½œ
                            print_mode_selection("è¯·é€‰æ‹©æ•°æ®ç›®å½•")
                            data_path = display_data_selection()
                            print_success(f"å·²é€‰æ‹©æ•°æ®ç›®å½•: {data_path}")
                            
                            print_action("æ­£åœ¨é‡æ–°æ„å»ºçŸ¥è¯†åº“...")
                            # åˆ›å»ºbuildæ¨¡å¼çš„demoå®ä¾‹
                            rebuild_demo = AgenticXGraphRAGDemo(config_path="configs.yml", mode="build")
                            rebuild_demo.data_dir = Path(data_path)
                            
                            # æ‰§è¡Œé‡å»º
                            await rebuild_demo.run_build_only()
                            print_success("çŸ¥è¯†åº“é‡å»ºå®Œæˆï¼")
                            
                            # å¦‚æœå½“å‰æœ‰è¿è¡Œçš„å®ä¾‹ï¼Œé‡ç½®å®ƒ
                            if demo_instance:
                                print_info("é‡ç½®å½“å‰ç³»ç»Ÿå®ä¾‹ï¼Œè¯·é‡æ–°ä½¿ç”¨ /mode é€‰æ‹©è¿è¡Œæ¨¡å¼")
                                demo_instance = None
                                run_mode = None
                                
                        except Exception as e:
                            print_error(f"é‡å»ºå¤±è´¥: {e}")
                    else:
                        print_info("å–æ¶ˆé‡æ–°æ„å»º")
                
                elif command == '/exit':
                    print_success("æ„Ÿè°¢ä½¿ç”¨ AgenticX GraphRAG ç³»ç»Ÿï¼")
                    break
                
                else:
                    print_error(f"æœªçŸ¥å‘½ä»¤: {command}")
                    print_info("è¾“å…¥ /help æŸ¥çœ‹å¯ç”¨å‘½ä»¤")
            
            else:
                # ğŸ”§ ä¿®å¤ï¼šç®€åŒ–é—®ç­”å¤„ç†é€»è¾‘
                if not demo_instance:
                    print_error("ç³»ç»Ÿå°šæœªåˆå§‹åŒ–ï¼Œè¯·å…ˆä½¿ç”¨ /mode é€‰æ‹©è¿è¡Œæ¨¡å¼")
                    continue
                
                # æ‰§è¡Œé—®ç­”
                try:
                    print_thinking(f"æ­£åœ¨å¤„ç†æ‚¨çš„é—®é¢˜: {user_input}")
                    await demo_instance._process_query(user_input)
                except Exception as e:
                    print_error(f"é—®ç­”å¤„ç†å¤±è´¥: {e}")
                    logger.error(f"Query processing error: {e}", exc_info=True)
        
        except KeyboardInterrupt:
            print_success("\næ„Ÿè°¢ä½¿ç”¨ AgenticX GraphRAG ç³»ç»Ÿï¼")
            break
        except Exception as e:
            print_error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            logger.error(f"Interactive mode error: {e}", exc_info=True)

async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(
        description='AgenticX GraphRAG æ¼”ç¤ºç³»ç»Ÿ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
è¿è¡Œæ¨¡å¼è¯´æ˜:
  full   - å®Œæ•´æµç¨‹: æ–‡æ¡£è§£æ + çŸ¥è¯†å›¾è°±æ„å»º + å‘é‡ç´¢å¼• + é—®ç­”ç³»ç»Ÿ
  build  - ä»…æ„å»º: æ–‡æ¡£è§£æ + çŸ¥è¯†å›¾è°±æ„å»º + å‘é‡ç´¢å¼• (ä¸å¯åŠ¨é—®ç­”)
  qa     - ä»…é—®ç­”: ç›´æ¥ä½¿ç”¨å·²æœ‰æ•°æ®å¯åŠ¨é—®ç­”ç³»ç»Ÿ (ä¸é‡å»ºæ•°æ®)
  interactive - äº¤äº’å¼æ¨¡å¼: ç¾è§‚çš„ç”¨æˆ·ç•Œé¢ï¼Œæ”¯æŒåŠ¨æ€é…ç½®

ä½¿ç”¨ç¤ºä¾‹:
  python demo.py                    # äº¤äº’å¼æ¨¡å¼ (é»˜è®¤)
  python demo.py --mode full        # å®Œæ•´æµç¨‹
  python demo.py --mode build       # ä»…é‡å»ºçŸ¥è¯†åº“
  python demo.py --mode qa          # ä»…å¯åŠ¨é—®ç­”
        """
    )
    
    parser.add_argument('--mode', choices=['full', 'build', 'qa', 'interactive'], default='interactive',
                       help='è¿è¡Œæ¨¡å¼: interactive=äº¤äº’å¼(é»˜è®¤), full=å®Œæ•´æµç¨‹, build=ä»…æ„å»ºçŸ¥è¯†åº“, qa=ä»…é—®ç­”æ¨¡å¼')
    parser.add_argument('--config', default='configs.yml',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: configs.yml)')
    parser.add_argument('--data-path', default='data',
                       help='æ•°æ®ç›®å½•è·¯å¾„ (é»˜è®¤: data)')
    
    args = parser.parse_args()
    
    # å¦‚æœæ˜¯äº¤äº’å¼æ¨¡å¼ï¼Œç›´æ¥å¯åŠ¨
    if args.mode == 'interactive':
        await interactive_mode()
        return
    
    # æ˜¾ç¤ºæ¨¡å¼ä¿¡æ¯
    mode_descriptions = {
        'full': 'ğŸ”„ å®Œæ•´æ¨¡å¼ - æ–‡æ¡£è§£æ + çŸ¥è¯†åº“æ„å»º + é—®ç­”ç³»ç»Ÿ',
        'build': 'ğŸ”¨ æ„å»ºæ¨¡å¼ - ä»…é‡å»ºçŸ¥è¯†åº“å’Œå‘é‡ç´¢å¼•',
        'qa': 'ğŸ’¬ é—®ç­”æ¨¡å¼ - ä½¿ç”¨å·²æœ‰æ•°æ®å¯åŠ¨é—®ç­”ç³»ç»Ÿ'
    }
    
    print(f"\n{mode_descriptions[args.mode]}")
    print(f"ğŸ“ é…ç½®æ–‡ä»¶: {args.config}")
    print(f"ğŸ“‚ æ•°æ®ç›®å½•: {args.data_path}")
    print("=" * 60)
    
    demo = None
    try:
        # åˆ›å»ºæ¼”ç¤ºç³»ç»Ÿ
        demo = AgenticXGraphRAGDemo(config_path=args.config, mode=args.mode)
        
        # æ ¹æ®æ¨¡å¼è¿è¡Œ
        if args.mode == 'qa':
            await demo.run_qa_only()
        elif args.mode == 'build':
            await demo.run_build_only()
        else:  # full
            await demo.run_demo()
        
    except Exception as e:
        print_error(f"ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {e}")
        sys.exit(1)
    finally:
        # æ¸…ç†èµ„æº
        if demo:
            await demo.cleanup()


if __name__ == "__main__":
    # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
    asyncio.run(main())