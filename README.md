# AgenticX GraphRAG æ¼”ç¤ºç³»ç»Ÿ

ğŸš€ **åŸºäº AgenticX æ¡†æ¶çš„æ™ºèƒ½çŸ¥è¯†å›¾è°±æ„å»ºä¸é—®ç­”ç³»ç»Ÿ**

è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„ GraphRAGï¼ˆå›¾æ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æ¼”ç¤ºç³»ç»Ÿï¼Œé‡‡ç”¨åˆ›æ–°çš„**ä¸¤é˜¶æ®µSPOæŠ½å–æ–¹æ³•**ï¼Œå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ AgenticX æ¡†æ¶æ„å»ºæ™ºèƒ½çŸ¥è¯†å›¾è°±å’Œé—®ç­”ç³»ç»Ÿã€‚

## ğŸ“‹ ç›®å½•

- [ç³»ç»Ÿæ¦‚è¿°](#ç³»ç»Ÿæ¦‚è¿°)
- [æ ¸å¿ƒåˆ›æ–°](#æ ¸å¿ƒåˆ›æ–°)
- [æŠ€æœ¯æ¶æ„](#æŠ€æœ¯æ¶æ„)
- [å·¥ä½œæµç¨‹](#å·¥ä½œæµç¨‹)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [é…ç½®è¯´æ˜](#é…ç½®è¯´æ˜)
- [ä½¿ç”¨æŒ‡å—](#ä½¿ç”¨æŒ‡å—)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
- [ä¸‰è·¯æ£€ç´¢æ¶æ„ä¼˜åŒ–](#ä¸‰è·¯æ£€ç´¢æ¶æ„ä¼˜åŒ–)
- [ç´¢å¼•æ„å»ºä¸æ£€ç´¢æ¶æ„è¯¦è§£](#ç´¢å¼•æ„å»ºä¸æ£€ç´¢æ¶æ„è¯¦è§£)

## ç³»ç»Ÿæ¦‚è¿°

æœ¬æ¼”ç¤ºç³»ç»Ÿé›†æˆäº† AgenticX æ¡†æ¶çš„æ ¸å¿ƒèƒ½åŠ›ï¼Œå®ç°äº†ä»æ–‡æ¡£åˆ°æ™ºèƒ½é—®ç­”çš„å®Œæ•´æµç¨‹ï¼š

- **ğŸ“„ æ™ºèƒ½æ–‡æ¡£å¤„ç†**: å¤šæ ¼å¼æ–‡æ¡£è¯»å–å’Œæ™ºèƒ½åˆ†å—
- **ğŸ§  ä¸¤é˜¶æ®µçŸ¥è¯†æŠ½å–**: Schemaç”Ÿæˆ + SPOæŠ½å–
- **ğŸ•¸ï¸ çŸ¥è¯†å›¾è°±æ„å»º**: å®ä½“å…³ç³»å›¾è°±å’Œç¤¾åŒºæ£€æµ‹
- **ğŸ’¾ å¤šæ¨¡æ€å­˜å‚¨**: å‘é‡ã€å›¾ã€é”®å€¼å­˜å‚¨
- **ğŸ” æ··åˆæ£€ç´¢**: å‘é‡+å›¾+BM25æ™ºèƒ½æ£€ç´¢
- **ğŸ¤– æ™ºèƒ½é—®ç­”**: åŸºäºæ£€ç´¢çš„ç”Ÿæˆå¼é—®ç­”

## ğŸš€ æ ¸å¿ƒåˆ›æ–°

### ä¸¤é˜¶æ®µSPOæŠ½å–æ–¹æ³•

**ä¼ ç»Ÿæ–¹æ³•é—®é¢˜**ï¼š
- âŒ åˆ†ç¦»æŠ½å–ï¼šå…ˆæŠ½å®ä½“ï¼Œå†æŠ½å…³ç³»ï¼Œéœ€è¦2æ¬¡LLMè°ƒç”¨
- âŒ å›ºå®šSchemaï¼šæ— æ³•é€‚åº”ä¸åŒé¢†åŸŸçš„æ–‡æ¡£
- âŒ IDä¸åŒ¹é…ï¼šéœ€è¦å¤æ‚çš„å®ä½“IDä¿®å¤é€»è¾‘

**æˆ‘ä»¬çš„åˆ›æ–°æ–¹æ¡ˆ**ï¼š
```mermaid
graph LR
    A[æ–‡æ¡£é›†åˆ] --> B[æ–‡æ¡£åˆ†æå™¨]
    B --> C[å®šåˆ¶Schemaç”Ÿæˆ]
    C --> D[SPOæŠ½å–å™¨]
    D --> E[çŸ¥è¯†å›¾è°±]
    
    B --> F[æ–‡æ¡£æ‘˜è¦<br/>ç±»åˆ«è¯†åˆ«<br/>é¢†åŸŸæ ‡ç­¾]
    C --> G[å®ä½“ç±»å‹<br/>å…³ç³»ç±»å‹<br/>å±æ€§ç±»å‹]
    D --> H[å®ä½“+å…³ç³»<br/>ä¸€æ¬¡æ€§æŠ½å–]
```

### ğŸ”§ æŠ€æœ¯æ¶æ„

```mermaid
graph TD
    subgraph "é˜¶æ®µ1: æ™ºèƒ½Schemaç”Ÿæˆ"
        A[æ–‡æ¡£å†…å®¹] --> B[æ–‡æ¡£åˆ†æå™¨]
        B --> C[é¢†åŸŸè¯†åˆ«]
        C --> D[Schemaç”Ÿæˆå™¨]
        D --> E[å®šåˆ¶Schema]
    end
    
    subgraph "é˜¶æ®µ2: SPOçŸ¥è¯†æŠ½å–"
        F[æ–‡æœ¬åˆ†å—] --> G[SPOæŠ½å–å™¨]
        E --> G
        G --> H[å®ä½“+å…³ç³»+å±æ€§]
    end
    
    subgraph "é˜¶æ®µ3: å›¾è°±æ„å»ºä¸å¤šæ¨¡æ€ç´¢å¼•"
        H --> I[çŸ¥è¯†å›¾è°±æ„å»º]
        I --> J[ç¤¾åŒºæ£€æµ‹]
        I --> K[å›¾å­˜å‚¨Neo4j]
        
        H --> L[æ–‡æ¡£å‘é‡ç´¢å¼•]
        H --> M[BM25å€’æ’ç´¢å¼•]
        I --> N[å›¾å‘é‡ç´¢å¼•]
        
        L --> O[Milvusæ–‡æ¡£é›†åˆ]
        M --> P[BM25å…³é”®è¯ç´¢å¼•]
        N --> Q[Milvuså›¾é›†åˆ]
    end
    
    subgraph "é˜¶æ®µ4: ä¸‰è·¯æ··åˆæ£€ç´¢é—®ç­”"
        R[ç”¨æˆ·æŸ¥è¯¢] --> S[æŸ¥è¯¢åˆ†æ]
        S --> T[å›¾æ£€ç´¢]
        S --> U[å‘é‡æ£€ç´¢]
        S --> V[BM25æ£€ç´¢]
        
        K --> T
        Q --> T
        O --> U
        P --> V
        
        T --> W[ä¸‰è·¯ç»“æœèåˆ]
        U --> W
        V --> W
        W --> X[ç­”æ¡ˆç”Ÿæˆ]
    end
```

## ğŸ”„ å·¥ä½œæµç¨‹è¯¦è§£

### ğŸ“‹ **å®Œæ•´å¤„ç†æµç¨‹**

```
ğŸ“„ æ–‡æ¡£è¾“å…¥ 
    â†“
ğŸ” æ–‡æ¡£åˆ†æ (åˆ†ç±»ã€æ‘˜è¦ã€æ ‡ç­¾)
    â†“  
å®šåˆ¶Schemaç”Ÿæˆ (å®ä½“ç±»å‹ã€å…³ç³»ç±»å‹ã€å±æ€§ç±»å‹)
    â†“
âœ‚ï¸ ä¸‰ç§åˆ†å—ç­–ç•¥ (GraphRAG:3000å­—ç¬¦ | å‘é‡:1500å­—ç¬¦ | BM25:600å­—ç¬¦)
    â†“
ğŸ” SPOæŠ½å– (åŸºäºå®šåˆ¶Schemaä¸€æ¬¡æ€§æŠ½å–)
    â†“
ğŸ•¸ï¸ çŸ¥è¯†å›¾è°±æ„å»º (å®ä½“+å…³ç³»+å±æ€§)
    â†“
ğŸ˜ï¸ ç¤¾åŒºæ£€æµ‹ (å®ä½“èšç±»å’Œå±‚çº§ç»“æ„)
    â†“
ğŸ“Š ä¸‰è·¯ç´¢å¼•æ„å»º 
    â”œâ”€â”€ ğŸ“„ æ–‡æ¡£å‘é‡ç´¢å¼• (Milvusæ–‡æ¡£é›†åˆ)
    â”œâ”€â”€ ğŸ•¸ï¸ å›¾å‘é‡ç´¢å¼• (Milvuså›¾é›†åˆ: èŠ‚ç‚¹+å…³ç³»+ä¸‰å…ƒç»„+ç¤¾åŒº)
    â””â”€â”€ ğŸ” BM25å€’æ’ç´¢å¼• (å…³é”®è¯ç´¢å¼•)
    â†“
ğŸ’¾ æŒä¹…åŒ–å­˜å‚¨ (Neo4j+Milvus+BM25)
    â†“
ğŸ¤– ä¸‰è·¯æ··åˆæ£€ç´¢é—®ç­”
    â”œâ”€â”€ ğŸ•¸ï¸ å›¾æ£€ç´¢ (ä¼ ç»Ÿéå†+å›¾å‘é‡) æƒé‡40%
    â”œâ”€â”€ ğŸ“„ å‘é‡æ£€ç´¢ (è¯­ä¹‰ç›¸ä¼¼åº¦) æƒé‡40%
    â””â”€â”€ ğŸ” BM25æ£€ç´¢ (å…³é”®è¯åŒ¹é…) æƒé‡20%
    â†“
ğŸ”„ æ™ºèƒ½ç»“æœèåˆ + ç”Ÿæˆå¼å›ç­”
```

### **é˜¶æ®µ1: æ™ºèƒ½Schemaç”Ÿæˆ**

**ç›®æ ‡**: åˆ†ææ–‡æ¡£å†…å®¹ï¼Œç”Ÿæˆé¢†åŸŸç‰¹å®šçš„çŸ¥è¯†æŠ½å–Schema

**æ­¥éª¤**:
1. **æ–‡æ¡£åˆ†æ** (`prompts/document_analysis.yml`):
   ```yaml
   è¾“å…¥: æ–‡æ¡£å†…å®¹
   è¾“å‡º: {
     "summary": "æ–‡æ¡£æ‘˜è¦",
     "category": "æŠ€æœ¯æ–‡æ¡£/å•†ä¸šæŠ¥å‘Š/å­¦æœ¯è®ºæ–‡",
     "domain": "äººå·¥æ™ºèƒ½/é‡‘è/åŒ»ç–—",
     "tags": ["æ·±åº¦å­¦ä¹ ", "Transformer"],
     "key_concepts": ["æ³¨æ„åŠ›æœºåˆ¶", "é¢„è®­ç»ƒ"]
   }
   ```

2. **Schemaç”Ÿæˆ** (`prompts/schema_generation.yml`):
   ```yaml
   è¾“å…¥: åŸºç¡€Schema + æ–‡æ¡£åˆ†æç»“æœ
   è¾“å‡º: {
     "Nodes": ["person", "algorithm", "model", "dataset"],
     "Relations": ["implements", "trains", "evaluates"],
     "Attributes": ["accuracy", "complexity", "version"],
     "domain_info": {
       "primary_domain": "æœºå™¨å­¦ä¹ ",
       "key_concepts": ["ç¥ç»ç½‘ç»œ", "è®­ç»ƒ"]
     }
   }
   ```

### ğŸ” **é˜¶æ®µ2: SPOçŸ¥è¯†æŠ½å–**

**ç›®æ ‡**: åŸºäºå®šåˆ¶Schemaè¿›è¡Œç²¾å‡†çš„å®ä½“-å…³ç³»-å±æ€§æŠ½å–

**æ­¥éª¤**:
1. **æ–‡æ¡£åˆ†å—**: ä½¿ç”¨è¯­ä¹‰åˆ†å—å™¨ï¼Œ800å­—ç¬¦/å—
2. **SPOæŠ½å–** (`prompts/spo_extraction.yml`):
   ```yaml
   è¾“å…¥: æ–‡æœ¬å— + å®šåˆ¶Schema + é¢†åŸŸä¿¡æ¯
   è¾“å‡º: {
     "attributes": {
       "PyTorch": ["ç±»å‹: æ·±åº¦å­¦ä¹ æ¡†æ¶", "å¼€å‘è€…: Meta"]
     },
     "triples": [
       ["PyTorch", "supports", "ç¥ç»ç½‘ç»œ"],
       ["Meta", "develops", "PyTorch"]
     ],
     "entity_types": {
       "PyTorch": "technology",
       "Meta": "organization"
     }
   }
   ```

### ğŸ”§ **åŠ¨æ€å®ä½“åˆ›å»ºæœºåˆ¶**

**æ ¸å¿ƒåˆ›æ–°**: æ™ºèƒ½å®ä½“è¡¥å…¨ï¼Œè§£å†³å…³ç³»æŠ½å–ä¸­çš„å®ä½“ç¼ºå¤±é—®é¢˜

**é—®é¢˜èƒŒæ™¯**:
åœ¨SPOæŠ½å–è¿‡ç¨‹ä¸­ï¼ŒLLMå¯èƒ½è¯†åˆ«å‡ºå…³ç³»ä¸‰å…ƒç»„ï¼Œä½†å…³ç³»ä¸­æ¶‰åŠçš„æŸäº›å®ä½“åœ¨ä¹‹å‰çš„å®ä½“æŠ½å–é˜¶æ®µè¢«é—æ¼ï¼Œå¯¼è‡´ï¼š
- âŒ å…³ç³»æ— æ³•å»ºç«‹ï¼ˆç¼ºå°‘ç«¯ç‚¹å®ä½“ï¼‰
- âŒ çŸ¥è¯†å›¾è°±ä¸å®Œæ•´
- âŒ æ£€ç´¢æ•ˆæœä¸‹é™

**è§£å†³æ–¹æ¡ˆ**:
```python
# å½“å‘ç°å…³ç³» ["PyTorch", "supports", "ç¥ç»ç½‘ç»œ"] æ—¶
# å¦‚æœ"ç¥ç»ç½‘ç»œ"å®ä½“ä¸å­˜åœ¨ï¼Œç³»ç»Ÿä¼šï¼š

def _create_missing_entity(self, entity_name: str) -> str:
    """åŠ¨æ€åˆ›å»ºç¼ºå¤±çš„å®ä½“"""
    
    # 1. æ™ºèƒ½è¿‡æ»¤æ— æ„ä¹‰å®ä½“
    if len(entity_name.strip()) < 2:
        return None
        
    # 2. å¯å‘å¼ç±»å‹æ¨æ–­
    entity_type = self._infer_entity_type(entity_name)
    # "ç¥ç»ç½‘ç»œ" â†’ EntityType.CONCEPT
    
    # 3. åˆ›å»ºå®ä½“å¯¹è±¡
    new_entity = Entity(
        id=str(uuid.uuid4()),
        name=entity_name,
        entity_type=entity_type,
        description=f"åŠ¨æ€åˆ›å»ºçš„å®ä½“: {entity_name}",
        confidence=0.7  # æ ‡è®°ä¸ºåŠ¨æ€åˆ›å»º
    )
    
    return new_entity.id
```

**æ™ºèƒ½ç±»å‹æ¨æ–­è§„åˆ™**:
```python
def _infer_entity_type(self, entity_name: str) -> EntityType:
    """åŸºäºå®ä½“åç§°ç‰¹å¾æ¨æ–­ç±»å‹"""
    
    name_lower = entity_name.lower()
    
    # äººå‘˜ç›¸å…³
    if any(word in name_lower for word in ['äºº', 'è€…', 'å‘˜', 'person', 'researcher']):
        return EntityType.PERSON
    
    # ç»„ç»‡ç›¸å…³  
    if any(word in name_lower for word in ['å…¬å¸', 'ç»„ç»‡', 'æœºæ„', 'company']):
        return EntityType.ORGANIZATION
        
    # åœ°ç‚¹ç›¸å…³
    if any(word in name_lower for word in ['åœ°', 'å¸‚', 'å›½', 'location', 'city']):
        return EntityType.LOCATION
        
    # æŠ€æœ¯æ¦‚å¿µï¼ˆé»˜è®¤ï¼‰
    return EntityType.CONCEPT
```

**æ ¸å¿ƒä¼˜åŠ¿**:
- ğŸ”§ **è‡ªåŠ¨è¡¥å…¨**: ç¡®ä¿å…³ç³»å®Œæ•´æ€§ï¼Œæ— éœ€æ‰‹åŠ¨å¹²é¢„
- ğŸ§  **æ™ºèƒ½æ¨æ–­**: åŸºäºè¯­ä¹‰ç‰¹å¾è‡ªåŠ¨æ¨æ–­å®ä½“ç±»å‹
- ğŸ“Š **è´¨é‡æ§åˆ¶**: è¿‡æ»¤æ— æ„ä¹‰å®ä½“ï¼Œè®¾ç½®åˆç†ç½®ä¿¡åº¦
- ğŸ”„ **å¢é‡å‹å¥½**: æ”¯æŒçŸ¥è¯†å›¾è°±çš„å¢é‡æ›´æ–°å’Œæ‰©å±•
- ğŸ¯ **é¢†åŸŸé€‚åº”**: ç‰¹åˆ«é€‚ç”¨äºå¤šé¢†åŸŸæ–‡æ¡£çš„æ··åˆå¤„ç†

**åº”ç”¨åœºæ™¯**:
- ğŸ“ˆ **é‡‘èæ–‡æ¡£**: åŠ¨æ€è¯†åˆ«æ–°çš„é‡‘èäº§å“ã€äº¤æ˜“ç­–ç•¥
- ğŸ”¬ **ç§‘ç ”è®ºæ–‡**: è‡ªåŠ¨å‘ç°æ–°çš„ç®—æ³•ã€æ¨¡å‹ã€æŠ€æœ¯æ¦‚å¿µ  
- ğŸ¢ **ä¼ä¸šæ–‡æ¡£**: è¯†åˆ«ç»„ç»‡ç»“æ„ã€ä¸šåŠ¡æµç¨‹ä¸­çš„æ–°å®ä½“
- ğŸŒ **å¤šè¯­è¨€æ–‡æ¡£**: è·¨è¯­è¨€å®ä½“çš„ç»Ÿä¸€ç®¡ç†

### ğŸ•¸ï¸ **é˜¶æ®µ3: çŸ¥è¯†å›¾è°±æ„å»º**

**ç›®æ ‡**: æ„å»ºå®Œæ•´çš„çŸ¥è¯†å›¾è°±å¹¶è¿›è¡Œä¼˜åŒ–

**æ­¥éª¤**:
1. **å®ä½“æ•´åˆ**: åˆå¹¶é‡å¤å®ä½“ï¼Œå»ºç«‹å®ä½“å­—å…¸
2. **å…³ç³»å»ºç«‹**: åˆ›å»ºå®ä½“é—´çš„å…³ç³»ç½‘ç»œ
3. **ç¤¾åŒºæ£€æµ‹**: å‘ç°å®ä½“èšç±»å’Œå±‚çº§ç»“æ„
4. **è´¨é‡éªŒè¯**: éªŒè¯å›¾è°±å®Œæ•´æ€§å’Œä¸€è‡´æ€§

### ğŸ“Š **é˜¶æ®µ4: å¤šæ¨¡æ€ç´¢å¼•**

**ç›®æ ‡**: å»ºç«‹å¤šç§æ£€ç´¢ç´¢å¼•ï¼Œæ”¯æŒä¸åŒç±»å‹çš„æŸ¥è¯¢

**ç´¢å¼•ç±»å‹**:
- **å‘é‡ç´¢å¼•**: åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦çš„æ£€ç´¢
- **å›¾ç´¢å¼•**: åŸºäºå®ä½“å…³ç³»çš„å›¾éå†
- **BM25ç´¢å¼•**: åŸºäºå…³é”®è¯çš„ç²¾ç¡®åŒ¹é…
- **SPOç´¢å¼•**: åŸºäºä¸‰å…ƒç»„çš„ç»“æ„åŒ–æŸ¥è¯¢

### ğŸ¤– **é˜¶æ®µ5: æ™ºèƒ½é—®ç­”**

**ç›®æ ‡**: åŸºäºå¤šæ¨¡æ€æ£€ç´¢çš„æ™ºèƒ½é—®ç­”

**æŸ¥è¯¢å¤„ç†æµç¨‹**:
```
ç”¨æˆ·æŸ¥è¯¢ â†’ æŸ¥è¯¢åˆ†æ â†’ æ£€ç´¢ç­–ç•¥é€‰æ‹© â†’ æ··åˆæ£€ç´¢ â†’ ç»“æœé‡æ’ â†’ ç­”æ¡ˆç”Ÿæˆ
```

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

### ğŸ“ ç›®å½•ç»“æ„

```
agenticx-for-graphrag/
â”œâ”€â”€ main.py                    # ä¸»æ¼”ç¤ºç¨‹åº
â”œâ”€â”€ prompt_manager.py          # æç¤ºè¯ç®¡ç†å™¨
â”œâ”€â”€ configs.yml               # ç³»ç»Ÿé…ç½®æ–‡ä»¶
â”œâ”€â”€ schema.json               # åŸºç¡€Schemaå®šä¹‰
â”œâ”€â”€ custom_schema.json        # ç”Ÿæˆçš„å®šåˆ¶Schema
â”œâ”€â”€ requirements.txt          # ä¾èµ–åŒ…åˆ—è¡¨
â”œâ”€â”€ .env.example             # ç¯å¢ƒå˜é‡ç¤ºä¾‹
â”œâ”€â”€ README.md                # é¡¹ç›®è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ prompts/                 # æç¤ºè¯æ–‡ä»¶å¤¹
â”‚   â”œâ”€â”€ document_analysis.yml    # æ–‡æ¡£åˆ†ææç¤ºè¯
â”‚   â”œâ”€â”€ schema_generation.yml    # Schemaç”Ÿæˆæç¤ºè¯
â”‚   â””â”€â”€ spo_extraction.yml       # SPOæŠ½å–æç¤ºè¯
â”œâ”€â”€ data/                    # ç¤ºä¾‹æ•°æ®ç›®å½•
â”‚   â””â”€â”€ sample_documents/
â””â”€â”€ workspace/               # å·¥ä½œç©ºé—´
    â”œâ”€â”€ cache/              # ç¼“å­˜ç›®å½•
    â”œâ”€â”€ logs/               # æ—¥å¿—ç›®å½•
    â””â”€â”€ exports/            # å¯¼å‡ºç›®å½•
```

### ğŸ”§ æ ¸å¿ƒç»„ä»¶

```python
# ä¸¤é˜¶æ®µæŠ½å–ç³»ç»Ÿ
SchemaGenerator              # Schemaç”Ÿæˆå™¨
â”œâ”€â”€ DocumentAnalyzer         # æ–‡æ¡£å†…å®¹åˆ†æ
â”œâ”€â”€ DomainIdentifier        # é¢†åŸŸè¯†åˆ«
â””â”€â”€ CustomSchemaBuilder     # å®šåˆ¶Schemaæ„å»º

SPOExtractor                # SPOæŠ½å–å™¨  
â”œâ”€â”€ PromptManager           # æç¤ºè¯ç®¡ç†
â”œâ”€â”€ SchemaAdapter           # Schemaé€‚é…
â””â”€â”€ TripleExtractor         # ä¸‰å…ƒç»„æŠ½å–

KnowledgeGraphBuilder       # çŸ¥è¯†å›¾è°±æ„å»ºå™¨
â”œâ”€â”€ EntityManager           # å®ä½“ç®¡ç†
â”œâ”€â”€ RelationshipManager     # å…³ç³»ç®¡ç†
â”œâ”€â”€ CommunityDetector       # ç¤¾åŒºæ£€æµ‹
â””â”€â”€ GraphOptimizer          # å›¾è°±ä¼˜åŒ–

HybridRetriever             # æ··åˆæ£€ç´¢å™¨
â”œâ”€â”€ VectorRetriever         # å‘é‡æ£€ç´¢
â”œâ”€â”€ GraphRetriever          # å›¾æ£€ç´¢
â”œâ”€â”€ BM25Retriever          # å…³é”®è¯æ£€ç´¢
â””â”€â”€ ResultReranker          # ç»“æœé‡æ’
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å…‹éš†é¡¹ç›®ä»“åº“
git clone https://github.com/DemonDamon/AgenticX-GraphRAG.git
cd AgenticX-GraphRAG

# ä½¿ç”¨anacondaåˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n agenticx_graphrag python=3.10 -y
conda activate agenticx_graphrag

# ğŸ”§ å®‰è£…AgenticXæ¡†æ¶ï¼ˆå¿…éœ€ï¼‰
pip install agenticx -i https://pypi.org/simple/

# å®‰è£…é¡¹ç›®ä¾èµ–
pip install -r requirements.txt

# å¤åˆ¶å¹¶é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
```

### 2. é…ç½®ç¯å¢ƒå˜é‡

ç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œè®¾ç½®å¿…è¦çš„ç¯å¢ƒå˜é‡ï¼š

```bash
# ç™¾ç‚¼LLMé…ç½®ï¼ˆæ¨èï¼‰
BAILIAN_API_KEY=your_bailian_api_key
BAILIAN_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1

# Neo4jå›¾æ•°æ®åº“é…ç½®
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_password

# Milvuså‘é‡æ•°æ®åº“é…ç½®
MILVUS_HOST=localhost
MILVUS_PORT=19530
MILVUS_USER=
MILVUS_PASSWORD=

# Redisç¼“å­˜é…ç½®
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=password
```

### 3. å¯åŠ¨æ•°æ®å±‚æœåŠ¡

ä½¿ç”¨docker-composeå¯åŠ¨å®Œæ•´çš„æ•°æ®å±‚æœåŠ¡æ ˆï¼š

```bash
# è¿›å…¥dockerç›®å½•
cd docker

# å¯åŠ¨æ‰€æœ‰æ•°æ®å±‚æœåŠ¡ï¼ˆNeo4jã€Milvusã€Redisç­‰ï¼‰
docker-compose up -d

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æœåŠ¡æ—¥å¿—ï¼ˆå¯é€‰ï¼‰
docker-compose logs -f
```

æœåŠ¡å¯åŠ¨åå¯é€šè¿‡ä»¥ä¸‹åœ°å€è®¿é—®ç®¡ç†ç•Œé¢ï¼š
- Neo4j Browser: http://localhost:7474
- Milvus Attu: http://localhost:3001  
- Redis Commander: http://localhost:8081

### 4. å‡†å¤‡æ–‡æ¡£æ•°æ®

```bash
# åˆ›å»ºæ•°æ®ç›®å½•
mkdir -p data

# å°†æ‚¨çš„æ–‡æ¡£æ”¾å…¥dataç›®å½•
cp your_documents.* data/
```

**æ”¯æŒçš„æ–‡æ¡£æ ¼å¼ï¼š**

| æ ¼å¼ç±»å‹ | æ–‡ä»¶æ‰©å±•å | è¯´æ˜ | æ¨èç”¨é€” |
|---------|-----------|------|---------|
| **PDFæ–‡æ¡£** | `.pdf` | æ”¯æŒæ–‡æœ¬æå–å’ŒOCRè¯†åˆ« | å­¦æœ¯è®ºæ–‡ã€æŠ€æœ¯æ–‡æ¡£ã€æŠ¥å‘Š |
| **æ–‡æœ¬æ–‡æ¡£** | `.txt` | çº¯æ–‡æœ¬æ ¼å¼ï¼Œå¤„ç†é€Ÿåº¦æœ€å¿« | ç®€å•æ–‡æ¡£ã€æ—¥å¿—æ–‡ä»¶ |
| **Markdown** | `.md` | æ”¯æŒç»“æ„åŒ–æ ‡è®°è¯­è¨€ | æŠ€æœ¯æ–‡æ¡£ã€è¯´æ˜æ–‡æ¡£ |
| **JSONæ•°æ®** | `.json` | ç»“æ„åŒ–æ•°æ®æ ¼å¼ | APIæ–‡æ¡£ã€é…ç½®æ–‡ä»¶ |
| **CSVè¡¨æ ¼** | `.csv` | è¡¨æ ¼æ•°æ®æ ¼å¼ | æ•°æ®æŠ¥è¡¨ã€ç»Ÿè®¡ä¿¡æ¯ |
| **Wordæ–‡æ¡£** | `.docx` | Microsoft Wordæ ¼å¼ | å•†ä¸šæ–‡æ¡£ã€åˆåŒæ–‡ä»¶ |
| **Excelè¡¨æ ¼** | `.xlsx` | Microsoft Excelæ ¼å¼ | æ•°æ®åˆ†æã€è´¢åŠ¡æŠ¥è¡¨ |

**æ–‡æ¡£å‡†å¤‡å»ºè®®ï¼š**
- å•ä¸ªæ–‡æ¡£å¤§å°å»ºè®®ä¸è¶…è¿‡50MB
- æ‰¹é‡å¤„ç†æ—¶å»ºè®®æ¯æ‰¹ä¸è¶…è¿‡100ä¸ªæ–‡æ¡£
- PDFæ–‡æ¡£ç¡®ä¿æ–‡æœ¬å¯é€‰æ‹©ï¼ˆéçº¯å›¾ç‰‡æ‰«æï¼‰
- æ–‡æ¡£å†…å®¹åº”å…·æœ‰ä¸€å®šçš„ç»“æ„æ€§å’Œé€»è¾‘æ€§

### 5. è¿è¡Œæ¼”ç¤º

```bash
# ç›´æ¥è¿è¡Œä¸»ç¨‹åº
python main.py
```

**æ¼”ç¤ºæµç¨‹**ï¼š
1. ğŸ” **æ–‡æ¡£åˆ†æ**: è‡ªåŠ¨åˆ†ææ–‡æ¡£å†…å®¹å’Œé¢†åŸŸ
2. **Schemaç”Ÿæˆ**: ç”Ÿæˆå®šåˆ¶åŒ–çš„æŠ½å–Schema
3. âœ‚ï¸ **æ™ºèƒ½åˆ†å—**: è¯­ä¹‰åˆ†å—å¤„ç†æ–‡æ¡£
4. ğŸ” **SPOæŠ½å–**: ä¸€æ¬¡æ€§æŠ½å–å®ä½“ã€å…³ç³»ã€å±æ€§
5. ğŸ•¸ï¸ **å›¾è°±æ„å»º**: æ„å»ºçŸ¥è¯†å›¾è°±å’Œç¤¾åŒºç»“æ„
6. ğŸ“Š **ç´¢å¼•å»ºç«‹**: å»ºç«‹å¤šæ¨¡æ€æ£€ç´¢ç´¢å¼•
7. ğŸ¤– **äº¤äº’é—®ç­”**: è¿›å…¥æ™ºèƒ½é—®ç­”æ¨¡å¼

## âš™ï¸ é…ç½®è¯´æ˜

### ğŸ“‹ é…ç½®æ–‡ä»¶ç»“æ„

`configs.yml` åŒ…å«äº†ç³»ç»Ÿçš„å®Œæ•´é…ç½®ï¼Œé‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼š

#### 1. LLMé…ç½®
```yaml
llm:
  provider: "bailian"        # æ¨èä½¿ç”¨ç™¾ç‚¼
  model: "qwen-turbo"       # ç¨³å®šå¿«é€Ÿçš„æ¨¡å‹
  temperature: 0.1          # ä½æ¸©åº¦ä¿è¯ç¨³å®šæ€§
  max_tokens: 2048          # é€‚ä¸­çš„tokenæ•°
  timeout: 180              # 3åˆ†é’Ÿè¶…æ—¶
  retry_attempts: 5         # é‡è¯•5æ¬¡
```

#### 2. ä¸¤é˜¶æ®µæŠ½å–é…ç½®
```yaml
knowledge:
  graphrag:
    # æŠ½å–æ–¹æ³•é…ç½®
    extraction_method: "spo"           # ä¸¤é˜¶æ®µSPOæŠ½å–
    schema_path: "schema.json"         # åŸºç¡€Schemaè·¯å¾„
    enable_custom_schema: true         # å¯ç”¨å®šåˆ¶Schema
    prompts_dir: "prompts"            # æç¤ºè¯ç›®å½•
    
    # æ™ºèƒ½åˆ†å—é…ç½®
    chunking:
      strategy: "semantic"             # è¯­ä¹‰åˆ†å—
      chunk_size: 800                 # åˆ†å—å¤§å°
      chunk_overlap: 150              # é‡å å¤§å°
      max_chunk_size: 1200            # æœ€å¤§åˆ†å—
```

#### 3. åµŒå…¥æœåŠ¡é…ç½®
```yaml
embeddings:
  router:
    default_provider: "bailian"       # é»˜è®¤æä¾›å•†
  providers:
    bailian:
      model: "text-embedding-v2"      # ç™¾ç‚¼åµŒå…¥æ¨¡å‹
      dimensions: 1536                # å‘é‡ç»´åº¦
```

#### 4. å­˜å‚¨é…ç½®
```yaml
storage:
  vector:
    provider: "chroma"                # å‘é‡å­˜å‚¨
    config:
      persist_directory: "./workspace/chroma_db"
  
  graph:
    provider: "neo4j"                 # å›¾å­˜å‚¨
    config:
      uri: "${NEO4J_URI}"
      username: "${NEO4J_USERNAME}"
      password: "${NEO4J_PASSWORD}"
      
  cache:
    provider: "redis"                 # ç¼“å­˜å­˜å‚¨
    config:
      host: "${REDIS_HOST}"
      port: 6379
```

#### 5. æ£€ç´¢é…ç½®
```yaml
retrieval:
  hybrid:
    vector_weight: 0.6               # å‘é‡æ£€ç´¢æƒé‡
    graph_weight: 0.3                # å›¾æ£€ç´¢æƒé‡
    bm25_weight: 0.1                 # BM25æ£€ç´¢æƒé‡
    top_k: 10                        # è¿”å›ç»“æœæ•°
    enable_reranking: true           # å¯ç”¨é‡æ’åº
```

### æç¤ºè¯é…ç½®

#### æ–‡æ¡£åˆ†ææç¤ºè¯ (`prompts/document_analysis.yml`)
```yaml
template: |
  åˆ†ææ–‡æ¡£å†…å®¹ï¼Œè¯†åˆ«ï¼š
  - æ–‡æ¡£ç±»åˆ«ï¼ˆæŠ€æœ¯/å•†ä¸š/å­¦æœ¯ï¼‰
  - ä¸“ä¸šé¢†åŸŸï¼ˆAI/é‡‘è/åŒ»ç–—ï¼‰
  - æ ¸å¿ƒæ¦‚å¿µå’Œå…³é”®è¯
  - æ½œåœ¨çš„å®ä½“å’Œå…³ç³»ç±»å‹
```

#### Schemaç”Ÿæˆæç¤ºè¯ (`prompts/schema_generation.yml`)
```yaml
template: |
  åŸºäºæ–‡æ¡£åˆ†æç»“æœï¼Œæ‰©å±•åŸºç¡€Schemaï¼š
  - ä¿ç•™é€šç”¨å®ä½“ç±»å‹
  - æ·»åŠ é¢†åŸŸç‰¹å®šç±»å‹
  - å®šä¹‰ä¸“ä¸šå…³ç³»ç±»å‹
  - è®¾è®¡ç›¸å…³å±æ€§ç±»å‹
```

#### SPOæŠ½å–æç¤ºè¯ (`prompts/spo_extraction.yml`)
```yaml
template: |
  åŸºäºå®šåˆ¶Schemaè¿›è¡ŒSPOæŠ½å–ï¼š
  - ä¸¥æ ¼æŒ‰ç…§Schemaç±»å‹æŠ½å–
  - ä¸€æ¬¡æ€§è¿”å›å®ä½“ã€å…³ç³»ã€å±æ€§
  - ç¡®ä¿å®ä½“åç§°ä¸€è‡´æ€§
  - é¿å…å†—ä½™å’Œé‡å¤
```

### ç¯å¢ƒå˜é‡è¯¦è§£

| å˜é‡å | æè¿° | å¿…éœ€ | é»˜è®¤å€¼ |
|--------|------|------|--------|
| `OPENAI_API_KEY` | OpenAI API å¯†é’¥ | âœ… | - |
| `OPENAI_BASE_URL` | OpenAI API åŸºç¡€URL | âŒ | https://api.openai.com/v1 |
| `NEO4J_URI` | Neo4j è¿æ¥åœ°å€ | âœ… | bolt://localhost:7687 |
| `NEO4J_USERNAME` | Neo4j ç”¨æˆ·å | âœ… | neo4j |
| `NEO4J_PASSWORD` | Neo4j å¯†ç  | âœ… | - |
| `REDIS_HOST` | Redis ä¸»æœºåœ°å€ | âŒ | localhost |
| `REDIS_PORT` | Redis ç«¯å£ | âŒ | 6379 |
| `REDIS_PASSWORD` | Redis å¯†ç  | âŒ | - |

## ğŸ“– ä½¿ç”¨æŒ‡å—

### **ä¸¤é˜¶æ®µæŠ½å–æ–¹æ³•ä¼˜åŠ¿**

| ç‰¹æ€§ | ä¼ ç»Ÿåˆ†ç¦»æŠ½å– | ä¸¤é˜¶æ®µSPOæŠ½å– |
|------|-------------|---------------|
| **LLMè°ƒç”¨æ¬¡æ•°** | 2æ¬¡/æ–‡æœ¬å— | 1æ¬¡å…¨å±€åˆ†æ + 1æ¬¡/æ–‡æœ¬å— |
| **Schemaé€‚åº”æ€§** | å›ºå®šSchema | æ–‡æ¡£å®šåˆ¶Schema |
| **æŠ½å–ç²¾åº¦** | ä¸­ç­‰ | é«˜ï¼ˆé¢†åŸŸç‰¹å®šï¼‰ |
| **å®ä½“IDä¸€è‡´æ€§** | éœ€è¦ä¿®å¤ | å¤©ç„¶ä¸€è‡´ |
| **æç¤ºè¯ç®¡ç†** | ç¡¬ç¼–ç  | YAMLæ–‡ä»¶ç®¡ç† |
| **é¢†åŸŸé€‚åº”** | æ—  | è‡ªåŠ¨è¯†åˆ«å’Œé€‚åº” |

### ğŸ“„ **æ”¯æŒçš„æ–‡æ¡£æ ¼å¼**

```bash
data/
â”œâ”€â”€ technical_docs.pdf      # PDFæ–‡æ¡£
â”œâ”€â”€ business_report.txt     # æ–‡æœ¬æ–‡æ¡£  
â”œâ”€â”€ research_paper.md       # Markdownæ–‡æ¡£
â”œâ”€â”€ structured_data.json    # JSONæ•°æ®
â””â”€â”€ dataset.csv            # CSVæ•°æ®
```

**æ ¼å¼æ”¯æŒ**ï¼š
- **PDF**: è‡ªåŠ¨æå–æ–‡æœ¬å’Œç»“æ„
- **æ–‡æœ¬**: TXTã€MDæ ¼å¼
- **ç»“æ„åŒ–**: JSONã€CSVæ ¼å¼
- **å¤šè¯­è¨€**: ä¸­æ–‡ã€è‹±æ–‡è‡ªåŠ¨è¯†åˆ«

### ğŸš€ **è¿è¡Œæ¼”ç¤º**

```bash
python main.py
```

**è¯¦ç»†æ‰§è¡Œæµç¨‹**ï¼š

1. **ğŸ” æ–‡æ¡£åˆ†æé˜¶æ®µ**:
   ```
   ğŸ“„ åŠ è½½æ–‡æ¡£ â†’ ğŸ“Š å†…å®¹åˆ†æ â†’ ğŸ·ï¸ é¢†åŸŸè¯†åˆ« â†’ ğŸ“‹ ç”Ÿæˆæ‘˜è¦
   ```

2. **Schemaç”Ÿæˆé˜¶æ®µ**:
   ```
   ğŸ“‹ åŸºç¡€Schema â†’ ğŸ“Š æ–‡æ¡£åˆ†æç»“æœ â†’ ğŸ”§ Schemaç”Ÿæˆå™¨ â†’ å®šåˆ¶Schema
   ```

3. **âœ‚ï¸ æ™ºèƒ½åˆ†å—é˜¶æ®µ**:
   ```
   ğŸ“„ åŸå§‹æ–‡æ¡£ â†’ ğŸ” è¯­ä¹‰åˆ†æ â†’ âœ‚ï¸ æ™ºèƒ½åˆ†å— â†’ ğŸ“ æ–‡æœ¬å—åˆ—è¡¨
   ```

4. **ğŸ” SPOæŠ½å–é˜¶æ®µ**:
   ```
   ğŸ“ æ–‡æœ¬å— â†’ å®šåˆ¶Schema â†’ ğŸ” SPOæŠ½å–å™¨ â†’ ğŸ“Š å®ä½“+å…³ç³»+å±æ€§
   ```

5. **ğŸ•¸ï¸ å›¾è°±æ„å»ºé˜¶æ®µ**:
   ```
   ğŸ“Š SPOæ•°æ® â†’ ğŸ”§ å›¾è°±æ„å»ºå™¨ â†’ ğŸ˜ï¸ ç¤¾åŒºæ£€æµ‹ â†’ ğŸ•¸ï¸ çŸ¥è¯†å›¾è°±
   ```

6. **ğŸ“Š ç´¢å¼•å»ºç«‹é˜¶æ®µ**:
   ```
   ğŸ•¸ï¸ çŸ¥è¯†å›¾è°± â†’ ğŸ“Š å‘é‡åŒ– â†’ ğŸ’¾ å¤šæ¨¡æ€å­˜å‚¨ â†’ ğŸ” æ£€ç´¢ç´¢å¼•
   ```

7. **ğŸ¤– æ™ºèƒ½é—®ç­”é˜¶æ®µ**:
   ```
   â“ ç”¨æˆ·æŸ¥è¯¢ â†’ ğŸ” æ··åˆæ£€ç´¢ â†’ ğŸ“Š ç»“æœé‡æ’ â†’ ğŸ¤– ç­”æ¡ˆç”Ÿæˆ
   ```

### ğŸ’¬ **äº¤äº’å¼é—®ç­”ç¤ºä¾‹**

```
ğŸ¤– AgenticX GraphRAG é—®ç­”ç³»ç»Ÿå·²å¯åŠ¨ï¼

è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ä»€ä¹ˆæ˜¯Transformeræ¶æ„ï¼Ÿ

ğŸ” æ­£åœ¨åˆ†ææŸ¥è¯¢...
ğŸ“Š æ£€ç´¢ç­–ç•¥: æ··åˆæ£€ç´¢ (å‘é‡60% + å›¾30% + BM25 10%)
ğŸ” æ‰¾åˆ°ç›¸å…³ä¿¡æ¯: 15ä¸ªå®ä½“, 8ä¸ªå…³ç³», 12ä¸ªæ–‡æ¡£ç‰‡æ®µ
ğŸ¤– ç”Ÿæˆç­”æ¡ˆ...

ğŸ“ å›ç­”: 
Transformeræ˜¯ä¸€ç§åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„ç¥ç»ç½‘ç»œæ¶æ„ï¼Œç”±Googleåœ¨2017å¹´æå‡ºã€‚
å®ƒçš„æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š
- è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼šèƒ½å¤Ÿæ•æ‰åºåˆ—ä¸­ä»»æ„ä½ç½®é—´çš„ä¾èµ–å…³ç³»
- å¹¶è¡Œè®¡ç®—ï¼šç›¸æ¯”RNNå¯ä»¥å¹¶è¡Œå¤„ç†ï¼Œå¤§å¤§æé«˜è®­ç»ƒæ•ˆç‡
- ä½ç½®ç¼–ç ï¼šé€šè¿‡ä½ç½®ç¼–ç æ¥å¤„ç†åºåˆ—ä¿¡æ¯
...

ğŸ“Š ç›¸å…³å®ä½“: Transformer, æ³¨æ„åŠ›æœºåˆ¶, Google, ç¥ç»ç½‘ç»œ
ğŸ”— ç›¸å…³å…³ç³»: Googleâ†’å¼€å‘â†’Transformer, Transformerâ†’ä½¿ç”¨â†’æ³¨æ„åŠ›æœºåˆ¶
```

### ğŸ›ï¸ **é…ç½®é€‰é¡¹è¯´æ˜**

#### æŠ½å–æ–¹æ³•é€‰æ‹©
```yaml
# ä¸¤é˜¶æ®µSPOæŠ½å–ï¼ˆæ¨èï¼‰
extraction_method: "spo"

# ä¼ ç»Ÿåˆ†ç¦»æŠ½å–ï¼ˆå¤‡ç”¨ï¼‰  
extraction_method: "separate"
```

#### åˆ†å—ç­–ç•¥é€‰æ‹©
```yaml
# è¯­ä¹‰åˆ†å—ï¼ˆæ¨èï¼‰
chunking:
  strategy: "semantic"
  
# å›ºå®šå¤§å°åˆ†å—
chunking:
  strategy: "fixed_size"
  
# Agenticæ™ºèƒ½åˆ†å—
chunking:
  strategy: "agentic"
```

## ğŸ”§ æ•…éšœæ’é™¤

### ğŸš¨ å¸¸è§é—®é¢˜

#### 1. ç™¾ç‚¼APIè°ƒç”¨è¶…æ—¶
```
âŒ ç™¾ç‚¼APIè°ƒç”¨å¤±è´¥: Request timed out
```

**è§£å†³æ–¹æ¡ˆ**:
- âœ… æ£€æŸ¥ç½‘ç»œè¿æ¥
- âœ… å¢åŠ è¶…æ—¶æ—¶é—´ï¼š`timeout: 180`
- âœ… ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹ï¼š`model: "qwen-turbo"`
- âœ… å‡å°‘åˆ†å—å¤§å°ï¼š`chunk_size: 600`

#### 2. Schemaç”Ÿæˆå¤±è´¥
```
âŒ Schemaç”Ÿæˆå¤±è´¥: JSONè§£æé”™è¯¯
```

**è§£å†³æ–¹æ¡ˆ**:
- âœ… æ£€æŸ¥æç¤ºè¯æ–‡ä»¶ï¼š`prompts/schema_generation.yml`
- âœ… éªŒè¯æ–‡æ¡£å†…å®¹é•¿åº¦
- âœ… å›é€€åˆ°åŸºç¡€Schemaï¼š`enable_custom_schema: false`

#### 3. æç¤ºè¯æ–‡ä»¶ç¼ºå¤±
```
âŒ æç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨: prompts/spo_extraction.yml
```

**è§£å†³æ–¹æ¡ˆ**:
- âœ… ç¡®ä¿promptsç›®å½•å­˜åœ¨
- âœ… æ£€æŸ¥æç¤ºè¯æ–‡ä»¶å®Œæ•´æ€§
- âœ… é‡æ–°åˆ›å»ºç¼ºå¤±çš„æç¤ºè¯æ–‡ä»¶

#### 4. å®ä½“IDä¸åŒ¹é…ï¼ˆä¼ ç»Ÿæ–¹æ³•ï¼‰
```
âš ï¸ è·³è¿‡å…³ç³»ï¼šæºå®ä½“ 'PyTorch' ä¸å­˜åœ¨
ğŸ”„ ä¿®å¤æºå®ä½“ID: 'PyTorch' -> 'entity_1'
```

**è§£å†³æ–¹æ¡ˆ**:
- âœ… ä½¿ç”¨SPOæŠ½å–æ–¹æ³•ï¼š`extraction_method: "spo"`
- âœ… æ£€æŸ¥å®ä½“åç§°ä¸€è‡´æ€§
- âœ… å¯ç”¨æ¨¡ç³ŠåŒ¹é…

#### 5. Neo4jè¿æ¥å¤±è´¥
```
âŒ Neo4jè¿æ¥å¤±è´¥: Failed to establish connection
```

**è§£å†³æ–¹æ¡ˆ**:
- âœ… å¯åŠ¨Neo4jæœåŠ¡ï¼š`docker run neo4j`
- âœ… æ£€æŸ¥è¿æ¥é…ç½®ï¼š`NEO4J_URI`, `NEO4J_PASSWORD`
- âœ… éªŒè¯ç½‘ç»œç«¯å£ï¼š7687

### ğŸ” è°ƒè¯•æŠ€å·§

#### 1. å¯ç”¨è¯¦ç»†æ—¥å¿—
```yaml
# åœ¨configs.ymlä¸­è®¾ç½®
system:
  debug: true
  log_level: "DEBUG"
```

#### 2. åˆ†é˜¶æ®µæµ‹è¯•
```bash
# åªæµ‹è¯•æ–‡æ¡£åˆ†æ
python -c "from main import *; demo.analyze_documents_only()"

# åªæµ‹è¯•Schemaç”Ÿæˆ  
python -c "from main import *; demo.test_schema_generation()"

# åªæµ‹è¯•SPOæŠ½å–
python -c "from main import *; demo.test_spo_extraction()"
```

#### 3. æŸ¥çœ‹ç”Ÿæˆçš„Schema
```bash
# æŸ¥çœ‹å®šåˆ¶Schema
cat custom_schema.json

# å¯¹æ¯”åŸºç¡€Schema
cat schema.json
```

#### 4. ç›‘æ§å¤„ç†è¿›åº¦
```
ğŸ” é˜¶æ®µ1: ç”Ÿæˆå®šåˆ¶Schema
ğŸ“Š æ–‡æ¡£åˆ†æå®Œæˆ: æŠ€æœ¯æ–‡æ¡£, äººå·¥æ™ºèƒ½é¢†åŸŸ
å®šåˆ¶Schemaç”Ÿæˆå®Œæˆï¼Œé¢†åŸŸ: æœºå™¨å­¦ä¹ 

ğŸ” é˜¶æ®µ2: SPOæŠ½å–  
ğŸ“ å¤„ç†æ–‡æœ¬å— 1/5 (ID: chunk_0)
ğŸ“Š SPOæŠ½å–ç»“æœ: 8 ä¸ªå®ä½“, 12 ä¸ªå…³ç³»
```

### âš¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®

#### 1. æ¨¡å‹é€‰æ‹©
```yaml
# é€Ÿåº¦ä¼˜å…ˆ
model: "qwen-turbo"

# è´¨é‡ä¼˜å…ˆ  
model: "qwen-max"

# å¹³è¡¡é€‰æ‹©
model: "qwen-plus"
```

#### 2. åˆ†å—ä¼˜åŒ–
```yaml
# å°æ–‡æ¡£
chunk_size: 600

# å¤§æ–‡æ¡£
chunk_size: 1000

# å¤æ‚æ–‡æ¡£
strategy: "agentic"
```

#### 3. å¹¶å‘å¤„ç†
```yaml
# å¯ç”¨å¹¶å‘å¤„ç†
processing:
  enable_parallel: true
  max_workers: 4
```

## ğŸŒŸ ç³»ç»Ÿç‰¹è‰²

### **åˆ›æ–°äº®ç‚¹**

1. **ä¸¤é˜¶æ®µæ™ºèƒ½æŠ½å–**ï¼š
   - ğŸ” æ–‡æ¡£åˆ†æ â†’ å®šåˆ¶Schema â†’ ğŸ“Š ç²¾å‡†æŠ½å–
   - ç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•ï¼ŒæŠ½å–ç²¾åº¦æå‡30%+

2. **æç¤ºè¯å·¥ç¨‹åŒ–ç®¡ç†**ï¼š
   - ğŸ“„ YAMLæ–‡ä»¶ç®¡ç†ï¼Œæ˜“äºç»´æŠ¤å’Œè°ƒä¼˜
   - ğŸ”§ æ¨¡æ¿åŒ–è®¾è®¡ï¼Œæ”¯æŒå˜é‡æ›¿æ¢
   - é¢†åŸŸç‰¹å®šæç¤ºè¯ï¼Œæå‡æŠ½å–è´¨é‡

3. **æ™ºèƒ½Schemaé€‚åº”**ï¼š
   - ğŸ§  è‡ªåŠ¨è¯†åˆ«æ–‡æ¡£é¢†åŸŸå’Œç‰¹ç‚¹
   - ğŸ”§ åŠ¨æ€æ‰©å±•Schemaç±»å‹
   - é¢†åŸŸç‰¹å®šçš„å®ä½“å’Œå…³ç³»ç±»å‹

4. **æ— éœ€å®ä½“IDä¿®å¤**ï¼š
   - âœ… å®ä½“å’Œå…³ç³»åœ¨åŒä¸€æ¬¡æŠ½å–ä¸­ç”Ÿæˆ
   - ğŸ”— å¤©ç„¶çš„IDä¸€è‡´æ€§
   - ğŸš€ å‡å°‘50%çš„å¤„ç†æ—¶é—´

### ğŸ“Š **æ€§èƒ½å¯¹æ¯”**

| æŒ‡æ ‡ | ä¼ ç»ŸGraphRAG | AgenticXä¸¤é˜¶æ®µæ–¹æ³• |
|------|-------------|------------------|
| **æŠ½å–ç²¾åº¦** | 70-80% | 85-95% |
| **å¤„ç†é€Ÿåº¦** | åŸºå‡† | å¿«50% |
| **Schemaé€‚åº”** | å›ºå®š | åŠ¨æ€é€‚åº” |
| **ç»´æŠ¤æˆæœ¬** | é«˜ | ä½ |
| **æ‰©å±•æ€§** | æœ‰é™ | é«˜åº¦å¯æ‰©å±• |

### ğŸ”§ **æŠ€æœ¯ä¼˜åŠ¿**

- **ç²¾å‡†æŠ½å–**: åŸºäºæ–‡æ¡£å†…å®¹å®šåˆ¶çš„Schema
- **âš¡ é«˜æ•ˆå¤„ç†**: å‡å°‘LLMè°ƒç”¨æ¬¡æ•°å’Œå¤„ç†æ—¶é—´
- **ğŸ”§ æ˜“äºç»´æŠ¤**: æç¤ºè¯æ–‡ä»¶åŒ–ç®¡ç†
- **ğŸš€ é«˜åº¦å¯æ‰©å±•**: æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ‰©å±•
- **ğŸ›¡ï¸ ç¨³å®šå¯é **: å®Œå–„çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

## ğŸ” ä¸‰è·¯æ£€ç´¢æ¶æ„ä¼˜åŒ–

### ğŸš¨ **æ¶æ„é—®é¢˜è¯Šæ–­**

åœ¨å®é™…éƒ¨ç½²ä¸­ï¼Œæˆ‘ä»¬å‘ç°äº†å…³é”®çš„æ¶æ„é—®é¢˜ï¼š

**é—®é¢˜ç°è±¡**ï¼š
- âŒ å‘é‡æ•°æ®åº“åªæœ‰140æ¡è®°å½•ï¼ˆé¢„æœŸåº”è¯¥æœ‰800+æ¡ï¼‰
- âŒ æŸ¥è¯¢"FutureX"è¿”å›å†…å®¹é•¿åº¦ä¸º0çš„ç»“æœ
- âŒ AIå›ç­”"ç‰›å¤´ä¸å¯¹é©¬å˜´ï¼Œé”™å¾—ç¦»è°±"

**æ ¹æœ¬åŸå› **ï¼š
1. **åˆ†å—é…ç½®æ··ç”¨**ï¼šGraphRAGã€å‘é‡æ£€ç´¢ã€BM25æ£€ç´¢å…±ç”¨ä¸€ä¸ªåˆ†å—é…ç½®
2. **å‘é‡ç´¢å¼•æ··ä¹±**ï¼šæ··åˆäº†å®ä½“å‘é‡ã€å…³ç³»å‘é‡ã€æ–‡æ¡£åˆ†å—å‘é‡
3. **BM25ç´¢å¼•ç¼ºå¤±**ï¼šBM25æ£€ç´¢å™¨ä»æœªè¢«å–‚å…¥æ•°æ®

### **æ­£ç¡®çš„ä¸‰è·¯æ£€ç´¢æ¶æ„**

#### **1. å›¾æ£€ç´¢ï¼ˆGraph Retrievalï¼‰**
- **æ•°æ®æº**ï¼šNeo4jçŸ¥è¯†å›¾è°±ï¼ˆ128ä¸ªå®ä½“ + 287ä¸ªå…³ç³»ï¼‰
- **æ£€ç´¢å†…å®¹**ï¼šå®ä½“ã€å…³ç³»ã€è·¯å¾„æ¨ç†
- **é€‚ç”¨åœºæ™¯**ï¼šå®ä½“æŸ¥è¯¢ã€å…³ç³»æŸ¥è¯¢ã€æ¨ç†æŸ¥è¯¢
- **å½“å‰çŠ¶æ€**ï¼šâœ… æ­£å¸¸å·¥ä½œ

#### **2. å‘é‡æ£€ç´¢ï¼ˆVector Retrievalï¼‰**  
- **æ•°æ®æº**ï¼šåŸå§‹æ–‡æ¡£çš„è¯­ä¹‰åˆ†å—ï¼ˆåº”è¯¥~300-500æ¡ï¼‰
- **æ£€ç´¢å†…å®¹**ï¼šæ–‡æ¡£åˆ†å—çš„å‘é‡è¡¨ç¤º
- **é€‚ç”¨åœºæ™¯**ï¼šè¯­ä¹‰ç›¸ä¼¼æ€§æŸ¥è¯¢
- **é—®é¢˜**ï¼šâŒ æ··åˆäº†å®ä½“/å…³ç³»å‘é‡ï¼Œå¯¼è‡´å†…å®¹ä¸ºç©º

#### **3. BM25æ£€ç´¢ï¼ˆKeyword Retrievalï¼‰**
- **æ•°æ®æº**ï¼šåŸå§‹æ–‡æ¡£çš„å…³é”®è¯åˆ†å—
- **æ£€ç´¢å†…å®¹**ï¼šåŸºäºTF-IDFçš„å…³é”®è¯åŒ¹é…
- **é€‚ç”¨åœºæ™¯**ï¼šç²¾ç¡®å…³é”®è¯æŸ¥è¯¢
- **é—®é¢˜**ï¼šâŒ ä»æœªè¢«å–‚å…¥æ•°æ®

### ğŸ”§ **åˆ†å—é…ç½®é‡æ„æ–¹æ¡ˆ**

**åŸé…ç½®é—®é¢˜**ï¼š
```yaml
# âŒ æ‰€æœ‰ç”¨é€”å…±ç”¨ä¸€ä¸ªåˆ†å—é…ç½®
chunking:
  strategy: "fixed_size"
  chunk_size: 4000
```

**æ–°çš„ä¸‰å±‚åˆ†å—é…ç½®**ï¼š
```yaml
# âœ… æŒ‰ç”¨é€”åˆ†ç¦»çš„åˆ†å—é…ç½®
chunking:
  # GraphRAGä¸“ç”¨åˆ†å— - ç”¨äºçŸ¥è¯†å›¾è°±æ„å»º
  graphrag:
    strategy: "semantic"    # è¯­ä¹‰åˆ†å—ï¼Œä¿æŒå®Œæ•´æ€§
    chunk_size: 3000       # é€‚ä¸­å¤§å°ï¼Œå¹³è¡¡ä¸Šä¸‹æ–‡
    
  # å‘é‡æ£€ç´¢ä¸“ç”¨åˆ†å— - ç”¨äºè¯­ä¹‰æ£€ç´¢
  vector:
    strategy: "fixed_size"  # å›ºå®šå¤§å°ï¼Œå¹³è¡¡ç²¾åº¦
    chunk_size: 1500       # å……åˆ†åˆ©ç”¨æ¨¡å‹èƒ½åŠ›(~1000 tokens)
    
  # BM25æ£€ç´¢ä¸“ç”¨åˆ†å— - ç”¨äºå…³é”®è¯æ£€ç´¢
  bm25:
    strategy: "fixed_size"  # å°å—ï¼Œæé«˜å¬å›ç‡
    chunk_size: 600        # æé«˜å…³é”®è¯å¯†åº¦
```

### ğŸ“Š **å‘é‡åŒ–æ¨¡å‹é€‚é…**

**å½“å‰ä½¿ç”¨æ¨¡å‹**ï¼š
- **ä¸»æ¨¡å‹**ï¼šç™¾ç‚¼ `text-embedding-v4`
- **è¾“å…¥é™åˆ¶**ï¼š8192 tokens (çº¦6000-8000ä¸­æ–‡å­—ç¬¦)
- **å‘é‡ç»´åº¦**ï¼š1024ç»´

**åˆ†å—å¤§å°éªŒè¯**ï¼š
| åˆ†å—ç”¨é€” | è®¾ç½®å¤§å° | Tokenä¼°ç®— | æ¨¡å‹é™åˆ¶ | çŠ¶æ€ |
|----------|----------|-----------|----------|------|
| **å‘é‡æ£€ç´¢** | 1500å­—ç¬¦ | ~1000 tokens | 8192 tokens | âœ… å®‰å…¨ |
| **BM25æ£€ç´¢** | 600å­—ç¬¦ | ~400 tokens | 8192 tokens | âœ… å®‰å…¨ |
| **GraphRAG** | 3000å­—ç¬¦ | ~2000 tokens | 8192 tokens | âœ… å®‰å…¨ |

### ğŸš€ **ä¿®å¤å®æ–½è®¡åˆ’**

1. **âœ… é…ç½®æ–‡ä»¶é‡æ„**ï¼šå·²å®Œæˆä¸‰å±‚åˆ†å—é…ç½®
2. **ğŸ”„ ä¿®æ”¹GraphRAGæ„å»º**ï¼šä½¿ç”¨`chunking.graph_knowledge`é…ç½®
3. **ğŸ”„ é‡æ„å‘é‡ç´¢å¼•æ„å»º**ï¼š
   - ç§»é™¤å®ä½“å’Œå…³ç³»å‘é‡
   - åªå¯¹åŸå§‹æ–‡æ¡£åˆ†å—è¿›è¡Œå‘é‡åŒ–
   - ä½¿ç”¨`chunking.vector`é…ç½®
4. **ğŸ†• æ–°å¢BM25ç´¢å¼•æ„å»º**ï¼š
   - å®ç°`_build_bm25_index()`æ–¹æ³•
   - ä½¿ç”¨`chunking.bm25`é…ç½®
   - ä¸ºBM25æ£€ç´¢å™¨å–‚å…¥æ•°æ®

### ğŸ“ˆ **é¢„æœŸæ”¹è¿›æ•ˆæœ**

**ä¿®å¤å‰ï¼ˆå½“å‰é—®é¢˜ï¼‰**ï¼š
- âŒ å‘é‡åº“ï¼š140æ¡æ··åˆè®°å½•
- âŒ BM25ï¼šæ— æ•°æ®
- âŒ æŸ¥è¯¢ç»“æœï¼šå†…å®¹ä¸ºç©º

**ä¿®å¤åï¼ˆé¢„æœŸç»“æœï¼‰**ï¼š
- âœ… å‘é‡åº“ï¼š~300-500æ¡æ–‡æ¡£åˆ†å—å‘é‡
- âœ… BM25ï¼š~500-1000æ¡å…³é”®è¯åˆ†å—
- âœ… æŸ¥è¯¢ç»“æœï¼šä¸°å¯Œçš„æ–‡æ¡£å†…å®¹

## ğŸ—ï¸ ç´¢å¼•æ„å»ºä¸æ£€ç´¢æ¶æ„è¯¦è§£

### ğŸ“Š **ç´¢å¼•æ„å»ºæµç¨‹**

#### **1. æ–‡æ¡£å‘é‡ç´¢å¼•æ„å»º**
```python
async def _build_document_vector_index(self) -> None:
    """æ„å»ºæ–‡æ¡£åˆ†å—å‘é‡ç´¢å¼• - ä¸“ç”¨äºå‘é‡æ£€ç´¢è·¯å¾„"""
    
    # ä½¿ç”¨å‘é‡æ£€ç´¢ä¸“ç”¨åˆ†å—é…ç½®
    vector_chunking_config = self.config['knowledge']['chunking']['vector']
    # strategy: "fixed_size", chunk_size: 1500, chunk_overlap: 250
    
    vector_chunker = get_chunker(vector_chunking_config['strategy'], vector_chunking_config)
    
    document_records = []
    for doc_idx, document in enumerate(self.documents):
        # ä½¿ç”¨å‘é‡æ£€ç´¢ä¸“ç”¨åˆ†å—
        chunks = await vector_chunker.chunk_document(document)
        
        for chunk_idx, chunk in enumerate(chunks):
            # ç”ŸæˆåµŒå…¥å‘é‡
            embedding = await self.embedding_router.aembed_text(chunk.content)
            
            # åˆ›å»ºå‘é‡è®°å½•
            record = VectorRecord(
                id=f"doc_{doc_idx}_chunk_{chunk_idx}",
                vector=embedding,
                metadata={
                    'type': 'document_chunk',
                    'document_id': document.id,
                    'chunk_index': chunk_idx,
                    'chunking_strategy': 'vector_optimized'
                },
                content=chunk.content  # å®Œæ•´æ–‡æ¡£å†…å®¹
            )
            document_records.append(record)
    
    # æ‰¹é‡å­˜å‚¨åˆ°Milvus
    vector_storage.add(document_records)
```

#### **2. å›¾å‘é‡ç´¢å¼•æ„å»º**
```python
async def _build_graph_vector_indices(self) -> None:
    """æ„å»ºå›¾å‘é‡ç´¢å¼• - ä¸“ç”¨äºå›¾æ£€ç´¢å¢å¼º"""
    
    # ä½¿ç”¨GraphRetrieverçš„å››ç§å›¾å‘é‡ç´¢å¼•
    results = await self.graph_retriever.build_vector_indices()
    
    # å››ç§ç´¢å¼•ç±»å‹ï¼š
    # - èŠ‚ç‚¹ç´¢å¼• (node.index): å®ä½“è¯­ä¹‰å‘é‡
    # - å…³ç³»ç´¢å¼• (relation.index): å…³ç³»ç±»å‹å‘é‡  
    # - ä¸‰å…ƒç»„ç´¢å¼• (triple.index): å®Œæ•´äº‹å®å‘é‡
    # - ç¤¾åŒºç´¢å¼• (comm.index): ç¤¾åŒºèšç±»å‘é‡
```

**å›¾å‘é‡ç´¢å¼•è¯¦ç»†å®ç°**ï¼š
```python
# èŠ‚ç‚¹å‘é‡ç´¢å¼•
async def _build_node_index(self, nodes: List[Dict[str, Any]]) -> bool:
    node_records = []
    for node in nodes:
        # ç”ŸæˆèŠ‚ç‚¹æè¿°æ–‡æœ¬
        node_text = f"{node['name']}: {node['description']}"
        embedding = await self.embedding_provider.aembed_text(node_text)
        
        record = VectorRecord(
            id=f"graph_node_{node['id']}",
            vector=embedding,
            metadata={
                'type': 'graph_node',
                'node_id': node['id'],
                'labels': node['labels']
            },
            content=node_text
        )
        node_records.append(record)
    
    # å­˜å‚¨åˆ°ä¸“ç”¨é›†åˆ
    await self.vector_storage.insert(node_records, collection_name="graph_nodes")

# ä¸‰å…ƒç»„å‘é‡ç´¢å¼•  
async def _build_triple_index(self, triples: List[tuple]) -> bool:
    triple_records = []
    for source, relation, target in triples:
        # ç”Ÿæˆä¸‰å…ƒç»„æè¿°æ–‡æœ¬
        triple_text = f"{source} {relation} {target}"
        embedding = await self.embedding_provider.aembed_text(triple_text)
        
        record = VectorRecord(
            id=f"graph_triple_{hash((source, relation, target))}",
            vector=embedding,
            metadata={
                'type': 'graph_triple',
                'source': source,
                'relation': relation,
                'target': target
            },
            content=triple_text
        )
        triple_records.append(record)
    
    # å­˜å‚¨åˆ°ä¸“ç”¨é›†åˆ
    await self.vector_storage.insert(triple_records, collection_name="graph_triples")
```

#### **3. BM25ç´¢å¼•æ„å»º**
```python
async def _build_bm25_index(self) -> None:
    """æ„å»ºBM25å€’æ’ç´¢å¼• - åŸºäºä¸“ç”¨åˆ†å—é…ç½®"""
    
    # ä½¿ç”¨BM25ä¸“ç”¨åˆ†å—é…ç½®
    bm25_chunking_config = self.config['knowledge']['chunking']['bm25']
    # strategy: "fixed_size", chunk_size: 600, chunk_overlap: 100
    
    bm25_chunker = get_chunker(bm25_chunking_config['strategy'], bm25_chunking_config)
    
    # å‡†å¤‡BM25æ–‡æ¡£
    bm25_documents = []
    for doc_idx, document in enumerate(self.documents):
        # ä½¿ç”¨BM25ä¸“ç”¨åˆ†å—
        chunks = await bm25_chunker.chunk_document(document)
        
        for chunk_idx, chunk in enumerate(chunks):
            bm25_doc = {
                'id': f"bm25_doc_{doc_idx}_chunk_{chunk_idx}",
                'content': chunk.content,
                'metadata': {
                    'type': 'bm25_chunk',
                    'document_id': document.id,
                    'chunk_index': chunk_idx,
                    'chunking_strategy': 'keyword_optimized'
                }
            }
            bm25_documents.append(bm25_doc)
    
    # æ‰¹é‡æ·»åŠ åˆ°BM25æ£€ç´¢å™¨
    await bm25_retriever.add_documents(bm25_documents)
```

### ğŸ” **ä¸‰è·¯æ£€ç´¢æ–¹æ³•è¯¦è§£**

#### **1. HybridRetrieveræ¶æ„**
```python
class HybridRetriever(BaseRetriever):
    """ä¸‰è·¯æ··åˆæ£€ç´¢å™¨"""
    
    def __init__(
        self,
        vector_retriever: VectorRetriever,      # å‘é‡æ£€ç´¢å™¨
        bm25_retriever: BM25Retriever,          # BM25æ£€ç´¢å™¨  
        graph_retriever: GraphRetriever,        # å›¾æ£€ç´¢å™¨
        config: HybridConfig                    # æ··åˆé…ç½®
    ):
        self.vector_retriever = vector_retriever
        self.bm25_retriever = bm25_retriever
        self.graph_retriever = graph_retriever
        self.config = config  # graph_weight: 0.4, vector_weight: 0.4, bm25_weight: 0.2
```

#### **2. ä¸‰è·¯æ£€ç´¢æ‰§è¡Œæµç¨‹**
```python
async def retrieve(self, query: str, **kwargs) -> List[RetrievalResult]:
    """ä¸‰è·¯æ··åˆæ£€ç´¢"""
    
    # å¹¶è¡Œæ‰§è¡Œä¸‰è·¯æ£€ç´¢
    vector_results = await self.vector_retriever.retrieve(query, **kwargs)
    bm25_results = await self.bm25_retriever.retrieve(query, **kwargs)
    graph_results = await self.graph_retriever.retrieve(query, **kwargs)
    
    # æ™ºèƒ½ç»“æœèåˆ
    combined_results = await self._combine_three_way_results(
        graph_results, vector_results, bm25_results
    )
    
    return combined_results
```

#### **3. å›¾æ£€ç´¢ç­–ç•¥è¯¦è§£**
```python
async def retrieve(self, query: str, strategy: str = "hybrid") -> List[RetrievalResult]:
    """å›¾æ£€ç´¢æ”¯æŒå¤šç§ç­–ç•¥"""
    
    if strategy == "traditional":
        # ä¼ ç»Ÿå›¾éå†
        return await self._traditional_graph_search(query)
        
    elif strategy == "vector":
        # çº¯å›¾å‘é‡æ£€ç´¢
        return await self._vector_graph_search(query)
        
    elif strategy == "hybrid":
        # æ··åˆå›¾æ£€ç´¢ï¼ˆé»˜è®¤ï¼‰
        traditional_results = await self._traditional_graph_search(query)
        vector_results = await self._vector_graph_search(query)
        return await self._hybrid_rank_results(traditional_results + vector_results, query)
        
    elif strategy == "auto":
        # æ™ºèƒ½ç­–ç•¥é€‰æ‹©
        return await self._auto_select_strategy(query)
```

**å›¾å‘é‡æ£€ç´¢å®ç°**ï¼š
```python
async def _vector_graph_search(self, query: str, top_k: int = 10) -> List[Dict[str, Any]]:
    """å›¾å‘é‡æ£€ç´¢ - å››ç§ç´¢å¼•å¹¶è¡Œæœç´¢"""
    
    # ç”ŸæˆæŸ¥è¯¢å‘é‡
    query_embedding = await self.embedding_provider.aembed_text(query)
    
    # å¹¶è¡Œæœç´¢å››ç§å›¾å‘é‡ç´¢å¼•
    node_results = await self._search_node_vectors(query_embedding, top_k)
    relation_results = await self._search_relation_vectors(query_embedding, top_k)
    triple_results = await self._search_triple_vectors(query_embedding, top_k)
    community_results = await self._search_community_vectors(query_embedding, top_k)
    
    # åˆå¹¶å’Œé‡æ’åºç»“æœ
    all_results = node_results + relation_results + triple_results + community_results
    return await self._rank_vector_results(all_results, query)

async def _search_node_vectors(self, query_embedding: List[float], top_k: int):
    """æœç´¢èŠ‚ç‚¹å‘é‡ç´¢å¼•"""
    results = await self.vector_storage.search(
        vectors=[query_embedding],
        collection_name="graph_nodes",
        limit=top_k
    )
    return self._convert_vector_results_to_graph_results(results, "node")
```

#### **4. ç»“æœèåˆç®—æ³•**
```python
async def _combine_three_way_results(
    self,
    graph_results: List[RetrievalResult],
    vector_results: List[RetrievalResult], 
    bm25_results: List[RetrievalResult]
) -> List[RetrievalResult]:
    """ä¸‰è·¯ç»“æœæ™ºèƒ½èåˆ"""
    
    # åˆ›å»ºå†…å®¹åˆ°ç»“æœçš„æ˜ å°„ï¼ˆå»é‡ï¼‰
    content_to_results = {}
    
    # å¤„ç†å›¾æ£€ç´¢ç»“æœ
    for result in graph_results:
        content_key = result.content.strip().lower()
        if content_key not in content_to_results:
            content_to_results[content_key] = {
                'graph_score': result.score,
                'vector_score': 0.0,
                'bm25_score': 0.0,
                'result': result
            }
    
    # å¤„ç†å‘é‡æ£€ç´¢ç»“æœ
    for result in vector_results:
        content_key = result.content.strip().lower()
        if content_key not in content_to_results:
            content_to_results[content_key] = {
                'graph_score': 0.0,
                'vector_score': result.score,
                'bm25_score': 0.0,
                'result': result
            }
        else:
            content_to_results[content_key]['vector_score'] = max(
                content_to_results[content_key]['vector_score'], result.score
            )
    
    # å¤„ç†BM25æ£€ç´¢ç»“æœ
    for result in bm25_results:
        content_key = result.content.strip().lower()
        if content_key not in content_to_results:
            content_to_results[content_key] = {
                'graph_score': 0.0,
                'vector_score': 0.0,
                'bm25_score': result.score,
                'result': result
            }
        else:
            content_to_results[content_key]['bm25_score'] = max(
                content_to_results[content_key]['bm25_score'], result.score
            )
    
    # è®¡ç®—ç»¼åˆè¯„åˆ†
    combined_results = []
    for content_key, scores in content_to_results.items():
        combined_score = self._calculate_three_way_score(
            scores['graph_score'],
            scores['vector_score'],
            scores['bm25_score']
        )
        
        result = scores['result']
        result.score = combined_score
        
        # æ·»åŠ è¯„åˆ†æ¥æºå…ƒæ•°æ®
        result.metadata.update({
            'graph_score': scores['graph_score'],
            'vector_score': scores['vector_score'],
            'bm25_score': scores['bm25_score'],
            'combined_score': combined_score,
            'retrieval_method': 'three_way_hybrid'
        })
        
        combined_results.append(result)
    
    # æŒ‰ç»¼åˆè¯„åˆ†æ’åº
    combined_results.sort(key=lambda x: x.score, reverse=True)
    return combined_results

def _calculate_three_way_score(self, graph_score: float, vector_score: float, bm25_score: float) -> float:
    """ä¸‰è·¯è¯„åˆ†ç®—æ³•"""
    # å½’ä¸€åŒ–è¯„åˆ†åˆ°0-1èŒƒå›´
    normalized_graph = min(1.0, max(0.0, graph_score))
    normalized_vector = min(1.0, max(0.0, vector_score))
    normalized_bm25 = min(1.0, max(0.0, bm25_score))
    
    # åŠ æƒç»„åˆ
    combined_score = (
        self.config.graph_weight * normalized_graph +      # 0.4
        self.config.vector_weight * normalized_vector +    # 0.4
        self.config.bm25_weight * normalized_bm25          # 0.2
    )
    
    return combined_score
```

### ğŸ“Š **æ•°æ®æµå‘å›¾**

```mermaid
graph TD
    subgraph "åŸå§‹æ–‡æ¡£"
        A[PDF/TXT/MDæ–‡æ¡£]
    end
    
    subgraph "ä¸‰ç§åˆ†å—ç­–ç•¥"
        B[GraphRAGåˆ†å—<br/>3000å­—ç¬¦<br/>è¯­ä¹‰åˆ†å—]
        C[å‘é‡åˆ†å—<br/>1500å­—ç¬¦<br/>å›ºå®šåˆ†å—]
        D[BM25åˆ†å—<br/>600å­—ç¬¦<br/>å›ºå®šåˆ†å—]
    end
    
    subgraph "ç´¢å¼•æ„å»º"
        E[çŸ¥è¯†å›¾è°±æ„å»º<br/>Neo4j]
        F[æ–‡æ¡£å‘é‡ç´¢å¼•<br/>Milvusæ–‡æ¡£é›†åˆ]
        G[BM25å€’æ’ç´¢å¼•<br/>å…³é”®è¯ç´¢å¼•]
        H[å›¾å‘é‡ç´¢å¼•<br/>Milvuså›¾é›†åˆ]
    end
    
    subgraph "æ£€ç´¢æ‰§è¡Œ"
        I[å›¾æ£€ç´¢<br/>ä¼ ç»Ÿ+å‘é‡]
        J[å‘é‡æ£€ç´¢<br/>è¯­ä¹‰ç›¸ä¼¼]
        K[BM25æ£€ç´¢<br/>å…³é”®è¯åŒ¹é…]
    end
    
    subgraph "ç»“æœèåˆ"
        L[ä¸‰è·¯ç»“æœèåˆ<br/>æƒé‡ï¼š0.4+0.4+0.2]
        M[æœ€ç»ˆæ£€ç´¢ç»“æœ]
    end
    
    A --> B
    A --> C  
    A --> D
    
    B --> E
    C --> F
    D --> G
    E --> H
    
    E --> I
    F --> J
    G --> K
    H --> I
    
    I --> L
    J --> L
    K --> L
    L --> M
```

### **æ£€ç´¢ç­–ç•¥å¯¹æ¯”**

| æ£€ç´¢è·¯å¾„ | æ•°æ®æº | åˆ†å—ç­–ç•¥ | é€‚ç”¨åœºæ™¯ | ä¼˜åŠ¿ | å±€é™æ€§ |
|----------|--------|----------|----------|------|--------|
| **å›¾æ£€ç´¢** | Neo4jçŸ¥è¯†å›¾è°± | 3000å­—ç¬¦è¯­ä¹‰åˆ†å— | å®ä½“æŸ¥è¯¢ã€å…³ç³»æ¨ç† | ç»“æ„åŒ–æ¨ç†ã€ç²¾ç¡®å®ä½“åŒ¹é… | è¦†ç›–èŒƒå›´æœ‰é™ |
| **å‘é‡æ£€ç´¢** | Milvusæ–‡æ¡£å‘é‡ | 1500å­—ç¬¦å›ºå®šåˆ†å— | è¯­ä¹‰ç›¸ä¼¼æŸ¥è¯¢ | è¯­ä¹‰ç†è§£ã€æ¨¡ç³ŠåŒ¹é… | è®¡ç®—å¼€é”€å¤§ |
| **BM25æ£€ç´¢** | å€’æ’ç´¢å¼• | 600å­—ç¬¦å›ºå®šåˆ†å— | å…³é”®è¯ç²¾ç¡®åŒ¹é… | å¿«é€Ÿã€ç²¾ç¡® | æ— è¯­ä¹‰ç†è§£ |
| **æ··åˆæ£€ç´¢** | ä¸‰è·¯èåˆ | å¤šç­–ç•¥ç»„åˆ | ç»¼åˆæŸ¥è¯¢ | äº’è¡¥ä¼˜åŠ¿ã€å…¨é¢è¦†ç›– | å¤æ‚åº¦é«˜ |

### ğŸ”§ **æ€§èƒ½ä¼˜åŒ–ç­–ç•¥**

#### **1. ç´¢å¼•æ„å»ºä¼˜åŒ–**
```python
# æ‰¹é‡å¤„ç†ä¼˜åŒ–
batch_size = 100
for i in range(0, len(records), batch_size):
    batch = records[i:i + batch_size]
    await vector_storage.add(batch)

# å¹¶è¡Œæ„å»ºä¼˜åŒ–
import asyncio
tasks = [
    self._build_document_vector_index(),
    self._build_graph_vector_indices(), 
    self._build_bm25_index()
]
await asyncio.gather(*tasks)
```

#### **2. æ£€ç´¢æ€§èƒ½ä¼˜åŒ–**
```python
# ç¼“å­˜æŸ¥è¯¢å‘é‡
@lru_cache(maxsize=1000)
async def get_query_embedding(self, query: str):
    return await self.embedding_provider.aembed_text(query)

# å¹¶è¡Œæ£€ç´¢
async def parallel_retrieve(self, query: str):
    tasks = [
        self.vector_retriever.retrieve(query),
        self.bm25_retriever.retrieve(query),
        self.graph_retriever.retrieve(query)
    ]
    return await asyncio.gather(*tasks)
```

#### **3. å†…å­˜ä¼˜åŒ–**
```python
# æµå¼å¤„ç†å¤§æ–‡æ¡£
async def stream_process_documents(self, documents):
    for document in documents:
        chunks = await self.chunker.chunk_document(document)
        for chunk in chunks:
            yield await self.process_chunk(chunk)
            
# å®šæœŸæ¸…ç†ç¼“å­˜
import gc
gc.collect()
```

## ğŸ“š ç›¸å…³èµ„æº

- **AgenticXæ¡†æ¶**: [GitHubä»“åº“](https://github.com/AgenticX/AgenticX)
- **GraphRAGè®ºæ–‡**: [Microsoft GraphRAG](https://arxiv.org/abs/2404.16130)
- **ç™¾ç‚¼APIæ–‡æ¡£**: [é˜¿é‡Œäº‘ç™¾ç‚¼](https://help.aliyun.com/zh/dashscope/)
- **Neo4jå›¾æ•°æ®åº“**: [å®˜æ–¹æ–‡æ¡£](https://neo4j.com/docs/)

## ğŸ‰ æ€»ç»“

AgenticX GraphRAGæ¼”ç¤ºç³»ç»Ÿå±•ç¤ºäº†ï¼š

âœ… **æ™ºèƒ½åŒ–**: è‡ªåŠ¨åˆ†ææ–‡æ¡£ï¼Œç”Ÿæˆå®šåˆ¶Schema  
âœ… **é«˜æ•ˆåŒ–**: ä¸¤é˜¶æ®µæŠ½å–ï¼Œå‡å°‘APIè°ƒç”¨  
âœ… **å·¥ç¨‹åŒ–**: æç¤ºè¯æ–‡ä»¶ç®¡ç†ï¼Œæ˜“äºç»´æŠ¤  
âœ… **å¯æ‰©å±•**: æ¨¡å—åŒ–è®¾è®¡ï¼Œæ”¯æŒå¤šç§é…ç½®  
âœ… **å®ç”¨åŒ–**: å®Œæ•´çš„ç«¯åˆ°ç«¯è§£å†³æ–¹æ¡ˆ  
âœ… **æ¶æ„ä¼˜åŒ–**: ä¸‰è·¯æ£€ç´¢åˆ†å—é…ç½®åˆ†ç¦»ï¼Œç²¾å‡†å®šä½é—®é¢˜æ ¹æº  

### ğŸ” **å…³é”®æŠ€æœ¯çªç ´**

1. **ä¸¤é˜¶æ®µSPOæŠ½å–**ï¼šç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•ï¼ŒæŠ½å–ç²¾åº¦æå‡30%+
2. **æ™ºèƒ½Schemaé€‚åº”**ï¼šåŠ¨æ€é€‚åº”ä¸åŒé¢†åŸŸæ–‡æ¡£ç‰¹ç‚¹
3. **ä¸‰è·¯æ£€ç´¢æ¶æ„**ï¼šå›¾æ£€ç´¢+å‘é‡æ£€ç´¢+BM25æ£€ç´¢çš„æ­£ç¡®å®ç°
4. **åˆ†å—é…ç½®åˆ†ç¦»**ï¼šé’ˆå¯¹ä¸åŒç”¨é€”çš„ä¸“ç”¨åˆ†å—ç­–ç•¥
5. **å‘é‡åŒ–æ¨¡å‹é€‚é…**ï¼šå……åˆ†åˆ©ç”¨ç™¾ç‚¼text-embedding-v4çš„8192 tokensèƒ½åŠ›
6. **å››ç§å›¾å‘é‡ç´¢å¼•**ï¼šèŠ‚ç‚¹ã€å…³ç³»ã€ä¸‰å…ƒç»„ã€ç¤¾åŒºçš„å…¨æ–¹ä½å‘é‡åŒ–
7. **æ™ºèƒ½ç»“æœèåˆç®—æ³•**ï¼šä¸‰è·¯æ£€ç´¢ç»“æœçš„æƒé‡åŒ–èåˆä¸å»é‡
8. **æ€§èƒ½ä¼˜åŒ–ç­–ç•¥**ï¼šæ‰¹é‡å¤„ç†ã€å¹¶è¡Œæ„å»ºã€ç¼“å­˜ä¼˜åŒ–

### âš ï¸ **é‡è¦å‘ç°**

é€šè¿‡å®é™…éƒ¨ç½²å‘ç°çš„å…³é”®é—®é¢˜ï¼š
- **é…ç½®æ··ç”¨å¯¼è‡´æ£€ç´¢è´¨é‡ä¸‹é™**ï¼šå•ä¸€åˆ†å—é…ç½®æ— æ³•æ»¡è¶³å¤šç§æ£€ç´¢éœ€æ±‚
- **å‘é‡ç´¢å¼•æ··ä¹±å½±å“è¯­ä¹‰æ£€ç´¢**ï¼šå®ä½“/å…³ç³»å‘é‡ä¸æ–‡æ¡£å‘é‡æ··åˆå­˜å‚¨
- **BM25ç´¢å¼•ç¼ºå¤±é™ä½å¬å›ç‡**ï¼šå…³é”®è¯æ£€ç´¢è·¯å¾„å®Œå…¨å¤±æ•ˆ

è¿™äº›å‘ç°ä¸ºGraphRAGç³»ç»Ÿçš„æ­£ç¡®å®ç°æä¾›äº†å®è´µç»éªŒã€‚

## ğŸ¯ å¤šè·³æ•°æ®é›†æ„å»ºå™¨

æœ¬ç³»ç»Ÿè¿˜æä¾›äº†ä¸€ä¸ªå¼ºå¤§çš„**å¤šè·³å¤æ‚æ¨ç†é—®ç­”å¯¹æ•°æ®é›†æ„å»ºå™¨**ï¼Œå¯ä»¥åŸºäºä»»æ„é¢†åŸŸçš„æ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„å¤šè·³æ¨ç†æµ‹è¯•æ•°æ®é›†ã€‚

### ğŸ“‹ åŠŸèƒ½ç‰¹æ€§

- **ğŸŒ é¢†åŸŸé€šç”¨**: æ”¯æŒæŠ€æœ¯ã€é‡‘èã€åŒ»å­¦ç­‰ä»»æ„é¢†åŸŸ
- **ğŸ“„ å¤šæ ¼å¼æ”¯æŒ**: PDFã€TXTã€JSONã€CSVç­‰æ–‡æ¡£æ ¼å¼
- **ğŸ¤– å¤šæ¨¡å‹æ”¯æŒ**: ç™¾ç‚¼ã€OpenAIã€Anthropicç­‰LLMæä¾›å•†
- **ğŸ”§ çµæ´»é…ç½®**: é€šè¿‡æç¤ºå˜é‡ç³»ç»Ÿå®ç°é¢†åŸŸå®šåˆ¶
- **ğŸ“Š è´¨é‡ä¿è¯**: è‡ªåŠ¨éªŒè¯ç”Ÿæˆæ•°æ®çš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§

### ğŸš€ å¿«é€Ÿä½¿ç”¨

#### åŸºç¡€ç”¨æ³•
```bash
# åŸºç¡€ä½¿ç”¨ - å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡æ¡£
python multihop_dataset_builder.py \
  --data_path ./documents \
  --output ./multihop_dataset.json \
  --llm_provider bailian \
  --llm_model qwen3-max

# æŒ‡å®šé¢†åŸŸå’Œå‚æ•°
python multihop_dataset_builder.py \
  --data_path ./tech_papers \
  --output ./tech_dataset.json \
  --domain technology \
  --sample_nums 20 \
  --min_docs 2
```

#### æ”¯æŒçš„é¢†åŸŸç±»å‹
- `technology`: æŠ€æœ¯é¢†åŸŸï¼ˆç®—æ³•ã€æ¡†æ¶ã€ç³»ç»Ÿæ¶æ„ï¼‰
- `finance`: é‡‘èé¢†åŸŸï¼ˆäº¤æ˜“ç­–ç•¥ã€é£é™©ç®¡ç†ã€å¸‚åœºåˆ†æï¼‰
- `medical`: åŒ»å­¦é¢†åŸŸï¼ˆè¯Šæ–­æ–¹æ³•ã€æ²»ç–—æ–¹æ¡ˆã€è¯ç‰©æœºåˆ¶ï¼‰
- `general`: é€šç”¨é¢†åŸŸï¼ˆè‡ªåŠ¨è¯†åˆ«ä¸»é¢˜ï¼‰

#### å‘½ä»¤è¡Œå‚æ•°è¯´æ˜
```bash
# å¿…éœ€å‚æ•°
--data_path     # æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆæ–‡ä»¶æˆ–ç›®å½•ï¼‰
--output        # è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„

# LLMé…ç½®
--llm_provider  # LLMæä¾›å•† (bailian, openai, anthropicç­‰)
--llm_model     # LLMæ¨¡å‹åç§°

# å¯é€‰å‚æ•°
--domain        # é¢†åŸŸç±»å‹ (technology, finance, medical, general)
--sample_nums   # ç”Ÿæˆé—®é¢˜æ•°é‡
--min_docs      # æ¯ä¸ªé—®é¢˜æœ€å°‘æ¶‰åŠæ–‡æ¡£æ•°
--file_types    # æ”¯æŒçš„æ–‡ä»¶ç±»å‹ (pdf txt json csvç­‰)
```

### ğŸ¨ è‡ªå®šä¹‰é¢†åŸŸé…ç½®

ä½ å¯ä»¥é€šè¿‡ç¼–ç¨‹æ–¹å¼åˆ›å»ºå®Œå…¨è‡ªå®šä¹‰çš„é¢†åŸŸé…ç½®ï¼š

```python
from multihop_dataset_builder import MultihopDatasetBuilder

# åˆ›å»ºè‡ªå®šä¹‰æ•™è‚²é¢†åŸŸé…ç½®
custom_domain_config = {
    'domain_guidance': '''
è¯·æ ¹æ®æ–‡æ¡£å†…å®¹è‡ªåŠ¨è¯†åˆ«æ•™è‚²ç›¸å…³ä¸»é¢˜ï¼ˆå¦‚æ•™å­¦æ–¹æ³•ã€å­¦ä¹ ç†è®ºã€è¯„ä¼°ä½“ç³»ç­‰ï¼‰ï¼Œ
ç„¶åé€‰æ‹©ä¸¤ä¸ªä¸åŒæ•™è‚²ä¸»é¢˜è¿›è¡Œç»„åˆï¼Œç”Ÿæˆè·¨æ–‡æ¡£å¤šè·³é—®é¢˜ã€‚
    '''.strip(),
    'domain_specific_terms': 'æ•™å­¦æ–¹æ³•ã€å­¦ä¹ ç†è®ºã€è¯„ä¼°æŒ‡æ ‡ã€æ•™è‚²å·¥å…·',
    'comparison_aspect': 'æ•™å­¦æ•ˆæœ/å­¦ä¹ ä½“éªŒ/è¯„ä¼°å‡†ç¡®æ€§/é€‚ç”¨èŒƒå›´',
    'reasoning_pattern': 'åŸºäº{context}æ•™å­¦å®è·µï¼Œåˆ†æ{target}å­¦ä¹ æ–¹æ³•çš„{aspect}å¦‚ä½•å½±å“{outcome}æ•™å­¦æ•ˆæœï¼Ÿ'
}

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
builder = MultihopDatasetBuilder("configs.yml")
await builder.build_dataset(
    data_path="./education_docs",
    output_path="./education_dataset.json",
    domain_config=custom_domain_config
)
```

### ğŸ“Š è¾“å‡ºæ ¼å¼

ç”Ÿæˆçš„æ•°æ®é›†é‡‡ç”¨æ ‡å‡†JSONæ ¼å¼ï¼Œä¸ç°æœ‰çš„ `multihop_test_dataset.json` å®Œå…¨å…¼å®¹ï¼š

```json
[
  {
    "query": "è·¨æ–‡æ¡£å¤šè·³æ¨ç†é—®é¢˜",
    "from_docs": ["doc1.pdf", "doc2.pdf"],
    "expected_output": "åŸºäºæ–‡æ¡£å†…å®¹çš„æ ‡å‡†ç­”æ¡ˆ",
    "criteria_clarify": "0-5åˆ†è¯„åˆ†è¯´æ˜"
  }
]
```

### ğŸ”§ é…ç½®æ–‡ä»¶è¯´æ˜

å¤šè·³æ•°æ®é›†ç”Ÿæˆä½¿ç”¨ `prompts/multihop_dataset_generation.yml` é…ç½®æ–‡ä»¶ï¼š

- **é¢†åŸŸé€šç”¨è®¾è®¡**: ç§»é™¤äº†ç¡¬ç¼–ç çš„é¢†åŸŸç‰¹å®šå†…å®¹
- **å˜é‡åŒ–é…ç½®**: é€šè¿‡ `variables` éƒ¨åˆ†æ”¯æŒçµæ´»å®šåˆ¶
- **æ— Few-shot**: é¿å…é¢†åŸŸåè§ï¼Œæå‡é€šç”¨æ€§
- **è´¨é‡æ§åˆ¶**: å†…ç½®æ•°æ®è´¨é‡éªŒè¯æœºåˆ¶

### ğŸ“š ä½¿ç”¨ç¤ºä¾‹

æŸ¥çœ‹ `example_usage.py` æ–‡ä»¶è·å–å®Œæ•´çš„ä½¿ç”¨ç¤ºä¾‹ï¼ŒåŒ…æ‹¬ï¼š
- ä¸åŒé¢†åŸŸçš„é…ç½®ç¤ºä¾‹
- è‡ªå®šä¹‰å˜é‡çš„ä½¿ç”¨æ–¹æ³•
- æ‰¹é‡å¤„ç†å’Œå•æ–‡ä»¶å¤„ç†
- é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•

---

ğŸŒŸ **æ„Ÿè°¢ä½¿ç”¨ AgenticX GraphRAG æ¼”ç¤ºç³»ç»Ÿï¼**

è¿™ä¸ªæ¼”ç¤ºä¸ä»…å±•ç¤ºäº†å¦‚ä½•å°†ä¼ ç»Ÿçš„GraphRAGæ–¹æ³•å‡çº§ä¸ºæ›´æ™ºèƒ½ã€æ›´é«˜æ•ˆçš„ä¸¤é˜¶æ®µæŠ½å–ç³»ç»Ÿï¼Œæ›´é‡è¦çš„æ˜¯é€šè¿‡å®é™…éƒ¨ç½²å‘ç°å¹¶è§£å†³äº†ä¸‰è·¯æ£€ç´¢æ¶æ„çš„å…³é”®é—®é¢˜ã€‚æ–°å¢çš„å¤šè·³æ•°æ®é›†æ„å»ºå™¨ä¸ºGraphRAGç³»ç»Ÿçš„è¯„ä¼°å’Œæµ‹è¯•æä¾›äº†å¼ºå¤§çš„å·¥å…·æ”¯æŒã€‚å¸Œæœ›è¿™äº›ç»éªŒèƒ½ä¸ºæ‚¨çš„çŸ¥è¯†å›¾è°±é¡¹ç›®æä¾›å‚è€ƒå’Œå¯å‘ï¼