"""AgenticX Knowledge Graph Construction Demo

This demo showcases the powerful knowledge graph construction capabilities of AgenticX,
including entity extraction, relationship extraction, graph building, and GraphRAG features.

Features demonstrated:
- Basic knowledge graph construction
- Entity and relationship extraction
- Graph quality validation
- Advanced GraphRAG construction with communities
- Incremental graph updates
- Graph optimization and analysis

Usage:
    python examples/knowledge_graph_demo.py
"""

import asyncio
import json
import sys
import yaml
from pathlib import Path
from typing import List
from loguru import logger

# é…ç½®loguruæ—¥å¿—
logger.remove()  # ç§»é™¤é»˜è®¤çš„æ—¥å¿—å¤„ç†å™¨
logger.add(
    sys.stdout,
    format="<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
    level="DEBUG",
    colorize=True
)
logger.add(
    "knowledge_graph_demo.log",
    format="{time:YYYY-MM-DD HH:mm:ss.SSS} | {level: <8} | {name}:{function}:{line} - {message}",
    level="DEBUG",
    rotation="10 MB"
)

from agenticx.knowledge.graphers import (
    # Data models
    Document, DocumentMetadata, Entity, Relationship, KnowledgeGraph,
    EntityType, RelationType,
    # Builders
    KnowledgeGraphBuilder, EntityExtractor, RelationshipExtractor,
    GraphQualityValidator,
    # Advanced constructors
    GraphRAGConstructor, CommunityDetector, GraphOptimizer
)
from agenticx.knowledge.graphers.config import GrapherConfig

# æ—¥å¿—å·²åœ¨æ–‡ä»¶å¼€å¤´é…ç½®


def basic_graph_construction_demo():
    """Basic knowledge graph construction example"""
    print("=== Basic Knowledge Graph Construction Demo ===")
    
    # Sample documents
    documents = [
        Document(
            content="""
            å¼ ä¸‰æ˜¯åŒ—äº¬å¤§å­¦çš„è®¡ç®—æœºç§‘å­¦æ•™æˆã€‚ä»–ä¸“é—¨ç ”ç©¶äººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ ã€‚
            å¼ ä¸‰ä¸æå››æ˜¯åŒäº‹ï¼Œä»–ä»¬ä¸€èµ·åœ¨AIå®éªŒå®¤å·¥ä½œã€‚
            åŒ—äº¬å¤§å­¦ä½äºåŒ—äº¬å¸‚æµ·æ·€åŒºï¼Œæ˜¯ä¸­å›½é¡¶å°–çš„ç ”ç©¶å‹å¤§å­¦ã€‚
            """,
            metadata=DocumentMetadata(
                name="doc1",
                source_type="text",
                content_type="text/plain"
            )
        ),
        Document(
            content="""
            æå››æ˜¯åŒ—äº¬å¤§å­¦çš„æ•°æ®ç§‘å­¦ç ”ç©¶å‘˜ã€‚å¥¹çš„ç ”ç©¶é‡ç‚¹æ˜¯æ·±åº¦å­¦ä¹ å’Œç¥ç»ç½‘ç»œã€‚
            æå››æ›¾åœ¨æ¸…åå¤§å­¦è·å¾—åšå£«å­¦ä½ã€‚
            æ¸…åå¤§å­¦ä¹Ÿä½äºåŒ—äº¬å¸‚ï¼Œä¸åŒ—äº¬å¤§å­¦é½åã€‚
            """,
            metadata=DocumentMetadata(
                name="doc2",
                source_type="text",
                content_type="text/plain"
            )
        ),
        Document(
            content="""
            AIå®éªŒå®¤æ˜¯åŒ—äº¬å¤§å­¦è®¡ç®—æœºå­¦é™¢çš„é‡è¦ç ”ç©¶æœºæ„ã€‚
            å®éªŒå®¤ä¸»è¦ç ”ç©¶æ–¹å‘åŒ…æ‹¬æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰ã€‚
            å¼ ä¸‰æ‹…ä»»å®éªŒå®¤ä¸»ä»»ï¼Œæå››æ˜¯æ ¸å¿ƒç ”ç©¶å‘˜ã€‚
            """,
            metadata=DocumentMetadata(
                name="doc3",
                source_type="text",
                content_type="text/plain"
            )
        )
    ]
    
    # Load config from YAML
    config_path = Path(__file__).parent.parent / "agenticx" / "configs" / "knowledge_graphers_config.yml"
    with open(config_path, "r", encoding="utf-8") as f:
        config_data = yaml.safe_load(f)

    grapher_config = GrapherConfig.from_dict(config_data)

    # Build knowledge graph
    builder = KnowledgeGraphBuilder(
        config=grapher_config.graphrag,
        llm_config=grapher_config.llm
    )
    texts = [doc.content for doc in documents]
    metadata = [vars(doc.metadata) for doc in documents]
    graph = builder.build_from_texts(texts, metadata)
    graph.name = "University Research Graph"
    
    print(f"Graph Name: {graph.name}")
    print(f"Entities: {len(graph.entities)}")
    print(f"Relationships: {len(graph.relationships)}")
    
    # Show entities
    print("\nExtracted Entities:")
    for entity in graph.entities.values():
        print(f"  - {entity.name} ({entity.entity_type.value}) [confidence: {entity.confidence:.2f}]")
    
    # Show relationships
    print("\nExtracted Relationships:")
    for rel in graph.relationships.values():
        source_name = graph.get_entity(rel.source_entity_id).name
        target_name = graph.get_entity(rel.target_entity_id).name
        rel_type = rel.relation_type.value if hasattr(rel.relation_type, 'value') else rel.relation_type
        print(f"  - {source_name} --[{rel_type}]--> {target_name} [confidence: {rel.confidence:.2f}]")
    
    return graph


def graph_quality_validation_demo(graph: KnowledgeGraph):
    """Graph quality validation example"""
    print("\n=== Graph Quality Validation Demo ===")
    
    # Load config from YAML
    config_path = Path(__file__).parent.parent / "configs" / "knowledge_graphers_config.yml"
    with open(config_path, "r", encoding="utf-8") as f:
        config_data = yaml.safe_load(f)

    grapher_config = GrapherConfig.from_dict(config_data)

    validator = GraphQualityValidator(config=grapher_config.graphrag.quality_validation)
    quality_report = validator.validate(graph)
    
    print(f"Overall Quality Score: {quality_report.overall_score:.3f}")
    print(f"Quality Level: {quality_report.quality_level}")
    
    print("\nQuality Metrics:")
    metrics = quality_report.metrics
    print(f"  Entity Count: {metrics.entity_count}")
    print(f"  Relationship Count: {metrics.relationship_count}")
    print(f"  Entity Coverage: {metrics.entity_coverage:.3f}")
    print(f"  Relationship Diversity: {metrics.relationship_diversity}")
    print(f"  Confidence Score: {metrics.confidence_score:.3f}")
    print(f"  Entities with Attributes: {metrics.entities_with_attributes}")
    print(f"  Entities with Descriptions: {metrics.entities_with_descriptions}")
    
    if quality_report.issues:
        print("\nIdentified Issues:")
        for issue in quality_report.issues:
            print(f"  - {issue}")
    
    if quality_report.recommendations:
        print("\nRecommendations:")
        for rec in quality_report.recommendations:
            print(f"  - {rec}")


def graphrag_construction_demo():
    """Advanced GraphRAG construction example"""
    print("\n=== GraphRAG Construction Demo ===")
    
    # Load config from YAML
    config_path = Path(__file__).parent.parent / "configs" / "knowledge_graphers_config.yml"
    with open(config_path, "r", encoding="utf-8") as f:
        config_data = yaml.safe_load(f)

    grapher_config = GrapherConfig.from_dict(config_data)

    # Extended documents for better community detection
    documents = [
        Document(
            content="""
            äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚
            æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒæŠ€æœ¯ï¼ŒåŒ…æ‹¬ç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ã€‚
            æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ã€‚
            """,
            metadata=DocumentMetadata(name="ai_overview", source_type="text")
        ),
        Document(
            content="""
            è‡ªç„¶è¯­è¨€å¤„ç†(NLP)æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åº”ç”¨é¢†åŸŸã€‚
            NLPæŠ€æœ¯åŒ…æ‹¬æ–‡æœ¬åˆ†æã€è¯­è¨€ç†è§£ã€æœºå™¨ç¿»è¯‘ç­‰ã€‚
            BERTã€GPTç­‰é¢„è®­ç»ƒæ¨¡å‹æ¨åŠ¨äº†NLPæŠ€æœ¯çš„å¿«é€Ÿå‘å±•ã€‚
            """,
            metadata=DocumentMetadata(name="nlp_tech", source_type="text")
        ),
        Document(
            content="""
            è®¡ç®—æœºè§†è§‰æ˜¯å¦ä¸€ä¸ªé‡è¦çš„AIåº”ç”¨é¢†åŸŸã€‚
            å·ç§¯ç¥ç»ç½‘ç»œ(CNN)æ˜¯è®¡ç®—æœºè§†è§‰çš„æ ¸å¿ƒæŠ€æœ¯ã€‚
            å›¾åƒè¯†åˆ«ã€ç›®æ ‡æ£€æµ‹ã€å›¾åƒåˆ†å‰²æ˜¯è®¡ç®—æœºè§†è§‰çš„ä¸»è¦ä»»åŠ¡ã€‚
            """,
            metadata=DocumentMetadata(name="cv_tech", source_type="text")
        ),
        Document(
            content="""
            åŒ—äº¬å¤§å­¦ã€æ¸…åå¤§å­¦ã€ä¸­ç§‘é™¢æ˜¯ä¸­å›½AIç ”ç©¶çš„é‡è¦æœºæ„ã€‚
            è¿™äº›æœºæ„åœ¨æ·±åº¦å­¦ä¹ ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ç­‰é¢†åŸŸéƒ½æœ‰é‡è¦è´¡çŒ®ã€‚
            äº§å­¦ç ”åˆä½œæ¨åŠ¨äº†AIæŠ€æœ¯çš„äº§ä¸šåŒ–åº”ç”¨ã€‚
            """,
            metadata=DocumentMetadata(name="ai_institutions", source_type="text")
        )
    ]
    
    # Build GraphRAG
    constructor = GraphRAGConstructor(
        config=grapher_config.graphrag,
        llm_config=grapher_config.llm
    )
    
    texts = [doc.content for doc in documents]
    metadata = [vars(doc.metadata) for doc in documents]
    
    graph = constructor.construct_from_texts(texts, metadata)
    graph.name = "AI Knowledge Graph"
    
    print(f"GraphRAG Name: {graph.name}")
    print(f"Total Nodes: {graph.graph.number_of_nodes()}")
    print(f"Total Edges: {graph.graph.number_of_edges()}")
    
    # Show hierarchical structure
    level_distribution = graph.metadata.get('level_distribution', {})
    print(f"\nHierarchical Structure:")
    for level, count in sorted(level_distribution.items()):
        level_name = {1: "Attributes", 2: "Entities", 3: "Keywords", 4: "Communities"}.get(level, f"Level {level}")
        print(f"  {level_name}: {count} nodes")
    
    # Show communities
    community_nodes = [
        (node_id, data) for node_id, data in graph.graph.nodes(data=True)
        if data.get('level') == 4  # Community level
    ]
    
    if community_nodes:
        print(f"\nDetected Communities:")
        for node_id, data in community_nodes:
            properties = data.get('properties', {})
            name = properties.get('name', 'Unknown')
            member_count = properties.get('member_count', 0)
            description = properties.get('description', 'No description')
            print(f"  - {name}: {member_count} members")
            print(f"    Description: {description}")
    
    return graph


def incremental_update_demo(graph: KnowledgeGraph):
    """Incremental graph update example"""
    print("\n=== Incremental Update Demo ===")
    
    print(f"Original graph: {len(graph.entities)} entities, {len(graph.relationships)} relationships")
    
    # New documents to add
    new_documents = [
        Document(
            content="""
            å¼ºåŒ–å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ç¬¬ä¸‰å¤§ç±»ï¼Œä¸ç›‘ç£å­¦ä¹ å’Œæ— ç›‘ç£å­¦ä¹ å¹¶åˆ—ã€‚
            å¼ºåŒ–å­¦ä¹ é€šè¿‡æ™ºèƒ½ä½“ä¸ç¯å¢ƒçš„äº¤äº’æ¥å­¦ä¹ æœ€ä¼˜ç­–ç•¥ã€‚
            AlphaGoå°±æ˜¯å¼ºåŒ–å­¦ä¹ çš„æˆåŠŸåº”ç”¨æ¡ˆä¾‹ã€‚
            """,
            metadata=DocumentMetadata(name="rl_intro", source_type="text")
        ),
        Document(
            content="""
            OpenAIæ˜¯äººå·¥æ™ºèƒ½ç ”ç©¶çš„é‡è¦æœºæ„ï¼Œå¼€å‘äº†GPTç³»åˆ—æ¨¡å‹ã€‚
            GPT-4æ˜¯ç›®å‰æœ€å…ˆè¿›çš„å¤§è¯­è¨€æ¨¡å‹ä¹‹ä¸€ã€‚
            å¤§è¯­è¨€æ¨¡å‹çš„å‘å±•æ¨åŠ¨äº†é€šç”¨äººå·¥æ™ºèƒ½çš„ç ”ç©¶ã€‚
            """,
            metadata=DocumentMetadata(name="openai_gpt", source_type="text")
        )
    ]
    
    # Load config from YAML
    config_path = Path(__file__).parent.parent / "configs" / "knowledge_graphers_config.yml"
    with open(config_path, "r", encoding="utf-8") as f:
        config_data = yaml.safe_load(f)

    grapher_config = GrapherConfig.from_dict(config_data)

    # Perform incremental update
    constructor = GraphRAGConstructor(
        config=grapher_config.graphrag,
        llm_config=grapher_config.llm
    )
    new_texts = [doc.content for doc in new_documents]
    updated_graph = constructor.construct_incremental(graph, new_texts)
    
    print(f"Updated graph: {len(updated_graph.entities)} entities, {len(updated_graph.relationships)} relationships")
    
    # Show new entities
    print("\nNew entities added:")
    for entity in updated_graph.entities.values():
        if any("rl_intro" in chunk or "openai_gpt" in chunk for chunk in entity.source_chunks):
            print(f"  - {entity.name} ({entity.entity_type.value})")
    
    return updated_graph


async def graph_analysis_demo(graph: KnowledgeGraph):
    """Graph analysis and statistics example"""
    print("\n=== Graph Analysis Demo ===")
    
    # Basic statistics
    stats = graph.get_statistics()
    print("Basic Statistics:")
    for key, value in stats.items():
        if isinstance(value, dict):
            print(f"  {key}:")
            for sub_key, sub_value in value.items():
                print(f"    {sub_key}: {sub_value}")
        else:
            print(f"  {key}: {value}")
    
    # Find most connected entities
    entity_degrees = []
    for entity_id in graph.entities.keys():
        if entity_id in graph.graph:
            degree = graph.graph.degree(entity_id)
            entity_name = graph.entities[entity_id].name
            entity_degrees.append((entity_name, degree))
    
    entity_degrees.sort(key=lambda x: x[1], reverse=True)
    
    print(f"\nMost Connected Entities:")
    for name, degree in entity_degrees[:5]:
        print(f"  - {name}: {degree} connections")
    
    # Find entities by type
    print(f"\nEntities by Type:")
    for entity_type in EntityType:
        entities_of_type = graph.find_entities_by_type(entity_type)
        if entities_of_type:
            print(f"  {entity_type.value}: {len(entities_of_type)} entities")
            for entity in entities_of_type[:3]:  # Show first 3
                print(f"    - {entity.name}")
            if len(entities_of_type) > 3:
                print(f"    ... and {len(entities_of_type) - 3} more")


def graph_export_demo(graph: KnowledgeGraph):
    """Graph export and serialization example"""
    print("\n=== Graph Export Demo ===")
    
    # Export to JSON
    output_dir = Path("output")
    output_dir.mkdir(exist_ok=True)
    
    json_file = output_dir / "knowledge_graph.json"
    graph.to_json(str(json_file))
    print(f"Graph exported to JSON: {json_file}")
    
    # Show JSON structure (first few lines)
    with open(json_file, 'r', encoding='utf-8') as f:
        content = f.read()
        lines = content.split('\n')
        print(f"JSON file preview (first 10 lines):")
        for line in lines[:10]:
            print(f"  {line}")
        if len(lines) > 10:
            print(f"  ... and {len(lines) - 10} more lines")
    
    # Test loading from JSON
    loaded_graph = KnowledgeGraph.from_json(str(json_file))
    print(f"Loaded graph: {len(loaded_graph.entities)} entities, {len(loaded_graph.relationships)} relationships")
    
    # Export graph statistics
    stats_file = output_dir / "graph_statistics.json"
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(graph.get_statistics(), f, ensure_ascii=False, indent=2)
    print(f"Graph statistics exported to: {stats_file}")


def main():
    """Run all knowledge graph demos"""
    logger.info("ğŸš€ å¯åŠ¨AgenticXçŸ¥è¯†å›¾è°±æ„å»ºæ¼”ç¤º")
    print("AgenticX Knowledge Graph Construction Demo")
    print("=" * 60)
    
    try:
        logger.info("ğŸ“Š å¼€å§‹åŸºç¡€çŸ¥è¯†å›¾è°±æ„å»ºæ¼”ç¤º")
        # Basic construction
        basic_graph = basic_graph_construction_demo()
        logger.success(f"âœ… åŸºç¡€çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆï¼ŒåŒ…å« {len(basic_graph.entities)} ä¸ªå®ä½“ï¼Œ{len(basic_graph.relationships)} ä¸ªå…³ç³»")
        
        logger.info("ğŸ” å¼€å§‹å›¾è°±è´¨é‡éªŒè¯æ¼”ç¤º")
        # Quality validation
        graph_quality_validation_demo(basic_graph)
        logger.success("âœ… å›¾è°±è´¨é‡éªŒè¯å®Œæˆ")
        
        # Advanced GraphRAG construction
        graphrag_graph = graphrag_construction_demo()
        
        # Incremental updates
        updated_graph = incremental_update_demo(graphrag_graph)
        
        # Graph analysis
        graph_analysis_demo(updated_graph)
        
        # Export and serialization
        graph_export_demo(updated_graph)
        
        print("\n" + "=" * 60)
        print("All knowledge graph demos completed successfully!")
        
        # Final summary
        print(f"\nFinal Graph Summary:")
        print(f"  Name: {updated_graph.name}")
        print(f"  Entities: {len(updated_graph.entities)}")
        print(f"  Relationships: {len(updated_graph.relationships)}")
        print(f"  Total Nodes: {updated_graph.graph.number_of_nodes()}")
        print(f"  Total Edges: {updated_graph.graph.number_of_edges()}")
        print(f"  Created: {updated_graph.created_at}")
        print(f"  Last Updated: {updated_graph.updated_at}")
        
    except Exception as e:
        logger.error(f"Demo execution failed: {e}")
        raise


if __name__ == "__main__":
    main()